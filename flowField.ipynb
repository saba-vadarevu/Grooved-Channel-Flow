{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# flowField class for iterative solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "- Subclass of numpy.ndarray()\n",
    "\n",
    "### Basic flow descriptors\n",
    "Define as a dictionary:\n",
    "* $ \\alpha, \\beta $  describing the periodicity, and $Re$\n",
    "* K,L,M,N describing the resolution:\n",
    "    - K: No. of temporal frequencies\n",
    "    - L: No. of positive streamwise Fourier modes\n",
    "    - M: No. of positive spanwise Fourier modes\n",
    "    - N: No. of Chebyshev collocation nodes in wall-normal \n",
    "    - The total size of each variable would be (2L+1)(2M+1)N\n",
    "* Flow type: Couette or Poiseuille (use flags)- default to Couette\n",
    "    - Boundary conditions on $u_0$\n",
    "    - dPdx\n",
    "    \n",
    "### Values\n",
    "* The classes are a subclass of np.ndarray. So the values of the flowField can be directly accessed through the name of the instance. But this is not recommended unless one's absolutely sure about what they're doing. Class methods should be used as much as possible, and if doing something with the arrays outside of the methods, the accompanying dictionaries should also be appropriately modified.\n",
    "    - Store only fluctuations\n",
    "    - Define a separate $u_{base}$ based on `isPois` when the base flow is needed. \n",
    "\n",
    "\n",
    "### Methods to be defined\n",
    "* Viewers: \n",
    "    - self.view1d(): 1D array for state\n",
    "    - self.view4d(): 4D array (streamwise, spanwise, variable ID, wall-normal)\n",
    "* Verification:  self.verify()\n",
    "    - Check that the dictionary `flowDict` has all the required parameters\n",
    "    - Check that the parameters are consistent with the size of the np.ndarray\n",
    "    - Check that appropriate modes are complex conjugates\n",
    "* Slicing: self.slice()\n",
    "    - Return only a subset of Fourier modes (centered at (K,L,M) = (0,0,0) )\n",
    "    - Extend the flowField by adding zero modes for higher wavenumbers\n",
    "* Dot product of flow fields: chi1.dot(chi2)\n",
    "    - Defined as $\\int_0^T\\int_\\forall (u_1\\bar{u_2} + v_1 \\bar{v_2} + w_1 \\bar{w_2}) dx dy dz dt$ \n",
    "    - Optional parameter to include the fourth field variable in the integration\n",
    "* Norm: self.norm()\n",
    "    - self.norm() = sqrt( self.dot(self)) \n",
    "* physical: self.physical(fileName)\n",
    "    - Print field on Cartesian coordinates to file\n",
    "    - Set defaults for optional parameters `xsteps,ysteps,zsteps,tsteps` based on number of Fourier and Chebyshev modes in the flowField. Prints fields at different times to different files\n",
    "    \n",
    "## Inputs\n",
    "* Flow descriptors (see above)\n",
    "    - Keep $ \\alpha, \\beta, Re$ as optional parameters, default values being those used in ChannelFlow: (1.14,2.5,400)\n",
    "    * Resolution: L,M,N    \n",
    "* Base flow type (flag):\n",
    "    - Either linear, or quadratic. Assume linear as default. \n",
    "* Read from file- optional (flag):\n",
    "    - Filename, format ('mat', 'npy', 'asc',...)\n",
    "* Noise levels (default to zero):\n",
    "    - Add random noise to the state vector whose norm is that as input.\n",
    "\n",
    "## Tests for class\n",
    "* Ensure that solving for flat-walled Couette and Poiseuille flows using direct inversion works\n",
    "* Ensure that the above cases work with iterative solver. \n",
    "\n",
    "### Other notes to self:\n",
    "* Write doc-strings for all the methods and inputs\n",
    "* When initializing flowField as white-noise, think about smoothening the noise. Do this by using random coefficients for fields in Chebyshev spectral, and then transform to collocation nodes. Put more of the energy into lower Cheb modes and lower Fourier modes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborator comments\n",
    "Use this cell for comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "---------------------------------------------------\n",
    "\n",
    "## Inheriting numpy.ndarray()\n",
    "\n",
    "Reference: http://docs.scipy.org/doc/numpy/user/basics.subclassing.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class C(np.ndarray): pass\n",
    "\n",
    "arr = np.zeros(3,)\n",
    "c_arr = arr.view(C)\n",
    "\n",
    "print(type(arr))\n",
    "print(type(c_arr))\n",
    "print(c_arr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v= c_arr[:]\n",
    "print(type(v))\n",
    "\n",
    "v is c_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(type(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(dir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(c_arr)\n",
    "v[1]=5.\n",
    "print(c_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v == c_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to be careful when using `is`. It refers to the IDs of objects. If using arrays or elements of arrays, using `is` is a bad idea. Stick to `==` when comparing numerical values- which is usually all I care for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen = np.zeros(3,)\n",
    "v1 = gen[:]\n",
    "print(v1 is gen)\n",
    "v1[1]=3.\n",
    "print(gen)\n",
    "print(gen[:] is gen)\n",
    "print(id(gen))\n",
    "print(id(gen[:]))\n",
    "v2 = gen\n",
    "print (v2 is gen)\n",
    "print (id(v2))\n",
    "print(v1 == gen)\n",
    "print (v1[0] is gen[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Reading files into dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cat flowConfig.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flowDict = {}\n",
    "with open(\"flowConfig.txt\",'r') as f:\n",
    "    for line in f:\n",
    "        (key,val) = line.split()[:2]\n",
    "        flowDict[key] = float(val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "defaultDict = {'alpha':1.14, 'beta' : 2.5, 'omega':0.0, 'L': 0.0, 'M': 0.0, 'N': 0.0, 'K':0.0,\n",
    "               'ReLam': 400.0, 'isPois':0.0, 'noise':0.0 , 'testvar':5.5}\n",
    "for key in defaultDict:\n",
    "    if key not in flowDict:\n",
    "        flowDict[key] = defaultDict[key]\n",
    "        print(key,flowDict[key],type(flowDict[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(flowDict)\n",
    "print( 2.5+flowDict['alpha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flowDict['alpha'],flowDict['beta']\n",
    "print (2+float(flowDict['alpha']))\n",
    "print(flowDict.values)\n",
    "float(flowDict['beta'])\n",
    "\n",
    "flowDict['alpha'] = float(flowDict['alpha'])\n",
    "flowDict['alpha']+2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining flowField class that inherits np.ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For starters, defining the class to initialize an empty ndarray along with a dictionary provided during initialization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to verify that the dictionary being supplied has all the info I need to go with a flowField class. But, I can't verify this all the time. This is how I'll deal with it: \n",
    "* Verify the dictionary only when constructing a flowField class. So, that's when\n",
    "    - Explicitly constructing an instance of the class\n",
    "    - Viewing a given array as an instance of the class\n",
    "* When slicing an array of the flowField class (to obtain another instance of the class), don't bother with the check. \n",
    "\n",
    "Basically, ensure every instance of the flowField class has a valid dictionary, and then stop worrying about it. \n",
    "\n",
    "So, we need a function that verifies the validity of dictionary, or creates one if one isn't supplied. The parameters required in the dictionary, and their defaults, are as follows:\n",
    "* alpha : 1.14    \n",
    "    *Wavenumber of fundamental streamwise Fourier mode*\n",
    "* beta :  2.5    \n",
    "    *Wavenumber of fundamental spanwise Fourier mode*\n",
    "* omega: 0.0    \n",
    "    *Fundamental frequency*\n",
    "* ReLam: 400.0  \n",
    "    *Reynolds number of the laminar base flow*\n",
    "* isPois: 0     \n",
    "    *Flag for base flow type. 0: Couette, 1: Poiseuille*\n",
    "* noise: 0.0    \n",
    "    *Norm of noise to be added to the flow*\n",
    "* L: 0          \n",
    "    *Number of (positive) harmonics of fundamental streamwise Fourier mode.*\n",
    "* M: 0          \n",
    "    *Number of (positive) harmonics of fundamental spanwise Fourier mode*\n",
    "* N: 35         \n",
    "    *Number of Chebyshev collocation nodes*\n",
    "* K: 0         \n",
    "    *Number of (positive) harmonics of fundamental frequency*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** For now, I'm ignoring the fact that np.ndarray can be viewed as a subclass. I'm defining the dictionary and checks in flowField.__new__(). Later, I'll have to move this to __array_finalize__ so that the dictionary is defined for cases when either an explicit constructor call is made or a view-casting is done**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure these features:\n",
    "* View-casting:\n",
    "    - ** View-casting a np.ndarray as flowField instance is not supported. Because view-casting does not allow any arguments, and the dictionary that accompanies the flowField array is fundamental. To make a flowField object out of an existing np.ndarray, use the constructor call. **\n",
    "* Explicit construction:\n",
    "    - Construct a randomField object based on noise levels supplied\n",
    "* New from template:\n",
    "    - Truncate and expand an instance of flowField to obtain a new instance with a changed dictionary (to reflect the truncation of L,M,N, or K)\n",
    "\n",
    "***Try to minimize making copies of flowField objects***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** I have three cases to consider when building a flowField instance. Suppose L = 1**:\n",
    "- The flowField has streamwise wavenumbers $-\\alpha, 0, \\alpha$\n",
    "- The flowField only has streamwise wavenumbers $-\\alpha, \\alpha$\n",
    "- The flowField only has streamwise wavenumber $\\alpha$\n",
    "    \n",
    "This question becomes particularly important if only a half-plane or half-volume of the wavenumber space is considered. \n",
    "\n",
    "This is how I chose to resolve this issue. Considering L:\n",
    "* If L = 0, then the flowField is of wavenumber $\\alpha$\n",
    "* If L = n ($\\in \\mathbb{N}$), then the flowField is resolved in wavenumbers {$0,\\alpha,2\\alpha,..,n\\alpha$}.\n",
    "* If L = -n ($n \\in \\mathbb{N}$), then the flowField is resolved in wavenumbers {$-n\\alpha, (-n+1)\\alpha,..,0,\\alpha,...,n\\alpha$}\n",
    "\n",
    "This way, a flowField can be defined in three different ways for each of the three Fourier axes (streamwise, spanwise, temporal):\n",
    "* As just one Fourier mode, $\\alpha$ (which could be positive, negative, or zero). \n",
    "* As a collection of `n` harmonics (positive integer multiples of a positive/negative wavenumber), along with mode zero (the invariant mode).\n",
    "* As a collection of `2n+1` harmonics, from $-n\\alpha$ through $n\\alpha$.\n",
    "\n",
    "** Correction: For streamwise and temporal Fourier modes, the flowField class does not allow having just positive modes. We either have just one wavenumber (initialized with L=0 and/or K=0), of have 2L+1 and 2K+1 wavenumbers with both positive and negative**\n",
    "\n",
    "I think this should be enough to deal with most cases. We will later need to define collections of flowFields. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In case dictionary is 'None':\n",
    "defaultDict = {'alpha':1.14, 'beta' : 2.5, 'omega':0.0, 'L': 0.0, 'M': 0.0, 'N': 0.0, 'K':0.0,\n",
    "               'ReLam': 400.0, 'isPois':0.0, 'noise':0.0 }\n",
    "\n",
    "def verify_dict(tempDict):\n",
    "    if tempDict is None:\n",
    "        tempDict = defaultDict\n",
    "    else: \n",
    "        for key in defaultDict:\n",
    "            if key not in tempDict:\n",
    "                tempDict[key] = defaultDict[key]\n",
    "    return tempDict\n",
    "\n",
    "flowDict = None\n",
    "flowDict = verify_dict(flowDict)\n",
    "print(flowDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slice\n",
    "I'm defining `slice` as a general method used for either truncating or extending the existing flowField instance. \n",
    "\n",
    "There are several cases to consider:\n",
    "1.  Both existing and requested instances have the same wavenumber extension: either both contain positive and negative wavenumbers, or both contain only non-negative wavenumbers. For this case, there are 2 subcases:\n",
    "    1.  The requested instance needs the existing instance to be truncated or held the same.\n",
    "    2.  The requested instance needs the existing instance to be extended.\n",
    "2.  The existing instance contains positive as well as negative wavenumbers, whereas the requested instance is only for positive wavenumbers. For this case:\n",
    "    1.  The requested instance requires truncation in positive modes of the existing instance.\n",
    "    2.  The requested instance requires extension in positive wavenumbers (with zeros for modes unavailable).\n",
    "3.  The existing instance contains only positive wavenumbers, whereas the requested instance is for positive as well as negative. For this case too:\n",
    "    1.  Truncation.\n",
    "    2.  Extension.\n",
    "\n",
    "\n",
    "## Going from half plane/volume to full using conjugate\n",
    "I thought that if the Fourier modes available were $(0:K\\omega,0:L\\alpha, 0:M\\beta)$, I could extend each set of modes into the negative side. But that's not true, I can only do that for just 1 set of modes. That is, I can't extend a quadrant to a full plane or an octant to a full volume. I can only go from 2 quadrants to 4, or 4 octants to 8. \n",
    "\n",
    "For now, I will suppose that we always have the flow resolved in the half-plane or the half-volume $\\beta>0$. So, K,L are always negative (-0=0). Only M is allowed to be positive, but it could also be set to be negative. \n",
    "\n",
    "**With this simplification, cases 2 and 3 identified for slicing (above) only relate to M. For K and L, it's always case 1.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linearizing convection term about a base flow\n",
    "\n",
    "$\\chi = \\chi_b + \\chi_f$ \n",
    "    where $\\chi_b$ is the base flow and $\\chi_f$ the perturbation\n",
    "\n",
    "\n",
    "$\\begin{align}\n",
    "(\\chi.\\nabla)\\chi &= ((\\chi_b+\\chi_f).\\nabla)(\\chi_b+\\chi_f)\\\\\n",
    "        &\\approx \\chi_b.\\nabla \\chi_b + \\chi_b.\\nabla \\chi_f + \\chi_f.\\nabla \\chi_b \\\\\n",
    "\\implies (\\chi.\\nabla)\\chi - (\\chi_b.\\nabla)\\chi_b &= \\chi_b.\\nabla \\chi_f + \\chi_f.\\nabla \\chi_b = C_l\n",
    "\\end{align}$ \n",
    "\n",
    "With the domain transformation stuff, the non-linear terms for stability analysis is going to be a pain to deal with- because when the fluctuation has a wavenumber which isn't an integral multiple of the surface wavenumber, the nice Fourier resolution that I have going right now will get messed up. For today, I'll do this part without worrying about the domain transformation. Just plain old LSA. \n",
    "\n",
    "Supposing $\\chi_b = [U(y),0,0]$, with $\\chi_f = [u_f(y), v_f(y), w_f(y)] e^{i(\\alpha x + \\beta z - \\omega t)}$, and dropping the subscript 'f' henceforth:\n",
    "\n",
    "$C_l[0] = U u_x + v U' \\\\\n",
    "C_l[1] = U v_x \\\\\n",
    "C_l[2] = U w_x $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting flowField.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile flowField.py\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "#from scipy.linalg import norm\n",
    "from warnings import warn\n",
    "from pseudo import chebdif\n",
    "#from pseudo.py import chebint\n",
    "\n",
    "defaultDict = {'alpha':1.14, 'beta' : 2.5, 'omega':0.0, 'L': 23, 'M': 23, 'nd':3,'N': 35, 'K':0,\n",
    "               'ReLam': 400.0, 'isPois':0.0, 'noise':0.0 }\n",
    "\n",
    "def verify_dict(tempDict):\n",
    "    '''Verify that the supplied flowDict has all the parameters required'''\n",
    "    change_parameters = False\n",
    "    if tempDict is None:\n",
    "        tempDict = defaultDict\n",
    "        warn('No flowDict was supplied. Assigning the default dictionary')\n",
    "    else: \n",
    "        for key in defaultDict:\n",
    "            if key not in tempDict:\n",
    "                change_parameters = True\n",
    "                tempDict[key] = defaultDict[key]\n",
    "    [tempDict['K'],tempDict['L'],tempDict['N'],tempDict['isPois']] = [int(abs(k)) for k in [tempDict['K'],tempDict['L'],tempDict['N'],tempDict['isPois']]]\n",
    "    tempDict['M'] = int(tempDict['M'])\n",
    "    if change_parameters:\n",
    "        warn('The supplied dictionary had some parameters missing. These were provided from the default dictionary')\n",
    "    return tempDict\n",
    "\n",
    "def read_dictFile(dictFile):\n",
    "    '''Read flowDict from file. MUST use \"flowConfig.txt\" as template. '''\n",
    "    tempDict = {}\n",
    "    with open(\"flowConfig.txt\",'r') as f:\n",
    "        for line in f:\n",
    "            (key,val) = line.split()[:2]\n",
    "            tempDict[key] = float(val)    \n",
    "    return tempDict\n",
    "\n",
    "def makeVector(*args):\n",
    "    '''Concatenate flowField objects. Use this to create a vector flowField from a scalar flowField as\n",
    "    uvw = makeVector(u,v,w)'''\n",
    "    ff = args[0]\n",
    "    if not isinstance(ff,flowField):\n",
    "        raise RuntimeError('makeVector takes as arguments only instances of flowField class')\n",
    "        return\n",
    "    for v in args[1:]:\n",
    "        if not isinstance(v,flowField):\n",
    "            raise RuntimeError('makeVector takes as arguments only instances of flowField class')\n",
    "        ff = ff.appendField(v)\n",
    "    return ff\n",
    "    \n",
    "\n",
    "class flowField(np.ndarray):\n",
    "    ''' Provides a class to define u,v,w,p in 4D: time, x,z,y. \n",
    "    Ordered as (omega,alpha,beta,nd,y): omega, alpha, beta are Fourier modes in t,x,z respectively.\n",
    "    nd is an index going from 0 to 3 for u,v,w,p. \n",
    "    y is the array of Chebyshev collocation nodes\n",
    "    The dictionary is fundamental to the workings of the flowField class. \n",
    "        All three arguments can be used to provide a dictionary (arr can be an instance of flowField).\n",
    "        flowDict argument has highest priority in defining the dictionary, \n",
    "            followed by dictFile\n",
    "            followed by arr.flowDict\n",
    "        If none of the above arguments provide a flowDict, a default dictionary (defined in the module) is used.\n",
    "        A warning message is printed when the default dictionary is used.\n",
    "\n",
    "    Methods: \n",
    "        slice(K,L,M,nd,N): Make grid finer or coarser along any direction\n",
    "        view1d(): Return 1-d array of class flowField\n",
    "        view4d(): Return 4-d array of class flowField\n",
    "        etc... \n",
    "        Create an object using defaults as ff = flowField() and use tab completion to see all the methods'''\n",
    "    \n",
    "    def __new__(cls, arr=None, flowDict=None, dictFile= None):\n",
    "        '''Creates a new instance of flowField class with arguments (arr=None,flowDict=None,dictFile=None)\n",
    "        '''\n",
    "        if flowDict is None:\n",
    "            if dictFile is None:\n",
    "                if hasattr(arr,'flowDict'):\n",
    "                    flowDict = arr.flowDict\n",
    "                else:\n",
    "                    flowDict=verify_dict(flowDict)\n",
    "            else:\n",
    "                flowDict = verify_dict(read_dictFile(dictFile))\n",
    "        else:\n",
    "            flowDict = verify_dict(flowDict)\n",
    "        \n",
    "        \n",
    "        L = flowDict['L']\n",
    "        M = flowDict['M']\n",
    "        N = flowDict['N']\n",
    "        K = flowDict['K']\n",
    "        nd = flowDict['nd']\n",
    "        nt = 2*K+1\n",
    "        nx = 2*L+1\n",
    "        nz = int(3.*abs(M)/2. - M/2. + 1)     # = 1 if M=0;    = M+1 if M>0;    = 2*|M|+1 if M<0\n",
    "        \n",
    "        if arr is None:\n",
    "            #obj =  np.zeros((nt,nx,nz,nd,N),dtype=np.complex).view(cls)\n",
    "            obj = np.ndarray.__new__(flowField,shape=(nt,nx,nz,nd,N),dtype=np.complex,buffer=np.zeros(nt*nx*nz*nd*N,dtype=np.complex))\n",
    "        else:\n",
    "            if arr.dtype == np.float:\n",
    "                arr = (arr+1.j*np.zeros(arr.shape))\n",
    "            obj = np.ndarray.__new__(flowField,shape=(nt,nx,nz,nd,N),dtype=np.complex,buffer=arr)\n",
    "        \n",
    "        #print(norm(obj))\n",
    "        \n",
    "        if obj.size != (nx*nz*nt*nd*N):\n",
    "            raise RuntimeError('The parameters in the dictionary are not consistent with the size of the supplied array')\n",
    "        \n",
    "        obj.flowDict = flowDict\n",
    "        obj.nx = nx\n",
    "        obj.nz = nz\n",
    "        obj.nt = nt\n",
    "        obj.N = N\n",
    "        obj.nd = flowDict['nd']\n",
    "        return obj\n",
    "        \n",
    "    \n",
    "    def __array_finalize__(self,obj):\n",
    "        if self.dtype != np.complex:\n",
    "            warn('flowField class is designed to work with complex array entries\\n'+\n",
    "                 'To obtain real/imaginary parts of an instance, use class methods \"real()\" and \"imag()\"')\n",
    "        if isinstance(obj, flowField):\n",
    "            self.flowDict = getattr(self,'flowDict',obj.flowDict.copy())\n",
    "            self.nt = getattr(self,'nt',obj.nt)\n",
    "            self.nx = getattr(self,'nx',obj.nx)\n",
    "            self.nz = getattr(self,'nz',obj.nz)\n",
    "            self.nd = getattr(self,'nd',obj.nd)\n",
    "            self.N = getattr(self,'N',obj.N)\n",
    "            return\n",
    "        elif obj != None:\n",
    "            raise RuntimeError('View-casting np.ndarray is not supported since dictionaries cannot be passed. \\n'+\n",
    "                               'To initialize class instance from np.ndarray, use constructor call:flowField(arr=myArray,dictFile=myFile)')\n",
    "        return\n",
    "\n",
    "    \n",
    "    def verify(self):\n",
    "        '''Ensures that the size of the class array is consistent with the dictionary entries. \n",
    "        Use this when writing new methods or tests'''\n",
    "        self.flowDict = verify_dict(self.flowDict)\n",
    "        if not ((self.nt == 2*self.flowDict['K']+1) and (self.nx == 2*self.flowDict['L']+1) and \n",
    "                (self.nz == int(3.*abs(self.flowDict['M'])/2. - self.flowDict['M']/2. + 1)) and\n",
    "                (self.N == self.flowDict['N']) and (self.nd == self.flowDict['nd'])): \n",
    "            raise RuntimeError('The shape attributes of the flowField instance are not consistent with dictionary entries')\n",
    "        if not (self.size == self.nt*self.nx*self.nz*self.nd*self.N):\n",
    "            raise RuntimeError('The size of the flowField array is not consistent with its shape attributes')\n",
    "        \n",
    "\n",
    "    def view1d(self):\n",
    "        ''' Returns a 1d view. \n",
    "        Don't try to figure out what the ordering is, just use self.view4d() to get an organized view'''\n",
    "        return self.reshape(self.size)\n",
    "    \n",
    "    def view4d(self):\n",
    "        ''' Returns a 4d view (actually, a 5-D array): (omega, alpha, beta, field=u,v,w,p, N)'''\n",
    "        return self.reshape((self.nt,self.nx,self.nz,self.nd,self.N))\n",
    "\n",
    "    def slice(self,K=None,L=None,M=None,nd=None,N=None):\n",
    "        '''\n",
    "        Returns a class instance with increased/reduced K,L,M,nd,N\n",
    "        Call as new_inst = myFlowField.slice(K=Knew,L=Lnew,N=Nnew)) to change values of K,L,N without affecting M (and nd)\n",
    "        When the number of Fourier modes (K,L,M, or nt,nx,nz) are smaller than what is requested, \n",
    "            additional zero modes are added. For Chebyshev nodes, interpolation is used'''\n",
    "        obj = self.copyArray()\n",
    "        nxt = self.nx\n",
    "        ntt = self.nt\n",
    "        nzt = self.nz\n",
    "        ndt = self.nd\n",
    "        Nt = self.N\n",
    "        flowDict_temp = self.flowDict.copy()\n",
    "        if K is not None:\n",
    "            K = int(abs(K))\n",
    "            Kt = flowDict_temp['K']               # Temporary name for 'K' of self\n",
    "            if K <= Kt:\n",
    "                obj = obj[Kt-K:Kt+K+1]\n",
    "            else: \n",
    "                obj = np.concatenate((  np.zeros((Kt-K,nxt,nzt,ndt,Nt),dtype=np.complex), obj,\n",
    "                               np.zeros((Kt-K,nxt,nzt,ndt,Nt),dtype=np.complex)  ), axis=0)\n",
    "            flowDict_temp['K']= K\n",
    "            ntt = 2*K+1\n",
    "        \n",
    "        if L is not None:\n",
    "            L = int(abs(L))\n",
    "            Lt = flowDict_temp['L']               # Temporary name for 'L' of self\n",
    "            if L <= Lt:\n",
    "                obj = obj[:,Lt-L:Lt+L+1]\n",
    "            else: \n",
    "                obj = np.concatenate((  np.zeros((ntt,abs(Lt-L),nzt,ndt,Nt),dtype=np.complex), obj,\n",
    "                               np.zeros((ntt,abs(Lt-L),nzt,ndt,Nt),dtype=np.complex)  ), axis=1)\n",
    "            flowDict_temp['L']= L\n",
    "            nxt = 2*L+1\n",
    "        \n",
    "        if M is not None:\n",
    "            M = int(M)\n",
    "            Mt = flowDict_temp['M']               # Temporary name for 'M' of self\n",
    "            nzt = int(3.*abs(M)/2. - M/2. + 1)     # = 1 if L=0;    = L+1 if L>0;    = 2*|L|+1 if L<0\n",
    "            \n",
    "            if M*Mt >=0: \n",
    "                if abs(M) <= abs(Mt): # Case 1.A: Truncate\n",
    "                    nz0 = int((abs(Mt)-Mt)/2)     # = Mt for Mt< 0, = 0 otherwise\n",
    "                    nzm1 = nz0 - int((abs(M)-M)/2) \n",
    "                    nzp1 = nz0 + abs(M) + 1\n",
    "                    obj = obj[:,:,nzm1:nzp1]\n",
    "                else:  # Case 1.B: Extend using zero modes\n",
    "                    nzplus = int(abs(M)-abs(Mt))\n",
    "                    if M<0: \n",
    "                        obj = np.concatenate(( np.zeros((ntt,nxt,abs(Mt-M),ndt,Nt),dtype=np.complex), obj,\n",
    "                               np.zeros((ntt,nxt,abs(Mt-M),ndt,Nt),dtype=np.complex)  ), axis=2)\n",
    "                    else:\n",
    "                        obj = np.concatenate(( obj,\n",
    "                               np.zeros((ntt,nxt,abs(Mt-M),ndt,Nt),dtype=np.complex) ), axis=2)\n",
    "            elif M > 0:          # Case 2: Get only modes [0,b,..,|M|b] from [-|Mt|*b,..,0,b,..,|Mt|*b]\n",
    "                if abs(M) <= abs(Mt): # Case 2.A: |M|< |Mt|, so truncate\n",
    "                    nz0 = int((abs(Mt)-Mt)/2)\n",
    "                    nzp1 = nz0 + M + 1\n",
    "                    obj = obj[:,:,nx0:nzp1]\n",
    "                else:    # Case 2.B: |M| > |Mt|, so add zero modes \n",
    "                    obj = np.concatenate(( obj[:,:,abs(Mt):], \n",
    "                               np.zeros((ntt,nxt,abs(Mt-M),ndt,Nt),dtype=np.complex) ), axis=2)\n",
    "            else: # Case 3: Get modes [-|M|b,...,0,b,..,|M|b], given [0,b,..,|Mt|b]\n",
    "                if abs(M) <= abs(Mt):        # Case 3.A: Truncate on positive, extend with conjugates on negative\n",
    "                    obj = np.concatenate(( obj[::-1,::-1,abs(M):0:-1].conjugate(), obj[:,:,:abs(M)+1] ), axis=2)\n",
    "                else:            # Case 3.B: Extend on positive with zeros, extend on negative with conjugates and zeros\n",
    "                    # Doing the extension with conjugates on negative first:\n",
    "                    obj = np.concatenate(( obj[::-1,::-1,:0:-1].conjugate(), obj ), axis=2)\n",
    "                    # Adding zeros on positive and negative:\n",
    "                    obj = np.concatenate((  np.zeros((ntt,nxt,abs(Mt-M),ndt,Nt),dtype=np.complex), obj,\n",
    "                               np.zeros((ntt,nxt,abs(Mt-M),ndt,Nt),dtype=np.complex) ), axis=2)\n",
    "            flowDict_temp['M']= M\n",
    "        \n",
    "        if N is not None:\n",
    "            N = abs(int(N))\n",
    "            Nt = flowDict_temp['N']\n",
    "            if N != Nt:\n",
    "                y = chebdif(Nt,1)[0]\n",
    "                obj_t = obj.reshape((obj.size/Nt,Nt))\n",
    "                obj = np.zeros((obj_t.size/Nt,N),dtype=np.complex)\n",
    "                for n in range(obj_t.size/N):\n",
    "                    obj[n] = chebint(obj_t[n],y)\n",
    "            obj = obj.reshape(obj.size)\n",
    "            flowDict_temp['N'] = N\n",
    "        \n",
    "        obj = flowField(arr=obj, flowDict = flowDict_temp).view4d()\n",
    "        \n",
    "        if nd is not None:\n",
    "            nd = np.asarray([nd])\n",
    "            nd = nd.reshape(nd.size)\n",
    "            obj = obj[:,:,:,nd]\n",
    "            obj.flowDict['nd'] = nd.size\n",
    "            obj.nd = nd.size\n",
    "        \n",
    "        obj.verify()\n",
    "        return obj\n",
    "    \n",
    "    def getScalar(self,nd=0):\n",
    "        '''Returns the field Variable in the flowField instance identified by the argument \"nd\".\n",
    "        Default for \"nd\" is 0, the first scalar in the flowField (u)'''\n",
    "        if type(nd) != int:\n",
    "            raise RuntimeError('getScalar(nd=0) only accepts integer arguments')\n",
    "        obj = self.view4d()[:,:,:,nd].copy()\n",
    "        obj.flowDict['nd'] = 1\n",
    "        obj.nd = 1\n",
    "        return obj.view4d()\n",
    "\n",
    "    def appendField(self,obj):\n",
    "        '''Append a field at the end of \"self\". To append \"p\" to \"uVec\", call as uVec.appendField(p)\n",
    "        Note: Both uVec and p must be flowField objects, each with their flowDict'''\n",
    "        if not isinstance(obj,flowField):\n",
    "            raise RuntimeError('Only flowField objects can be appended to a flowField object')\n",
    "        tempDict = self.flowDict.copy()\n",
    "        tempDict['nd'] += obj.flowDict['nd']\n",
    "        v1 = self.view4d().copyArray()\n",
    "        v2 = obj.view4d().copyArray()\n",
    "        return flowField(arr=np.append(v1,v2,axis=3), flowDict=tempDict)\n",
    "    \n",
    "    def copyArray(self):\n",
    "        ''' Returns a copy of the np.ndarray of the instance. \n",
    "        This is useful for manipulating the entries of a flowField without bothering with all the checks'''\n",
    "        return self.view(np.ndarray).copy()\n",
    "    \n",
    "    def real(self):\n",
    "        ''' Returns the real part of the flowField (the entries are still complex, with zero imaginary parts)'''\n",
    "        return flowField(arr=self.copyArray().real,flowDict=self.flowDict)\n",
    "    \n",
    "    def imag(self):\n",
    "        ''' Returns the imaginary part of the flowField (the entries are still complex, with zero imaginary parts)'''\n",
    "        return flowField(arr=self.copyArray().imag,flowDict=self.flowDict)\n",
    "    \n",
    "    def ddt(self):\n",
    "        ''' Returns a flowField instance that gives the partial derivative along \"t\" '''\n",
    "        if self.nt == 1:\n",
    "            return 1.j*self.flowDict['omega']*self.copy()\n",
    "        partialT = self.view4d().copy()\n",
    "        kArr = np.arange(-self.flowDict['K'],self.flowDict['K']+1).reshape(self.nt,1,1,1,1)\n",
    "        return partialT\n",
    "    \n",
    "    def ddx(self):\n",
    "        ''' Returns a flowField instance that gives the partial derivative along \"x\" '''\n",
    "        if self.nx == 1:\n",
    "            return 1.j*self.flowDict['alpha']*self.copy()\n",
    "        partialX = self.view4d().copy()\n",
    "        lArr = np.arange(-self.flowDict['L'],self.flowDict['L']+1)\n",
    "        tempArr = (np.ones((self.nt,self.nx))*lArr).reshape(self.nt,self.nx,1,1,1)\n",
    "        partialX[:] = 1.j*self.flowDict['alpha']*tempArr*partialX\n",
    "        return partialX\n",
    "    \n",
    "    def ddx2(self):\n",
    "        ''' Returns a flowField instance that gives the second partial derivative along \"x\" '''\n",
    "        if self.nx == 1:\n",
    "            return -1.*(self.flowDict['alpha']**2)*self.copy()\n",
    "        partialX2 = self.view4d().copy()\n",
    "        lArr = np.arange(-self.flowDict['L'],self.flowDict['L']+1)\n",
    "        tempArr = -(np.ones((self.nt,self.nx))*lArr**2).reshape(self.nt,self.nx,1,1,1)\n",
    "        partialX2[:] = self.flowDict['alpha']**2*tempArr*partialX2\n",
    "        return partialX2\n",
    "    \n",
    "    def ddz(self):\n",
    "        ''' Returns a flowField instance that gives the partial derivative along \"z\" '''\n",
    "        if self.nz == 1:\n",
    "            return 1.j*self.flowDict['beta']*self.copy()\n",
    "        partialZ = self.view4d().copy()\n",
    "        mArr = np.arange((self.flowDict['M']-np.abs(self.flowDict['M']))/2,self.flowDict['M']+1)\n",
    "        tempArr = (np.ones((self.nt,self.nx,self.nz))*mArr).reshape(self.nt,self.nx,self.nz,1,1)\n",
    "        partialZ[:] = 1.j*self.flowDict['beta']*tempArr*partialZ\n",
    "        return partialZ\n",
    "    \n",
    "    def ddz2(self):\n",
    "        ''' Returns a flowField instance that gives the second partial derivative along \"z\" '''\n",
    "        if self.nz == 1:\n",
    "            return -1.*(self.flowDict['beta']**2)*self.copy()\n",
    "        partialZ2 = self.view4d().copy()\n",
    "        mArr = np.arange(-self.flowDict['M'],self.flowDict['M']+1)\n",
    "        tempArr = -(np.ones((self.nt,self.nx,self.nz))*mArr**2).reshape(self.nt,self.nx,self.nz,1,1)\n",
    "        partialZ2[:] = self.flowDict['beta']**2*tempArr*partialZ2\n",
    "        return partialZ2\n",
    "    \n",
    "    def ddy(self):\n",
    "        ''' Returns a flowField instance that gives the partial derivative along \"y\" '''\n",
    "        partialY = self.view1d().copy()\n",
    "        N = partialY.flowDict['N']\n",
    "        D = (chebdif(N,1)[1]).reshape(N,N)\n",
    "        for n in range(self.nt*self.nx*self.nz*self.nd):\n",
    "            partialY[n*N:(n+1)*N] = np.dot(D, partialY[n*N:(n+1)*N])\n",
    "        return partialY.view4d()\n",
    "    \n",
    "    def ddy2(self):\n",
    "        ''' Returns a flowField instance that gives the partial derivative along \"y\" '''\n",
    "        partialY2 = self.view1d().copy()\n",
    "        N = partialY2.flowDict['N']\n",
    "        D2 = (chebdif(N,2)[1])[:,:,1].reshape(N,N)\n",
    "        for n in range(self.nt*self.nx*self.nz*self.nd):\n",
    "            partialY2[n*N:(n+1)*N] = np.dot(D2, partialY2[n*N:(n+1)*N])\n",
    "        return partialY2.view4d()\n",
    "\n",
    "\n",
    "    def convLinear(self,uBase=None):\n",
    "        ''' Computes linearized convection term as [U u_x + v U',  U v_x,  U w_x ]\n",
    "        Baseflow, uBase must be a 1D array of size \"N\" '''\n",
    "        N = self.N\n",
    "        y,DM = chebdif(N,1)\n",
    "        if uBase == None:\n",
    "            if self.flowDict['isPois'] == 1:\n",
    "                uBase = 1.- y**2\n",
    "            else:\n",
    "                uBase = y\n",
    "        else: \n",
    "            assert uBase.size == N, 'uBase should be 1D array of size \"self.N\"'\n",
    "        D = DM.reshape((N,N))\n",
    "        duBase = np.dot(D,uBase).reshape((1,1,1,N))\n",
    "        uBase = uBase.reshape((1,1,1,1,N))\n",
    "        \n",
    "        nd = 3\n",
    "        if self.nd > 3:\n",
    "            warn('Convection term is being requested using a flowField with more than 3 components. \\n',\n",
    "            'Taking only the first 3 components ')\n",
    "        elif self.nd == 2:\n",
    "            nd = 2\n",
    "        elif self.nd < 2: \n",
    "            raise RuntimeError('Need at least 2D perturbations for linear stability analysis')\n",
    "        \n",
    "        a = self.flowDict['alpha']\n",
    "        \n",
    "        convTerm = np.zeros((self.nt, self.nx, self.nz, nd, self.N), dtype=np.complex)\n",
    "        convTerm = uBase*1.j*a*self.view4d()[:,:,:,:nd].copyArray()\n",
    "        convTerm[:,:,:,0] += duBase*self.view4d()[:,:,:,1].copyArray()\n",
    "        tempDict = self.flowDict.copy()\n",
    "        tempDict['nd'] = nd\n",
    "        return flowField(arr=convTerm, flowDict=tempDict)\n",
    "    \n",
    "    def grad3d(self, scalDim=0, nd=3, partialX=flowField.ddx, partialY=flowField.ddy, partialZ = flowField.ddz):\n",
    "        ''' Computes gradient (in 3d by default) of either a scalar flowField object, \n",
    "            or of the first variable in a vector flowField object. \n",
    "            Grads of other variables can be calculated by passing scalDim=<index of variable>.\n",
    "            Gradients in 2D (x and y) can be calculated by passing nd=2'''\n",
    "        tempDict = self.flowDict.copy()\n",
    "        tempDict['nd'] = nd\n",
    "        if self.nd ==1:\n",
    "            scal = self\n",
    "        else:\n",
    "            scal = self.getScalar(nd=scalDim)\n",
    "        scal.verify()\n",
    "        if nd == 3:\n",
    "            gradVec = makeVector(partialX(scal), partialY(scal), partialZ(scal))\n",
    "        elif nd ==2:\n",
    "            gradVec = makeVector(partialX(scal),partialY(scal))\n",
    "        \n",
    "        return gradVec\n",
    "    \n",
    "    def grad(self,**kwargs):\n",
    "        return self.grad3d(**kwargs)\n",
    "    \n",
    "    def grad2d(self, **kwargs):\n",
    "        ''' Computes gradients in 2D (streamwise & wall-normal) for a scalar flowField object, \n",
    "            or for the scalar component of a vector field identified as vecField[:,:,:,scalDim]'''\n",
    "        kwargs['nd'] = 2\n",
    "        return self.grad3d(**kwargs)\n",
    "        \n",
    "    def laplacian(self, partialX2=flowField.ddx2, partialY2=flowField.ddy2, partialZ2=flowField.ddz2):\n",
    "        lapl = self.view4d().copy()\n",
    "        for scalDim in range(lapl.nd):\n",
    "            lapl[:,:,:,scalDim] = partialX2(lapl[:,:,:,scalDim])+partialY2(lapl[:,:,:,scalDim])+partialZ2(lapl[:,:,:,scalDim])\n",
    "        return lapl\n",
    "        \n",
    "    def div(self, partialX=flowField.ddx, partialY=flowField.ddy, partialZ=flowField.ddz, nd=3):\n",
    "        ''' Computes divergence of vector field as u_x+v_y+w_z\n",
    "        If a flowField with more than 3 scalars (nd>3) is supplied, takes first three components as u,v,w.\n",
    "        Optional: 2-D divergence, u_x+v_y can be requested by passing nd=2'''\n",
    "        assert nd in [2,3], ('Argument \"nd\" can only take values 2 or 3')\n",
    "        assert self.nd >= nd, ('Too few scalar components in the vector')\n",
    "        divergence = partialX(self.getScalar(nd=0)) + partialY(self.getScalar(nd=1))\n",
    "        if nd== 3:\n",
    "            divergence[:] += partialZ(self.getScalar(nd=2))\n",
    "        \n",
    "        return divergence\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 47, 24, 3, 35) (1, 47, 24, 3, 35) (1, 47, 24, 3, 35) (1, 47, 24, 3, 35) (1, 47, 24, 1, 35) (1, 47, 24, 2, 35) (1, 47, 24, 4, 35) (1, 47, 24, 3, 35) (1, 47, 24, 2, 35) (1, 47, 24, 2, 35) (1, 47, 24, 3, 35) (1, 47, 24, 1, 35)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/IPython/kernel/__main__.py:17: UserWarning: No flowDict was supplied. Assigning the default dictionary\n"
     ]
    }
   ],
   "source": [
    "ff = flowField()\n",
    "ff1 = ff.ddx()\n",
    "ff2 = ff.ddy()\n",
    "ff3 = ff.ddz()\n",
    "ff4 = ff.ddt()\n",
    "ff5 = ff.getScalar(nd=2)\n",
    "pff = ff.getScalar(nd=1)\n",
    "ff6 = ff5.appendField(pff)\n",
    "u = ff.getScalar()\n",
    "v = ff.getScalar(nd=1)\n",
    "wp = ff.slice(nd = [2,1])\n",
    "ff7 = makeVector(u,v,wp)\n",
    "uGrad = u.grad3d()\n",
    "uGrad2d = u.grad2d()\n",
    "vGrad2d = ff.grad2d(scalDim=1)\n",
    "ff8 = ff.convLinear()\n",
    "ff9 = ff.div()\n",
    "\n",
    "print(ff1.shape,ff2.shape,ff3.shape,ff4.shape, ff5.shape, ff6.shape, ff7.shape, uGrad.shape, uGrad2d.shape, vGrad2d.shape, ff8.shape, ff9.shape)\n",
    "ff.verify()\n",
    "ff1.verify()   # Prints error/warning messages if something's wrong, otherwise returns no output\n",
    "ff2.verify()\n",
    "ff3.verify()\n",
    "ff4.verify()\n",
    "ff5.verify()\n",
    "ff6.verify()\n",
    "ff7.verify()\n",
    "uGrad.verify()\n",
    "ff8.verify()\n",
    "ff9.verify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(flowField,'ddx2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ff[0]-ff1[0]: 0j\n",
      "ff[0,0,0,0,0]-ff1[0]: 0j\n",
      "Type of arr1:  <class '__main__.flowField'> shape of arr1: (1, 47, 24, 1, 35)\n",
      "<class '__main__.flowField'>\n",
      "<class 'method'>\n",
      "<class '__main__.flowField'>\n",
      "(1, 47, 24, 1, 35)\n"
     ]
    }
   ],
   "source": [
    "ff = flowField()\n",
    "ff1 = ff.view1d()\n",
    "ff1[:] = 1.\n",
    "print('ff[0]-ff1[0]:',ff.view1d()[0]-ff1[0]) # Checking if copies are made when viewing\n",
    "print('ff[0,0,0,0,0]-ff1[0]:',ff[0,0,0,0,0]-ff1[0])\n",
    "\n",
    "ff2 = ff.slice(M= -8)\n",
    "arr1 = ff.real()\n",
    "print('Type of arr1: ',type(arr1),'shape of arr1:',arr1.shape)\n",
    "\n",
    "\n",
    "ff3 = flowField(arr= np.real(ff.copyArray()))\n",
    "print(type(ff3))\n",
    "print(type(ff.ddx))\n",
    "print(type(ff.ddx()))\n",
    "print(ff.ddx().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 47, 24, 1, 35)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 3 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-61adef906d84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mff\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview4d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mff\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview4d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 3 with size 1"
     ]
    }
   ],
   "source": [
    "print(ff.view4d().shape)\n",
    "type(ff.view4d()[:,:,:,1,:].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "temp = scipy.io.loadmat('data_seprn_1.5.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
