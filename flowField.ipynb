{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# flowField class for iterative solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from flowField import *\n",
    "from flowFieldWavy import *\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pdb\n",
    "import cProfile\n",
    "import time\n",
    "from pseudo import *\n",
    "from scipy.linalg import norm, svd\n",
    "from scipy.sparse.linalg import gmres, LinearOperator\n",
    "from lgmresCustom import lgmres\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run test_flowFieldWavy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def vecnorm2(vec,N):\n",
    "    m = vec.size//N\n",
    "    w = clencurt(N).reshape((1,N))\n",
    "    W = np.tile(w,(1,m))\n",
    "    tempVec = vec.reshape(vec.size,1)\n",
    "    tempVecConj = tempVec.conj().T\n",
    "    \n",
    "    vecNorm = np.sqrt(np.abs( np.dot( tempVecConj*W, tempVec ) ))\n",
    "    return vecNorm[0,0]\n",
    "\n",
    "#flowDict = tempDict\n",
    "finDifEps =1.0e-7\n",
    "def residual(xF,**kwargs):\n",
    "    #return (xF.slice(nd=[0,1,2]).residuals(pField=xF.getScalar(nd=3))[0]).appendField(xF.slice(nd=[0,1,2]).div())\n",
    "    #xTemp = xF.slice(L=xF.nx//2+2,M=xF.nz//2+2)\n",
    "    #xTemp = xF.slice(L=xF.nx//2+2)\n",
    "    xTemp = xF\n",
    "    resid = (xTemp.slice(nd=[0,1,2]).residuals(pField=xTemp.getScalar(nd=3),**kwargs)[0]).appendField(xTemp.slice(nd=[0,1,2]).div())\n",
    "    #return resid.slice(L=xF.nx//2,M=xF.nz//2)\n",
    "    return resid # .slice(L=xF.nx//2)\n",
    "\n",
    "\n",
    "def jacobian(x0,r0,arr):\n",
    "    xFF = weighted2ff(flowDict=x0.flowDict, arr=arr)\n",
    "    #vf = finDifEps*xFF.slice(nd=[0,1,2]) + x0.slice(nd=[0,1,2])\n",
    "    #pf = finDifEps*xFF.getScalar(nd=3) + x0.slice(nd=3)\n",
    "    #residual = vf.residuals(pField=pf)[0]\n",
    "    #residual= residual.appendField(vf.div())\n",
    "    \n",
    "    matVecProd = (residual(x0+finDifEps*xFF)-r0)/finDifEps\n",
    "    return matVecProd.weighted()\n",
    "\n",
    "\n",
    "\n",
    "searchArr = np.append(np.arange(0.,1.5),np.array([2.0]))\n",
    "searchArr = np.append(-searchArr[::-1],searchArr[1:])\n",
    "def lineSearch(x0,arr):\n",
    "    delFF = (weighted2ff(flowDict=x0.flowDict,arr=arr).view4d())\n",
    "    resArr = np.zeros(searchArr.size)\n",
    "    k = 0\n",
    "    for step in searchArr:\n",
    "        resArr[k] = residual(x0 + step*delFF).norm()\n",
    "        k +=1\n",
    "    # print(resArr)\n",
    "    optimalStep = searchArr[resArr.argmin()]\n",
    "    print('Optimal factor from line search is ', optimalStep)\n",
    "    return (x0 + optimalStep* delFF)\n",
    "\n",
    "searchArrFine = np.arange(-0.1,0.11,0.01)\n",
    "def lineSearchFine(x0,arr):\n",
    "    delFF = (weighted2ff(flowDict=x0.flowDict,arr=arr).view4d())\n",
    "    resArr = np.zeros(searchArrFine.size)\n",
    "    k = 0\n",
    "    for step in searchArrFine:\n",
    "        resArr[k] = residual(x0 + step*delFF).norm()\n",
    "            \n",
    "    print(resArr)\n",
    "    print(searchArrFine)\n",
    "    optimalStep = searchArrFine[resArr.argmin()]\n",
    "    print('Optimal factor from line search is ', optimalStep)\n",
    "    return (x0 + optimalStep* delFF)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda = 25.\n",
    "\n",
    "def solvePressure(vf):\n",
    "    # To impose BCs, I need to evaluate the diffusion and convection terms at the wall (along y)\n",
    "    convTerm  = vf.convNL()\n",
    "    convTermY = convTerm.getScalar(nd=1)\n",
    "    diffTermY = vf.getScalar(nd=1).laplacian()/vf.flowDict['Re']\n",
    "    tempTerm = -convTermY + diffTermY + lda*vf.getScalar(nd=1)\n",
    "    \n",
    "    RHSterm = -convTerm.div()\n",
    "    # Replacing all wall-entries with the appropriate BCs:\n",
    "    RHSterm[:,:,:,:,[0,-1]] = tempTerm[:,:,:,:,[0,-1]]\n",
    "    RHSterm = RHSterm.copyArray().reshape(vf.nx, RHSterm.size//vf.nx)\n",
    "\n",
    "    pArr = np.zeros((vf.nx,n),dtype=np.complex)\n",
    "    for lp in range(vf.nx):\n",
    "        pArr[lp] = np.dot(invDelBC[lp],RHSterm[lp])\n",
    "\n",
    "    _pf = diffTermY.zero()\n",
    "    _pf.view1d()[:] = pArr.reshape(pArr.size)\n",
    "    return _pf.view4d()\n",
    "\n",
    "def residualV2(vf):\n",
    "    _pf = solvePressure(vf)\n",
    "    return residual(vf.appendField(_pf)).slice(nd=[0,1,2])\n",
    "\n",
    "def jacobianV2(vf0,r0,arr):\n",
    "    vfCorr = weighted2ff(flowDict=vf0.flowDict, arr=arr)\n",
    "    matVecProd = (residualV2(vf0+finDifEps*vfCorr)-r0)/finDifEps\n",
    "    return matVecProd.weighted()\n",
    "\n",
    "def divFree(vf):\n",
    "    gz = vf.flowDict['eps']*vf.flowDict['beta']\n",
    "    vf[:,:,1:,1] += 1.j*gz*vf[:,:,:-1,2]\n",
    "    vf[:,:,:-1,1]-= 1.j*gz*vf[:,:,1: ,2]\n",
    "    return \n",
    "\n",
    "def jacobianV3(vf0,r0,arr):\n",
    "    vfCorrect = weighted2ff(flowDict=vf0.flowDict, arr=arr)\n",
    "    matVecProd = (residualV3(vf0+finDifEps*vfCorrect)-r0)/finDifEps\n",
    "    return matVecProd.weighted()\n",
    "\n",
    "def residualV3(vf):\n",
    "    convTerm = vf.convNL()\n",
    "    diffTerm = vf.laplacian()/vf.flowDict['Re']\n",
    "    \n",
    "    convTermY = convTerm.getScalar(nd=1)\n",
    "    diffTermY = vf.getScalar(nd=1).laplacian()/vf.flowDict['Re']\n",
    "    tempTerm = -convTermY + diffTermY + lda*vf.getScalar(nd=1)\n",
    "    \n",
    "    RHSterm = -convTerm.div()\n",
    "    # Replacing all wall-entries with the appropriate BCs:\n",
    "    RHSterm[:,:,:,:,[0,-1]] = tempTerm[:,:,:,:,[0,-1]]\n",
    "    RHSterm = RHSterm.copyArray().reshape(vf.nx, RHSterm.size//vf.nx)\n",
    "\n",
    "    pArr = np.zeros((vf.nx,n),dtype=np.complex)\n",
    "    for lp in range(vf.nx):\n",
    "        pArr[lp] = np.dot(invDelBC[lp],RHSterm[lp])\n",
    "\n",
    "    _pf = diffTermY.zero()\n",
    "    _pf.view1d()[:] = pArr.reshape(pArr.size)\n",
    "    \n",
    "    # Residual = d_t(u,v,w), without BCs imposed\n",
    "    residual = -_pf.view4d().grad() + diffTerm - convTerm\n",
    "    \n",
    "    if True:\n",
    "        return residual\n",
    "    # BCs on x and z momentum equations are the velocity BCs:\n",
    "    residual[:,:,:,0,[0,-1]] = -vf[:,:,:,0,[0,-1]]     # set d_t(u) = -u for all modes\n",
    "    residual[:,vf.nx//2,vf.nz//2,0,0 ] += 1.           # For (0,0) mode, set d_t(u) = +/-1 - u\n",
    "    residual[:,vf.nx//2,vf.nz//2,0,-1] += -1.\n",
    "    \n",
    "    residual[:,:,:,2,[0,-1]] -= -vf[:,:,:,2,[0,-1]]     # set d_t(w) = -w for all modes\n",
    "    \n",
    "    # BC on y-momentum is the divergence-free condition. Set the residual as -div(u,v,w) at y = +/- 1\n",
    "    vfDiv = vf.div()\n",
    "    residual[:,:,:,1,[0,-1]] -= -vfDiv[:,:,:,0,[0,-1]]\n",
    "    \n",
    "    return residual\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vF = h52ff(\"eq1.h5\")\n",
    "pF = h52ff(\"eq1_pressure.h5\",pres=True)\n",
    "x00 = vF.appendField(pF)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = pF.laplacian() + vF.convNL().div()\n",
    "vecnorm2(res[:,:,:,:,1:N-1], res.N-2), res.norm()/pF.laplacian().norm(), residual(x00).norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = pC.laplacian() + vF.convNL().div()\n",
    "res.norm(), vecnorm2(res[:,:,:,:,1:N-1], res.N-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pCNorm = np.zeros(pC.nx)\n",
    "for l in range(pC.nx):\n",
    "    pCNorm[l] = vecnorm2( np.dot(DelBC[l],pC[0,l].reshape(pC.size//pC.nx)) - RHSterm[l],  pC.N)\n",
    "\n",
    "print(np.sum(pCNorm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yRes = pC.ddy() - vF.getScalar(nd=1).laplacian()/vF.flowDict['Re']+ vF.convNL().getScalar(nd=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit vF.convNL()\n",
    "%timeit residualV3(vF)\n",
    "%timeit residual(x00)\n",
    "%timeit x00.slice(nd=[0,1,2]).residuals(pField=x00.getScalar(nd=3))\n",
    "xTemp = x00.slice(L=10,M=10)\n",
    "%timeit residual(xTemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = residualV3(vF)\n",
    "r[:,:,:,:,[0,-1]] = 0.\n",
    "r.div().norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vecnorm2(r.div()[:,:,:,:,1:-1], vF.N-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm(vF.div()[:,:,:,:,[0,-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#(solvePressure(vF)-pF).norm()\n",
    "pC = solvePressure(vF)\n",
    "\n",
    "pDiffNorm = np.zeros(vF.nx)\n",
    "\n",
    "for l in range(vF.nx):\n",
    "    pDiffNorm[l] = vecnorm2( np.dot( DelBC[l], pF[0,l].reshape(pF.size//pF.nx) ) \n",
    "                            - np.dot(DelBC[l], pC[0,l].reshape(pC.size//pC.nx)), pF.N)\n",
    "\n",
    "#for l in range(vF.nx):\n",
    "    #pDiffNorm[l] = vecnorm2( np.dot( DelNoBC[l], (pF[0,l]-pC[0,l]).reshape(pF.size//pF.nx) )  , pF.N)\n",
    "    \n",
    "    \n",
    "np.sum(pDiffNorm), pF.flowDict['eps']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vf = vF.copy()\n",
    "# To impose BCs, I need to evaluate the diffusion and convection terms at the wall (along y)\n",
    "convTerm  = vf.convNL()\n",
    "convTermY = convTerm.getScalar(nd=1)\n",
    "diffTermY = vf.getScalar(nd=1).laplacian()/vf.flowDict['Re']\n",
    "#tempTerm = -convTermY + diffTermY + lda*vf.getScalar(nd=1)\n",
    "tempTerm = diffTermY\n",
    "\n",
    "RHSterm = -convTerm.div()\n",
    "# Replacing all wall-entries with the appropriate BCs:\n",
    "RHSterm[:,:,:,:,[0,-1]] = tempTerm[:,:,:,:,[0,-1]]\n",
    "RHSterm = RHSterm.copyArray().reshape(vf.nx, RHSterm.size//vf.nx)\n",
    "\n",
    "pCNorm = np.zeros(vF.nx)\n",
    "for l in range(vF.nx):\n",
    "    pCNorm[l] = vecnorm2( np.dot( DelBC[l], pC[0,l].reshape(pF.size//pF.nx) ) - RHSterm[l] , pF.N)\n",
    "\n",
    "print(pCNorm)\n",
    "print(np.sum(pCNorm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "laplpF = pF.lapl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMRES using pressure solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vf0 = vF.copy()\n",
    "vf0.flowDict['eps'] = 0.00\n",
    "#divFree(vf0)\n",
    "\n",
    "startTime = time.time()\n",
    "r0 = residualV3(vf0)\n",
    "r0norm = r0.norm()\n",
    "print('$||r_0|| $',r0norm)\n",
    "for iter in range(1):\n",
    "    if r0norm < 1.0e-15: print('Norm below tolerance, exiting....',r0norm); break\n",
    "    jcbn = lambda arr: jacobianV3(vf0,r0,arr)\n",
    "    A = LinearOperator((vf0.size,vf0.size), matvec=jcbn,dtype=np.complex)\n",
    "    delX,W,V,H,flag = lgmres(A,-r0.weighted(),tol=1.0e-3,maxiter=1,inner_m=5,outer_k=0)\n",
    "    if flag: print('LGMRES did not converge...................................')\n",
    "    print('||Ax-b||:',norm(A.matvec(delX)+r0.weighted(),2))\n",
    "    print('||Ax-b||/||b||:',norm(A.matvec(delX)+r0.weighted(),2)/norm(r0.weighted(),2))\n",
    "    break\n",
    "    vf0 += weighted2ff(arr=delX,flowDict=vf0.flowDict)\n",
    "    r0 = residualV2(vf0)\n",
    "    print('New and old norms respectively:',r0.norm(), r0norm)\n",
    "    print('****************************')\n",
    "    r0norm = r0.norm()\n",
    "    \n",
    "print('Done........................................')    \n",
    "print('Time elapsed:',int(time.time()-startTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ffList = []\n",
    "for k in range(5):\n",
    "    vField = weighted2ff(arr=V[k], flowDict=vf0.flowDict)\n",
    "    ffList.append(vField)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vF.div().norm()\n",
    "res = residualV3(vf0)\n",
    "res.div().norm()/res.norm(), ffList[0].div().norm()/ffList[0].norm(), vf0.div().norm()/vf0.norm()\n",
    "vecnorm2(res.div()[:,:,:,:,1:-1], res.N-2)\n",
    "vecnorm2(ffList[3].div()[:,:,:,:,1:-1], res.N-2)\n",
    "#((res/res.norm()*ffList[0].norm()) + ffList[0]).norm()\n",
    "#ffList[0].div().norm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pressure Poisson solver: Inverse of Del operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating Del_{l} matrices (these don't include BCs on pressure)\n",
    "# Different Del_l matrices only differ by a -l^2 a^2 on the diagonal,\n",
    "#  so creating a base matrix that can generate them all later\n",
    "\n",
    "L = vf.nx//2; M= vf.nz//2; N=vf.N; n= vf.nz*vf.N\n",
    "ms = 1    # m_s in my equations, functionality to be added later\n",
    "DelBase = np.matrix( np.zeros((n,n+4*ms*N),dtype=np.complex)  )\n",
    "b = vf.flowDict['beta']; a = vf.flowDict['alpha']; eps = vf.flowDict['eps']\n",
    "gz = eps*b\n",
    "Ns = 2*ms*N           # Makes it easier to define matrix (because some modes are absent)\n",
    "\n",
    "for mp in range(vf.nz):\n",
    "    m = mp-M\n",
    "    # First, diagonal blocks corresponding to (m,m): (-m^2 b^2)I + (1+2g_z^2)D^2\n",
    "    DelBase[ N*mp: N*(mp+1), Ns+N*mp: Ns+N*mp+N ] = -(m*b)**2 * np.identity(N) + (1.+2.*gz**2) * vf.D2\n",
    "    \n",
    "    DelBase[ N*mp: N*(mp+1), Ns+N*(mp-2*ms): Ns+N*(mp-2*ms)+N ] = -gz**2 * vf.D2\n",
    "    DelBase[ N*mp: N*(mp+1), Ns+N*(mp+2*ms): Ns+N*(mp+2*ms)+N ] = -gz**2 * vf.D2\n",
    "    \n",
    "    DelBase[ N*mp: N*(mp+1), Ns+N*(mp-ms): Ns+N*(mp-ms)+N ] = ( 2*m-ms)*gz*b * vf.D\n",
    "    DelBase[ N*mp: N*(mp+1), Ns+N*(mp+ms): Ns+N*(mp+ms)+N ] = (-2*m-ms)*gz*b * vf.D\n",
    "\n",
    "DelBase = DelBase[:,Ns:-Ns]\n",
    "\n",
    "DelNoBC = np.zeros((vf.nx,n,n), dtype=np.complex)\n",
    "for lp in range(vf.nx):\n",
    "    l = lp-L\n",
    "    DelNoBC[lp] += DelBase\n",
    "    for mp in range(vf.nz):\n",
    "        DelNoBC[lp, N*mp: N*(mp+1), N*mp: N*(mp+1) ] += -(l*a)**2 * np.identity(N)\n",
    "\n",
    "D = vf.D\n",
    "\n",
    "# Applying Neumann BCs on Del:\n",
    "DelBC = DelNoBC.copy()\n",
    "for lp in range(vf.nx):\n",
    "    DelBC[lp, N*mp    , :  ] = 0.      # Setting equations at wall to 0.*p\n",
    "    DelBC[lp, N*(mp+1)-1, :  ] = 0.        \n",
    "    for mp in range(vf.nz):\n",
    "        DelBC[lp, N*mp    , N*mp: N*(mp+1) ] = D[0]           # Changing equations at wall to D*p_{l,m}\n",
    "        DelBC[lp, N*(mp+1)-1, N*mp: N*(mp+1) ] = D[-1]\n",
    "        # The RHS for D*p(y=wall) has to be set separately\n",
    "\n",
    "# DelBC is not dependent on the velocity field at all\n",
    "#   So, if I invert this once, that should be enough\n",
    "invDelBC = np.zeros(DelBC.shape, dtype=np.complex)\n",
    "for lp in range(vf.nx):\n",
    "    invDelBC[lp] = np.linalg.pinv(DelBC[lp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the DelNoBC and DelBC matrices with known pressure fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pExArr = pF.view4d().copyArray()\n",
    "pExArr = pExArr.reshape(vf.nx, pExArr.size//vf.nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pNorm = np.zeros(vf.nx)\n",
    "for l in range(vf.nx):\n",
    "    pNorm[l] = vecnorm2( np.dot(DelNoBC[l],pExArr[l]) - RHSterm[l], vf.N   )\n",
    "\n",
    "pNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(pfCustom.laplacian()+convTerm.div()).norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pLaplArr = pF.laplacian().copyArray().reshape(pF.nx, pF.size//pF.nx)\n",
    "pFArr = pF.view4d().copyArray().reshape(pF.nx, pF.size//pF.nx)\n",
    "for l in range(pF.nx):\n",
    "    pNorm[l] = vecnorm2( pLaplArr[l] - np.dot(DelNoBC[l],pFArr[l]), pF.N )\n",
    "\n",
    "pNorm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vf0.div().norm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using numpy arrays for gmres instead of flowFieldWavy\n",
    "If I do that, I can use scipy's gmres and other routines. The plan is this- supply weighted np.ndarray copies of flowFieldWavy instances, and when the Jacobian matvec needs to be computed, make a flowField instance (actually, just assign to an existing instance) out of the array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit residual(x0,fft=True)\n",
    "%timeit residual(x0,fft=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#x0 = x00.slice(L=7,M=7)\n",
    "x0 = x0.slice(L=15,M=15)\n",
    "x0.flowDict['eps'] = 0.000\n",
    "\n",
    "#x0 = x00.copy()\n",
    "#x0[:]=0.; x0[0,x0.nx//2,x0.nz//2,0] = 1.-x0.y**2\n",
    "startTime = time.time()\n",
    "r0 = residual(x0)\n",
    "r0norm = r0.norm()\n",
    "print('$||r_0|| $',r0norm)\n",
    "for iter in range(1):\n",
    "    if r0norm < 1.0e-15: print('Norm below tolerance, exiting....',r0norm); break\n",
    "    jcbn = lambda arr: jacobian(x0,r0,arr)\n",
    "    A = LinearOperator((x0.size,x0.size), matvec=jcbn,dtype=np.complex)\n",
    "    delX,W,V,H,flag = lgmres(A,-r0.weighted(),tol=1.0e-3,maxiter=1,inner_m=100,outer_k=0)\n",
    "    if flag: print('LGMRES did not converge...................................')\n",
    "    print('||Ax-b||/||b||:',norm(A.matvec(delX)+r0.weighted(),2)/norm(r0.weighted(),2))\n",
    "    #break\n",
    "    #print('||del X||:',norm(delX,2))\n",
    "    x0[:] = lineSearch(x0,delX)\n",
    "    r0 = residual(x0)\n",
    "    print('New and old norms respectively:',r0.norm(), r0norm)\n",
    "    print('****************************')\n",
    "    r0norm = r0.norm()\n",
    "    \n",
    "print('Done........................................')    \n",
    "print('Time elapsed:',int(time.time()-startTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Verify that V[:-1] == W\n",
    "print('Is V[:-1] the same as W?:',(V[:-1]-W ==0).all())\n",
    "\n",
    "# Verify Orthonormality of vectors in V and W:\n",
    "testTol = 1.0e-12\n",
    "dotMat = np.dot(W, W.T.conj())\n",
    "norm2Arr = dotMat.diagonal().copy()\n",
    "np.fill_diagonal(dotMat, 0.)\n",
    "dotSum = np.sum( np.sum( np.abs(dotMat), axis=0  ), axis=0)/(W.shape[0]**2)\n",
    "print('Is the basis orthogonal?',dotSum<=testTol)\n",
    "print('Are basis vectors unit vectors?:',(np.abs(norm2Arr-1.) <= testTol).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save flowFieldRiblet object to binary file whenever happy with the residual norm\n",
    "x00 = x0.copy()\n",
    "np.save('eq1Wavy1.npy',x00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xTemp = np.load('eq1Custom.npy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x00[:] = xTemp\n",
    "residual(x00).norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Writing to hdf5 format to run in channel flow\n",
    "#    Simplest way to go about this would be to load a h5 file and then change one of its entries.\n",
    "\n",
    "# First, ordering my array in the way the h5 files are written\n",
    "# They need to be written in physical, and ordered as component, x, y, z\n",
    "# I'll simply reverse whatever I did in the h52ff function of flowFieldWavy module\n",
    "\n",
    "x = x00.slice(L=16,M=16).copy()\n",
    "x[0,16,16,0] -= x.y\n",
    "nx = x.nx; nz=x.nz; N= x.N\n",
    "# Split up components first, and then put them on axis 0:\n",
    "v1SpecArr = x.getScalar().copyArray().reshape((1,nx,nz,N))\n",
    "v2SpecArr = x.getScalar(nd=1).copyArray().reshape((1,nx,nz,N))\n",
    "v3SpecArr = x.getScalar(nd=2).copyArray().reshape((1,nx,nz,N))\n",
    "vSpecArr = np.concatenate( (v1SpecArr, v2SpecArr, v3SpecArr), axis=0 )\n",
    "\n",
    "# Do ifft to get to physical\n",
    "# numpy likes it when the modes go 0,1,..,N-1, -N, -N+1,.., -1: There's no +N\n",
    "# Dropping the largest positive modes\n",
    "vSpecArr = vSpecArr[:,:-1,:-1] ; nx -= 1; nz -= 1;\n",
    "vPhysArr = np.real(  np.fft.ifftn(  np.fft.ifftshift(vSpecArr, axes=[1,2]), axes=[1,2] ) * nx*nz  )\n",
    "\n",
    "# Finally, reordering from x,z,y to x,y,z:\n",
    "vT = np.zeros((3,nx,N,nz))\n",
    "for k in range(nz):\n",
    "    vT[:,:,:,k] = vPhysArr[:,:,k]\n",
    "\n",
    "# vT is ready to go into the h5 file. \n",
    "# Reading an h5 file so I don't have to define too many things:\n",
    "h5File = h5py.File('eq1Custom.h5','r+')\n",
    "# h5File has all the data stored as the appropriate structure\n",
    "# I only need to modify the velocity vector before saving to a different file\n",
    "uh5 = h5File['data']['u']\n",
    "uh5[...] = vT\n",
    "h5File.close()\n",
    "\n",
    "hFile = h5py.File('eq1Custom.h5','r')\n",
    "uT = np.array(hFile['data']['u'])\n",
    "norm( (uT-vT).reshape(vT.size)   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifying H and W are consistent with A \n",
    "* Ax = b\n",
    "\n",
    "Since numpy likes populating the last dimension first, the basis vectors are stored as rows of V and W instead of columns \n",
    "* H is the Hessenberg matrix, and  A V.T = W.T H\n",
    "* A is of size m,m\n",
    "* V is of size m,n\n",
    "* W is of size m,n-1\n",
    "* H is of size n-1,n\n",
    "\n",
    "The k^th column of H gives the components of the A*V[:,k] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First, verifying that V[:,:-1] and W are the same matrix\n",
    "\n",
    "\n",
    "Q = W.conj().T\n",
    "Qm1 = Q[:,:-1]\n",
    "tmpMat = A.matvec(Q)\n",
    "norm( A.matvec(Q[:,0]) - np.dot(Q,H)[:,0], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locally constrained Hookstep: Part 1\n",
    "\n",
    " Channelflow.org uses the following convention for GMRES/Hookstep of Ax=b:\n",
    "*    Q_n-1, Q_n: Arnoldi basis vector spaces\n",
    "*    H_n : Hessenberg matrix such that A*Q_n = Q_n-1 * H\n",
    "*    U D V* = H_n, the SVD of H_n\n",
    "*    \\hat{b} = U* b\n",
    "*    s = Q_n* x = Components of the correction 'x' along the basis Q_n\n",
    "*       's' is the vector that needs to be computed\n",
    "*    \\hat{s} = V* s\n",
    "*    \\hat{s} is given as \n",
    "*        \\hat{s}_i = (\\hat{b}_i d_i)/(d_i^2 + \\mu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "delta = 1.0e-9\n",
    "# Trust-region radius, needs to be actively modified\n",
    "\n",
    "b = -r0.weighted()\n",
    "assert b.size == W.shape[1]\n",
    "UMat, dArr, VHMat = svd(H.T)\n",
    "assert dArr.ndim == 1\n",
    "bHat = np.dot( UMat.conj().T, np.dot(W.conj(),b) )\n",
    "\n",
    "sHat = lambda mu: bHat*dArr/(dArr**2 + mu )\n",
    "\n",
    "# Important: I must ensure that mu is a positive scalar\n",
    "phi = lambda mu: norm( sHat(mu), 2 )**2 - delta**2\n",
    "phiPrime = lambda mu: -2.* np.sum(  sHat(mu)**2/(dArr**2+mu)   )\n",
    "\n",
    "# Need to run a modified Newton's search on phi(mu) = 0 \n",
    "mu = 1.\n",
    "tol = 1.0e-14\n",
    "nIter = 15\n",
    "muArr = np.zeros(nIter)\n",
    "print('beginning Newton search for mu...........')\n",
    "for k in range(nIter):\n",
    "    muArr[k] = mu\n",
    "    if np.abs(phi(mu)) <= tol: \n",
    "        print('Newton iterations for mu have converged for k =',k)\n",
    "        break\n",
    "    mu = mu - norm( sHat(mu),2)/delta*phi(mu)/phiPrime(mu)\n",
    "    if mu < 0.: \n",
    "        print('mu has gone negative, setting it to zero..')\n",
    "        mu = 0.\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sHat(mu).shape, VHMat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## FFT and Convolution of spectral coefficients for 1-D arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.signal as sig\n",
    "def fftMan(y,x): # Manual DFT\n",
    "    if y[-1]==y[0]: _y = y[:-1]; _x=x[:-1]\n",
    "    else: _y = y; _x = x\n",
    "    global alpha\n",
    "    N = _y.size//2\n",
    "    coeffs = np.zeros(2*N+1, dtype=np.complex)\n",
    "    for k in range(-N,N+1):\n",
    "        coeffs[N+k] = np.dot( _y,np.exp(-1.j*k*alpha*_x) )\n",
    "    \n",
    "    coeffs = coeffs/_y.size\n",
    "    \n",
    "    if norm(np.imag(y)) == 0.: return np.real(coeffs)\n",
    "    return coeffs\n",
    "    \n",
    "def ifftMan(y,x): # Manual inverseDFT\n",
    "    assert y.size//2 != 0.\n",
    "    _y = y\n",
    "        \n",
    "    global alpha\n",
    "    N = _y.size//2\n",
    "    phys = np.zeros(2*N,dtype=np.complex)\n",
    "    for k in range(-N,N+1):\n",
    "        phys += _y[N+k]*np.exp(1.j*k*alpha*x) \n",
    "    \n",
    "    return np.real(phys)\n",
    "\n",
    "def convMan(y1,y2): # convolution: pad zeros on both sides, do convolution, return middle part\n",
    "    # I'm supposing the convolution is on the spectral coeffs\n",
    "    N = y1.size//2\n",
    "    zArr = np.zeros(N,dtype=np.complex)\n",
    "    \n",
    "    res = np.zeros(y1.size+2*N, dtype=np.complex)\n",
    "    \n",
    "    for k1 in range(-N,N+1):\n",
    "        for k2 in range(-N,N+1):\n",
    "            res[2*N+k1+k2] += y1[N+k1] * y2[N+k2]\n",
    "    \n",
    "    return res[N:N+y1.size]\n",
    "\n",
    "def npfft(x):\n",
    "    assert x.size//2 != 0., \"Numpy's fft only works well on [0,2*pi), i.e., when 2*pi is not included\"\n",
    "    c = np.fft.fftshift(np.fft.fft(x))/x.size\n",
    "    c = np.append(c,np.conj(c[0]))\n",
    "    if norm(np.imag(c),2)/c.size<= 1.0e-14: return np.real(c)\n",
    "    return c\n",
    "\n",
    "def npifft(x):\n",
    "    assert x.size//2 != 0., \"Coefficient vector must have modes -N through +N, including +N\"\n",
    "    c = np.fft.ifft(np.fft.ifftshift(  x[:-1]*(x.size-1)    ))\n",
    "    assert norm(np.imag(c),2)/c.size<=1.0e-14, \"I only use real fields, so ifft should not have any imaginary parts\"\n",
    "    return np.real(c)\n",
    "\n",
    "def npconvolve(x,y):\n",
    "    return np.convolve(x,y,mode='same')\n",
    "\n",
    "def isZero(x):\n",
    "    return not (np.abs(x)>1.0e-14).any()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Testing convolution theorem: convolve(F(y1),F(y2)) = F(y1*y2)\n",
    "N = 5; A = 2.; alpha = 3.; M = -1\n",
    "x = (np.arange(-N,N)+N)/N*np.pi/alpha # x goes from -pi/alpha to pi/alpha (pi/alpha not included)\n",
    "y1 = A*np.cos(M*alpha*x)\n",
    "y2 = 2.*A*np.cos((M+1)*alpha*x)\n",
    "\n",
    "c1 = npfft(y1)\n",
    "c2 = npfft(y2)\n",
    "\n",
    "#print(npfft(y1))\n",
    "print(\"Does npfft comply with convolution theorem, convolution in spectral?:\", isZero(npconvolve(npfft(y1),npfft(y2))-npfft(y1*y2))                  )\n",
    "print(\"Does npfft match fftMan?:\", isZero(fftMan(y1,x)-npfft(y1))                  )\n",
    "print(\"Is ifftMan consistent with fftMan?:\", isZero( ifftMan(fftMan(y1,x),x)-y1  ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensure npfft and npifft (both custom functions) are consistent with each other\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First, showing that numpy's routines are self-consistent\n",
    "print(\"Are numpy's fft and ifft self-consistent?:\",isZero(np.fft.ifft(np.fft.fft(y1)) - y1))\n",
    "\n",
    "# Now, let's see compare what ifftshift to two things:\n",
    "#   1. ifftshift(fftshift(np.fft.fft))\n",
    "#   2. ifftshift(npfft)   - This one is the function I wrote where I append\n",
    "#       the coefficient for mode +N as the complex conjugate of mode -N:\n",
    "c1 = npfft(y1)\n",
    "cp1 = np.fft.fftshift(np.fft.fft(y1))\n",
    "if False:\n",
    "    print(\"ifftshift on custom function:\",np.fft.ifftshift(c1))\n",
    "    print(\"ifft of custom function:\", np.real(np.fft.ifft(np.fft.ifftshift(c1*(c1.size)))))\n",
    "    print(\"ifft of numpy's fft:\", np.real(np.fft.ifft(np.fft.ifftshift(cp1))))\n",
    "    print(\"Original function y1:\",y1)\n",
    "    print(\"ifft of custom function, ignoring +N mode:\", np.real(np.fft.ifft(np.fft.ifftshift(c1[:-1]*(c1.size-1)))))\n",
    "\n",
    "    print(\"Are npfft and npifft consistent with each other?\", isZero(npifft(npfft(y1))-y1) and isZero( npifft(npfft(y2))-y2 )   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Checking if sp.fftconvolve gives the same results\n",
    "N = 50 \n",
    "x = (np.arange(-N,N)+0.5)/N*np.pi/alpha # x goes from -pi/alpha to pi/alpha (pi/alpha not included)\n",
    "y1 = A*np.cos(M*alpha*x)\n",
    "y2 = 2.*A*np.cos((M+1)*alpha*x)\n",
    "c1 = npfft(y1)\n",
    "c2 = npfft(y2)\n",
    "\n",
    "print(\"Comparing performance of np.convolve, scipy.signal.convolve, scipy.signal.fftconvolve, and my custom functions at N=\",N)\n",
    "print(\"****************** \\n np.convolve:\")\n",
    "%timeit np.convolve(c1,c2,mode='same')\n",
    "print(\"****************** \\n sig.convolve:\")\n",
    "%timeit sig.convolve(c1,c2,mode='same')\n",
    "print(\"***************** \\n sp.signal.fftconvolve:\")\n",
    "%timeit sig.fftconvolve(c1,c2, mode='same')\n",
    "print(\"***************** \\n npfft and npifft:\")\n",
    "%timeit npfft(npifft(c1)*npifft(c2))\n",
    "\n",
    "\n",
    "N = 500 \n",
    "x = (np.arange(-N,N)+0.5)/N*np.pi/alpha # x goes from -pi/alpha to pi/alpha (pi/alpha not included)\n",
    "y1 = A*np.cos(M*alpha*x)\n",
    "y2 = 2.*A*np.cos((M+1)*alpha*x)\n",
    "c1 = npfft(y1)\n",
    "c2 = npfft(y2)\n",
    "\n",
    "print(\"\\n\\nComparing performance of np.convolve, scipy.signal.convolve, scipy.signal.fftconvolve, and my custom functions at N=\",N)\n",
    "print(\"Do np.convolve and sp.fftconvolve give the same result?:\", \n",
    "      isZero(np.convolve(c1,c2,mode='same')- sig.fftconvolve(c1,c2,mode='same'))  )\n",
    "print(\"Do np.convolve and custom convolve give the same result?:\", \n",
    "      isZero( np.convolve(c1,c2,mode='same')- npfft(npifft(c1)*npifft(c2)) )  )\n",
    "print(\"Do np.convolve and scipy.signal.convolve give the same result?:\", \n",
    "      isZero( np.convolve(c1,c2,mode='same')- sig.convolve(c1,c2,mode='same') )  )\n",
    "\n",
    "\n",
    "print(\"****************** \\n np.convolve:\")\n",
    "%timeit np.convolve(c1,c2,mode='same')\n",
    "print(\"****************** \\n sig.convolve:\")\n",
    "%timeit sig.convolve(c1,c2,mode='same')\n",
    "print(\"***************** \\n sp.signal.fftconvolve:\")\n",
    "%timeit sig.fftconvolve(c1,c2, mode='same')\n",
    "print(\"***************** \\n npfft and npifft:\")\n",
    "%timeit npfft(npifft(c1)*npifft(c2))\n",
    "\n",
    "\n",
    "N = 25000 \n",
    "x = (np.arange(-N,N)+0.5)/N*np.pi/alpha # x goes from -pi/alpha to pi/alpha (pi/alpha not included)\n",
    "y1 = A*np.cos(M*alpha*x)\n",
    "y2 = 2.*A*np.cos((M+1)*alpha*x)\n",
    "c1 = npfft(y1)\n",
    "c2 = npfft(y2)\n",
    "\n",
    "print(\"\\n\\nComparing performance of np.convolve, scipy.signal.convolve, scipy.signal.fftconvolve, and my custom functions at N=\",N)\n",
    "print(\"****************** \\n np.convolve:\")\n",
    "%timeit np.convolve(c1,c2,mode='same')\n",
    "print(\"****************** \\n sig.convolve:\")\n",
    "%timeit sig.convolve(c1,c2,mode='same')\n",
    "print(\"***************** \\n sp.signal.fftconvolve:\")\n",
    "%timeit sig.fftconvolve(c1,c2, mode='same')\n",
    "print(\"***************** \\n npfft and npifft:\")\n",
    "%timeit npfft(npifft(c1)*npifft(c2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figuring out how np.fft.fftn and np.fft.ifftn work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Nx = 3; Nz = 3\n",
    "A = 2.; \n",
    "alpha = 3.; L = 2; beta= 1.5; M= 1\n",
    "#y = vF.y; \n",
    "y = np.array([-1.,-0.3,0.3,1.])\n",
    "y=y.reshape((1,1,y.size))\n",
    "x = (np.arange(-Nx,Nx)+Nx)/Nx*np.pi/alpha # x goes from -pi/alpha to pi/alpha (pi/alpha not included)\n",
    "z = (np.arange(-Nz,Nz)+Nz)/Nz*np.pi/beta\n",
    "x = x.reshape((x.size,1,1))\n",
    "z = z.reshape((1,z.size,1))\n",
    "\n",
    "f1 = A*np.cos(L*alpha*x + M*beta*z)*(1.-y**2)\n",
    "f2 = A*np.cos(alpha*x + 2*beta*z)*(1.-y**4)\n",
    "print(f1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The following code works\n",
    "cp1 = np.fft.fftn(f1,axes=[0,1])/f1.size*4\n",
    "c1 = np.fft.fftshift(cp1, axes=[0,1])\n",
    "c1 = c1[1:,1:]\n",
    "\n",
    "#np.real(np.fft.fftn(f1,axes=[0,1]))/f1.size\n",
    "np.real(c1[:,:,1]/(1.-0.3*0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s1 = np.zeros((7,7,4), dtype=np.complex)\n",
    "s1[1,2] = A/2.\n",
    "s1[5,4] = A/2.\n",
    "s1[:] *= 1.-y**2\n",
    "\n",
    "s1 = s1[:-1,:-1]\n",
    "\n",
    "%timeit p1 = np.fft.ifftn(  np.fft.ifftshift(s1,axes=[0,1]), axes=[0,1] )*(s1.shape[0]*s1.shape[1])\n",
    "\n",
    "#c1[:,:,1], s1[1:,1:,1]\n",
    "isZero(p1- f1)\n",
    "norm((p1-f1).reshape(p1.size),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution and FFT for 2-d arrays, Fourier-spectral on axis 0\n",
    "\n",
    "This is the intermediate step before I finally move to my flowField objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convMan(ff1,ff2):\n",
    "    \"\"\"Returns convolution of flowField instances ff1 and ff2 along x and z as a 3d numpy array\n",
    "    The assumption here is that they're both in spectral. \n",
    "    Convolution is computed by first doing an ifft of both arrays along axes given by argument axes,\n",
    "        the arrays in physical space are multiplied, and the result is then fft'd\n",
    "    I use numpy's fft, which is a bit unintuitive. I have to pad ff1 and ff2 before the ifft\"\"\"\n",
    "    assert (ff1.nd==1) and (ff2.nd==1)\n",
    "    # Padding with an extra wavenumber on both dimensions, this will be discarded later\n",
    "    _f1 = ff1.slice(L=ff1.nx//2+1, M=ff1.nz//2+1)\n",
    "    _f2 = ff2.slice(L=ff2.nx//2+1, M=ff2.nz//2+1)\n",
    "    \n",
    "    # Discarding the last positive modes, because numpy's fft doesn't like it if it was in there\n",
    "    _f1 = _f1.view4d().copyArray()\n",
    "    _f2 = _f2.view4d().copyArray()\n",
    "    _f1 = _f1[0,:-1,:-1,0]\n",
    "    _f2 = _f2[0,:-1,:-1,0]\n",
    "    \n",
    "    # Arranging modes in the order that numpy's fft likes, obtaining array in physical space\n",
    "    ph1 = np.fft.ifftn(  np.fft.ifftshift(_f1, axes=[0,1]), axes=[0,1]  )*(_f1.shape[0]*_f1.shape[1])\n",
    "    ph2 = np.fft.ifftn(  np.fft.ifftshift(_f2, axes=[0,1]), axes=[0,1]  )*(_f1.shape[0]*_f1.shape[1])\n",
    "    \n",
    "    # Convolution as product in physical space\n",
    "    prod = ph1*ph2\n",
    "    \n",
    "    # Convolution by fft'ing product, and then shifting to the ordering I like\n",
    "    conv = np.fft.fftshift(  np.fft.fftn(prod,axes=[0,1]), axes=[0,1] )/(_f1.shape[0]*_f1.shape[1])\n",
    "    \n",
    "    # Removing the last negative mode, which I only padded in.\n",
    "    conv = conv[1:,1:]\n",
    "    \n",
    "    return conv      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#vF = mapData2ff(eps=0.01, g=0.8, Re=100., theta=0)[0]\n",
    "vF = vf.copy()\n",
    "#vF[:,:,:,1:] = 0.\n",
    "u = vF.getScalar(); v=vF.getScalar(nd=1); w=vF.getScalar(nd=2)\n",
    "\n",
    "%timeit vF.convNL().getScalar().view4d().copyArray()\n",
    "convClassArr = vF.convNL().getScalar().view4d().copyArray()\n",
    "convClassArr = convClassArr[0,:,:,0]\n",
    "\n",
    "%timeit convMan(u,u.ddx())\n",
    "convCustom = convMan(u,u.ddx()) + convMan(v,u.ddy()) + convMan(w,u.ddz())       \n",
    "    \n",
    "diff = convClassArr - convCustom\n",
    "print(norm(convCustom.reshape(convCustom.size)), norm(diff.reshape(diff.size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#(vf.convNL(fft=False) - vf.convNL()).norm()\n",
    "start = time.time()\n",
    "conv1= vf.convNL()\n",
    "stop = time.time()\n",
    "print(stop-start)\n",
    "conv2 = vf.convNL(fft=False)\n",
    "print(time.time()-stop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y = np.append(y1.reshape((y1.size,1)),y2.reshape((y2.size,1)),axis=1)\n",
    "C = npfft2d(Y)\n",
    "\n",
    "isZero(npconvolve2d(C,C) - npfft2d(Y*Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr = np.array([0,1,2,3,-3,-2,-1]).reshape((7,1))\n",
    "arr = arr*arr.reshape((1,7))\n",
    "print(arr)\n",
    "np.fft.fftshift(arr, axes=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using scipy.signal.convolve2d (for each wall-normal node) to do the convolution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#vF = mapData2ff(eps=0.02,g=0.8,Re=100.,theta=0)[0]\n",
    "vF = vf.copy()\n",
    "vF[:,:,:,1:] = 0.\n",
    "u = vF.getScalar()\n",
    "uArr = u.view4d().copyArray(); duArr = u.ddx().view4d().copyArray()\n",
    "\n",
    "uArr = uArr[0,:,:,0]; duArr = duArr[0,:,:,0]\n",
    "\n",
    "%timeit vF.convNL().getScalar().view4d().copyArray()\n",
    "convClassArr = vF.convNL().getScalar().view4d().copyArray()\n",
    "print(convClassArr.shape)\n",
    "convClassArr = convClassArr[0,:,:,0]\n",
    "\n",
    "        \n",
    "convConvolve = uArr.copy(); \n",
    "%timeit [sig.convolve2d(uArr[:,:,k],duArr[:,:,k],mode='same') for k in range(vF.N)] \n",
    "\n",
    "%timeit sig.convolve2d(uArr[:,:,5],duArr[:,:,5])\n",
    "\n",
    "for k in range(vF.N): \n",
    "    convConvolve[:,:,k] = sig.convolve2d(uArr[:,:,k],duArr[:,:,k],mode='same') \n",
    "    \n",
    "diff = convClassArr - convConvolve\n",
    "print(norm(convConvolve.reshape(convConvolve.size)), norm(diff.reshape(diff.size)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit vf.slice(L=vf.nx//2+1,M=vf.nz//2+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = h5py.File(\"eq1_pressure.h5\",'r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = np.array(f['data']['u'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for name in f['geom']: print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vF = h52ff('eq1.h5')\n",
    "pF = h52ff('eq1_pressure.h5',pres=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x0 = vF.appendField(pF)\n",
    "res = residual(x0)\n",
    "res.norm()*Lx*Lz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm(res.view1d(),2)/Lx/Lz/2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ffArr = x0.copyArray().reshape((x0.size//N,N))\n",
    "for k in range(x0.size//N):\n",
    "    ffArr[k] = chebcoeffs(ffArr[k])\n",
    "    #ffArr[k,-1] = 0.\n",
    "    ffArr[k] = chebcoll_vec(ffArr[k])\n",
    "\n",
    "x=x0.copy()\n",
    "x.view1d()[:] = ffArr.reshape(ffArr.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vFluct = vF.copy()\n",
    "vFluct[0,23,23,0] -= vFluct.y\n",
    "vFluct.norm()*Lx*Lz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vFluctPhys = np.fft.ifftn(  np.fft.ifftshift(vFluct.view4d().copyArray()[:,:-1,:-1], axes=[1,2]), axes=[1,2] )*46.*46.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm(vFluctPhys.reshape(vFluctPhys.size), 2)/Lx/Lz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Lx = 2.*np.pi/vFluct.flowDict['alpha']\n",
    "Lz = 2.*np.pi/vFluct.flowDict['beta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm(vFluct.view1d(),2)/Lx/Lz/2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ff = vF.slice(L=0,M=0,N=3,nd=[0])\n",
    "w = clencurt(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ff[:] = np.array([1.,1.,1.])\n",
    "ff.norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm(vFluct.view1d(),2)/Lx/Lz/2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
