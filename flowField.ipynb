{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# flowField class for iterative solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "- Subclass of numpy.ndarray()\n",
    "\n",
    "### Basic flow descriptors\n",
    "Define as a dictionary:\n",
    "* $ \\alpha, \\beta $  describing the periodicity, and $Re$\n",
    "* K,L,M,N describing the resolution:\n",
    "    - K: No. of temporal frequencies\n",
    "    - L: No. of positive streamwise Fourier modes\n",
    "    - M: No. of positive spanwise Fourier modes\n",
    "    - N: No. of Chebyshev collocation nodes in wall-normal \n",
    "    - The total size of each variable would be (2L+1)(2M+1)N\n",
    "* Flow type: Couette or Poiseuille (use flags)- default to Couette\n",
    "    - Boundary conditions on $u_0$\n",
    "    - dPdx\n",
    "    \n",
    "### Values\n",
    "* The classes are a subclass of np.ndarray. So the values of the flowField can be directly accessed through the name of the instance. But this is not recommended unless one's absolutely sure about what they're doing. Class methods should be used as much as possible, and if doing something with the arrays outside of the methods, the accompanying dictionaries should also be appropriately modified.\n",
    "    - Store only fluctuations\n",
    "    - Define a separate $u_{base}$ based on `isPois` when the base flow is needed. \n",
    "\n",
    "\n",
    "### Methods to be defined\n",
    "* Viewers: \n",
    "    - self.view1d(): 1D array for state\n",
    "    - self.view4d(): 4D array (streamwise, spanwise, variable ID, wall-normal)\n",
    "* Verification:  self.verify()\n",
    "    - Check that the dictionary `flowDict` has all the required parameters\n",
    "    - Check that the parameters are consistent with the size of the np.ndarray\n",
    "    - Check that appropriate modes are complex conjugates\n",
    "* Slicing: self.slice()\n",
    "    - Return only a subset of Fourier modes (centered at (K,L,M) = (0,0,0) )\n",
    "    - Extend the flowField by adding zero modes for higher wavenumbers\n",
    "* Dot product of flow fields: chi1.dot(chi2)\n",
    "    - Defined as $\\int_0^T\\int_\\forall (u_1\\bar{u_2} + v_1 \\bar{v_2} + w_1 \\bar{w_2}) dx dy dz dt$ \n",
    "    - Optional parameter to include the fourth field variable in the integration\n",
    "* Norm: self.norm()\n",
    "    - self.norm() = sqrt( self.dot(self)) \n",
    "* physical: self.physical(fileName)\n",
    "    - Print field on Cartesian coordinates to file\n",
    "    - Set defaults for optional parameters `xsteps,ysteps,zsteps,tsteps` based on number of Fourier and Chebyshev modes in the flowField. Prints fields at different times to different files\n",
    "    \n",
    "## Inputs\n",
    "* Flow descriptors (see above)\n",
    "    - Keep $ \\alpha, \\beta, Re$ as optional parameters, default values being those used in ChannelFlow: (1.14,2.5,400)\n",
    "    * Resolution: L,M,N    \n",
    "* Base flow type (flag):\n",
    "    - Either linear, or quadratic. Assume linear as default. \n",
    "* Read from file- optional (flag):\n",
    "    - Filename, format ('mat', 'npy', 'asc',...)\n",
    "* Noise levels (default to zero):\n",
    "    - Add random noise to the state vector whose norm is that as input.\n",
    "\n",
    "## Tests for class\n",
    "* Ensure that solving for flat-walled Couette and Poiseuille flows using direct inversion works\n",
    "* Ensure that the above cases work with iterative solver. \n",
    "\n",
    "### Other notes to self:\n",
    "* Write doc-strings for all the methods and inputs\n",
    "* When initializing flowField as white-noise, think about smoothening the noise. Do this by using random coefficients for fields in Chebyshev spectral, and then transform to collocation nodes. Put more of the energy into lower Cheb modes and lower Fourier modes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborator comments\n",
    "Use this cell for comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "---------------------------------------------------\n",
    "\n",
    "## Inheriting numpy.ndarray()\n",
    "\n",
    "Reference: http://docs.scipy.org/doc/numpy/user/basics.subclassing.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class C(np.ndarray): pass\n",
    "\n",
    "arr = np.zeros(3,)\n",
    "c_arr = arr.view(C)\n",
    "\n",
    "print(type(arr))\n",
    "print(type(c_arr))\n",
    "print(c_arr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v= c_arr[:]\n",
    "print(type(v))\n",
    "\n",
    "v is c_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(type(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(dir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(c_arr)\n",
    "v[1]=5.\n",
    "print(c_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v == c_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to be careful when using `is`. It refers to the IDs of objects. If using arrays or elements of arrays, using `is` is a bad idea. Stick to `==` when comparing numerical values- which is usually all I care for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen = np.zeros(3,)\n",
    "v1 = gen[:]\n",
    "print(v1 is gen)\n",
    "v1[1]=3.\n",
    "print(gen)\n",
    "print(gen[:] is gen)\n",
    "print(id(gen))\n",
    "print(id(gen[:]))\n",
    "v2 = gen\n",
    "print (v2 is gen)\n",
    "print (id(v2))\n",
    "print(v1 == gen)\n",
    "print (v1[0] is gen[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Reading files into dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "defaultDict = {'alpha':1.14, 'beta' : 2.5, 'omega':0.0, 'L': 0.0, 'M': 0.0, 'N': 0.0, 'K':0.0,\n",
    "               'ReLam': 400.0, 'isPois':0.0, 'noise':0.0 , 'testvar':5.5}\n",
    "for key in defaultDict:\n",
    "    if key not in flowDict:\n",
    "        flowDict[key] = defaultDict[key]\n",
    "        print(key,flowDict[key],type(flowDict[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining flowField class that inherits np.ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For starters, defining the class to initialize an empty ndarray along with a dictionary provided during initialization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to verify that the dictionary being supplied has all the info I need to go with a flowField class. But, I can't verify this all the time. This is how I'll deal with it: \n",
    "* Verify the dictionary only when constructing a flowField class. So, that's when\n",
    "    - Explicitly constructing an instance of the class\n",
    "    - Viewing a given array as an instance of the class\n",
    "* When slicing an array of the flowField class (to obtain another instance of the class), don't bother with the check. \n",
    "\n",
    "Basically, ensure every instance of the flowField class has a valid dictionary, and then stop worrying about it. \n",
    "\n",
    "So, we need a function that verifies the validity of dictionary, or creates one if one isn't supplied. The parameters required in the dictionary, and their defaults, are as follows:\n",
    "* alpha : 1.14    \n",
    "    *Wavenumber of fundamental streamwise Fourier mode*\n",
    "* beta :  2.5    \n",
    "    *Wavenumber of fundamental spanwise Fourier mode*\n",
    "* omega: 0.0    \n",
    "    *Fundamental frequency*\n",
    "* ReLam: 400.0  \n",
    "    *Reynolds number of the laminar base flow*\n",
    "* isPois: 0     \n",
    "    *Flag for base flow type. 0: Couette, 1: Poiseuille*\n",
    "* noise: 0.0    \n",
    "    *Norm of noise to be added to the flow*\n",
    "* L: 0          \n",
    "    *Number of (positive) harmonics of fundamental streamwise Fourier mode.*\n",
    "* M: 0          \n",
    "    *Number of (positive) harmonics of fundamental spanwise Fourier mode*\n",
    "* N: 35         \n",
    "    *Number of Chebyshev collocation nodes*\n",
    "* K: 0         \n",
    "    *Number of (positive) harmonics of fundamental frequency*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** For now, I'm ignoring the fact that np.ndarray can be viewed as a subclass. I'm defining the dictionary and checks in flowField.__new__(). Later, I'll have to move this to __array_finalize__ so that the dictionary is defined for cases when either an explicit constructor call is made or a view-casting is done**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure these features:\n",
    "* View-casting:\n",
    "    - ** View-casting a np.ndarray as flowField instance is not supported. Because view-casting does not allow any arguments, and the dictionary that accompanies the flowField array is fundamental. To make a flowField object out of an existing np.ndarray, use the constructor call. **\n",
    "* Explicit construction:\n",
    "    - Construct a randomField object based on noise levels supplied\n",
    "* New from template:\n",
    "    - Truncate and expand an instance of flowField to obtain a new instance with a changed dictionary (to reflect the truncation of L,M,N, or K)\n",
    "\n",
    "***Try to minimize making copies of flowField objects***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** I have three cases to consider when building a flowField instance. Suppose L = 1**:\n",
    "- The flowField has streamwise wavenumbers $-\\alpha, 0, \\alpha$\n",
    "- The flowField only has streamwise wavenumbers $-\\alpha, \\alpha$\n",
    "- The flowField only has streamwise wavenumber $\\alpha$\n",
    "    \n",
    "This question becomes particularly important if only a half-plane or half-volume of the wavenumber space is considered. \n",
    "\n",
    "This is how I chose to resolve this issue. Considering L:\n",
    "* If L = 0, then the flowField is of wavenumber $\\alpha$\n",
    "* If L = n ($\\in \\mathbb{N}$), then the flowField is resolved in wavenumbers {$0,\\alpha,2\\alpha,..,n\\alpha$}.\n",
    "* If L = -n ($n \\in \\mathbb{N}$), then the flowField is resolved in wavenumbers {$-n\\alpha, (-n+1)\\alpha,..,0,\\alpha,...,n\\alpha$}\n",
    "\n",
    "This way, a flowField can be defined in three different ways for each of the three Fourier axes (streamwise, spanwise, temporal):\n",
    "* As just one Fourier mode, $\\alpha$ (which could be positive, negative, or zero). \n",
    "* As a collection of `n` harmonics (positive integer multiples of a positive/negative wavenumber), along with mode zero (the invariant mode).\n",
    "* As a collection of `2n+1` harmonics, from $-n\\alpha$ through $n\\alpha$.\n",
    "\n",
    "** Correction: For streamwise and temporal Fourier modes, the flowField class does not allow having just positive modes. We either have just one wavenumber (initialized with L=0 and/or K=0), of have 2L+1 and 2K+1 wavenumbers with both positive and negative**\n",
    "\n",
    "I think this should be enough to deal with most cases. We will later need to define collections of flowFields. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In case dictionary is 'None':\n",
    "defaultDict = {'alpha':1.14, 'beta' : 2.5, 'omega':0.0, 'L': 0.0, 'M': 0.0, 'N': 0.0, 'K':0.0,\n",
    "               'ReLam': 400.0, 'isPois':0.0, 'noise':0.0 }\n",
    "\n",
    "def verify_dict(tempDict):\n",
    "    if tempDict is None:\n",
    "        tempDict = defaultDict\n",
    "    else: \n",
    "        for key in defaultDict:\n",
    "            if key not in tempDict:\n",
    "                tempDict[key] = defaultDict[key]\n",
    "    return tempDict\n",
    "\n",
    "flowDict = None\n",
    "flowDict = verify_dict(flowDict)\n",
    "print(flowDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slice\n",
    "I'm defining `slice` as a general method used for either truncating or extending the existing flowField instance. \n",
    "\n",
    "There are several cases to consider:\n",
    "1.  Both existing and requested instances have the same wavenumber extension: either both contain positive and negative wavenumbers, or both contain only non-negative wavenumbers. For this case, there are 2 subcases:\n",
    "    1.  The requested instance needs the existing instance to be truncated or held the same.\n",
    "    2.  The requested instance needs the existing instance to be extended.\n",
    "2.  The existing instance contains positive as well as negative wavenumbers, whereas the requested instance is only for positive wavenumbers. For this case:\n",
    "    1.  The requested instance requires truncation in positive modes of the existing instance.\n",
    "    2.  The requested instance requires extension in positive wavenumbers (with zeros for modes unavailable).\n",
    "3.  The existing instance contains only positive wavenumbers, whereas the requested instance is for positive as well as negative. For this case too:\n",
    "    1.  Truncation.\n",
    "    2.  Extension.\n",
    "\n",
    "\n",
    "## Going from half plane/volume to full using conjugate\n",
    "I thought that if the Fourier modes available were $(0:K\\omega,0:L\\alpha, 0:M\\beta)$, I could extend each set of modes into the negative side. But that's not true, I can only do that for just 1 set of modes. That is, I can't extend a quadrant to a full plane or an octant to a full volume. I can only go from 2 quadrants to 4, or 4 octants to 8. \n",
    "\n",
    "For now, I will suppose that we always have the flow resolved in the half-plane or the half-volume $\\beta>0$. So, K,L are always negative (-0=0). Only M is allowed to be positive, but it could also be set to be negative. \n",
    "\n",
    "**With this simplification, cases 2 and 3 identified for slicing (above) only relate to M. For K and L, it's always case 1.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load flowField.py\n",
    "''' \n",
    "#####################################################\n",
    "Author : Sabarish Vadarevu\n",
    "Affiliation: Aerodynamics and Flight Mechanics group, University of Southampton.\n",
    "\n",
    "This module provides a class to define u,v,w (or scalars such as pressure) in 4D: t, x,z,y. \n",
    "The shape of a class instance is (nt,nx,nz,nd,N): nt,nx,nz are harmonics (in omega, alpha,beta) \n",
    "    of Fourier modes in t,x,z respectively.\n",
    "nd is the number of components, 3 for [u,v,w]. \n",
    "Scalars and non-3d fields can be created by setting 'nd' appropriately (nd=1 for scalars).\n",
    "N refers to Chebyshev collocation nodes\n",
    "\n",
    "Class attributes:\n",
    "    self:   np.ndarray of shape (nt,nx,nz,nd,N)\n",
    "    nt, nx, nz : length of axes 0,1, and 2 respectively\n",
    "    nd:     Number of components of vector field. =1 for scalars. Length of axis 3\n",
    "    N:      Number of Chebyshev collocation nodes.\n",
    "    lOffset:When non-zero, indicates that the streamwisemodes are not harmonics of \n",
    "                fundamental frequency (alpha) but are offset from harmonics by a constant `lOffset`\n",
    "    mOffset:Same as lOffset, for spanwise modes\n",
    "    flowDict: \n",
    "        defaultDict = {'alpha':1.14, 'beta' : 2.5, 'omega':0.0, 'L': 23, 'M': 23, 'nd':3,'N': 35, 'K':0,\n",
    "               'Re': 400.0, 'isPois':0.0, 'noise':0.0 }\n",
    "        'noise' is currently not implemented, but will later be used to initialize \"random\" flowField instances\n",
    "        \n",
    "\n",
    "Methods (names only. See doc-strings for methods for template): \n",
    "    verify. view1d, view4d \n",
    "    slice, getScalar, appendField, copyArray\n",
    "    real, imag, conjugate, abs\n",
    "    ddt, ddx, ddx2, ddz, ddz2, ddy, ddy2, intY\n",
    "    grad3d, grad2d, grad, div, laplacian, curl3d, curl\n",
    "    convLinear, convNL, convSemiLinear\n",
    "    dot, sumAll, norm\n",
    "    residuals, solvePressure\n",
    "\n",
    "It must always be ensured that the dictionary, self.flowDict, is always consistent with the flowField instance.\n",
    "Unless one is absolutely sure that the dictionary attributes don't need to be changed, \n",
    "    the arrays should not be accessed directly. Either the methods must be used, \n",
    "    or for cases when a method isn't appropriate, the dictionary must be appropriately modified.\n",
    "    \n",
    "self.verify() ensures that at least the shape attributes are self-consistent. \n",
    "alpha, beta, omega, Re are not verified with self.verify()\n",
    "\n",
    "non-class functions:\n",
    "getDefaultDict(), verify_dict(), read_dictFile(), makeVector()\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "#from scipy.linalg import norm\n",
    "from warnings import warn\n",
    "from pseudo import chebdif, clencurt, chebintegrate, chebint\n",
    "#from pseudo.py import chebint\n",
    "\n",
    "defaultDict = {'alpha':1.14, 'beta' : 2.5, 'omega':0.0, 'L': 23, 'M': 23, 'nd':3,'N': 35, 'K':0,\n",
    "               'Re': 400.0, 'isPois':0.0, 'noise':0.0 , 'lOffset':0.0, 'mOffset':0.0}\n",
    "\n",
    "defaultBaseDict = {'alpha':0, 'beta' : 0, 'omega':0.0, 'L': 0, 'M': 0, 'nd':1,'N': 35, 'K':0,\n",
    "               'Re': 400.0, 'isPois':0.0, 'noise':0.0 , 'lOffset':0.0, 'mOffset':0.0}\n",
    "\n",
    "divTol = 1.0e-06\n",
    "pCorrTol = 1.0e-04\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def getDefaultDict(base=False):\n",
    "    if base:\n",
    "        return defaultBaseDict.copy()\n",
    "    else:\n",
    "        return defaultDict.copy()\n",
    "\n",
    "def verify_dict(tempDict):\n",
    "    '''Verify that the supplied flowDict has all the parameters required'''\n",
    "    change_parameters = False\n",
    "    if tempDict is None:\n",
    "        tempDict = defaultDict.copy()\n",
    "        warn('No flowDict was supplied. Assigning the default dictionary')\n",
    "    else: \n",
    "        for key in defaultDict:\n",
    "            assert key in tempDict, 'Some dictionary keys are missing'\n",
    "    [tempDict['K'],tempDict['L'],tempDict['N'],tempDict['isPois']] = [int(abs(k)) for k in [tempDict['K'],tempDict['L'],tempDict['N'],tempDict['isPois']]]\n",
    "    tempDict['M'] = int(tempDict['M'])\n",
    "    if tempDict['alpha'] == 0.: assert tempDict['L'] == 0, 'If alpha is zero, L should also be set to zero in the dictionary'\n",
    "    if tempDict['beta'] == 0.: assert tempDict['M'] == 0, 'If beta is zero, M should also be set to zero in the dictionary'\n",
    "    if tempDict['omega'] == 0.: assert tempDict['K'] == 0, 'If omega is zero, K should also be set to zero in the dictionary'\n",
    "    return tempDict\n",
    "\n",
    "def read_dictFile(dictFile):\n",
    "    '''Read flowDict from file. MUST use \"flowConfig.txt\" as template. '''\n",
    "    tempDict = {}\n",
    "    with open(\"flowConfig.txt\",'r') as f:\n",
    "        for line in f:\n",
    "            (key,val) = line.split()[:2]\n",
    "            tempDict[key] = float(val)    \n",
    "    return tempDict\n",
    "\n",
    "def makeVector(*args):\n",
    "    '''Concatenate flowField objects. Use this to create a vector flowField from scalar/vector flowFields\n",
    "    For instance,   uvw = makeVector(u,v,w)\n",
    "                    uvwp = makeVector(u,v,w,p) = makeVector(uvw,p)'''\n",
    "    ff = args[0]\n",
    "    if not isinstance(ff,flowField):\n",
    "        raise RuntimeError('makeVector takes as arguments only instances of flowField class')\n",
    "        return\n",
    "    for v in args[1:]:\n",
    "        if not isinstance(v,flowField):\n",
    "            raise RuntimeError('makeVector takes as arguments only instances of flowField class')\n",
    "        ff = ff.appendField(v)\n",
    "    return ff\n",
    "    \n",
    "\n",
    "class flowField(np.ndarray):\n",
    "    '''Provides 4d scalars and vectors of shape (nt,nx,nz,nd,N),\n",
    "    nt, nx, nz: Number of temporal, streamwise, and spanwise Fourier modes contained in the flowField. \n",
    "    nd: Number of components of the vector\n",
    "    N: Number of Chebyshev collocation nodes (on [1,-1])\n",
    "    nt,nx,nz,nd,N, and a bunch of other parameters: Re, alpha, beta, omega, isPois (flag to say if flow is pressure driven or driven by plate motion)\n",
    "        are taken from a dictionary that MUST accompany the field array. The class fails to work when the dictionary is not consistent\n",
    "\n",
    "    Initialization:\n",
    "        flowField() creates an instance using a default dictionar: a 3 component vector of shape (1,47,24,3,35).\n",
    "        flowField(flowDict=dictName) creates an instance with shape attributes as defined in the dictionary.\n",
    "            If the dictionary does not have all the keys needed, an assertion error is printed\n",
    "        flowField(dictFile='flowConfig.txt') creates an instance using the attributes defined in the file flowConfig.txt\n",
    "            The file flowConfig.txt has its lines formatted to facilitate being read by a function in this module. DO NOT EDIT IT except for the values\n",
    "        flowField(arr=initArr, flowDict=dictName)\n",
    "            Unless an array is passed using the keyword 'arr', the instance is initialized with zeros\n",
    "\n",
    "    All three arguments can be used to provide a dictionary (arr can be an instance of flowField).\n",
    "    flowDict argument has highest priority in defining the dictionary, \n",
    "        followed by dictFile\n",
    "        followed by arr.flowDict (when arr is an instance of flowField or its subclass)\n",
    "    If none of the above arguments provide a flowDict, a default dictionary (defined in the module) is used.\n",
    "    A warning message is printed when the default dictionary is used.\n",
    "            \n",
    "    '''\n",
    "    def __new__(cls, arr=None, flowDict=None, dictFile= None):\n",
    "        '''Creates a new instance of flowField class with arguments (arr=None,flowDict=None,dictFile=None)\n",
    "        '''\n",
    "        if flowDict is None:\n",
    "            if dictFile is None:\n",
    "                if hasattr(arr,'flowDict'):\n",
    "                    flowDict = arr.flowDict\n",
    "                else:\n",
    "                    flowDict=verify_dict(flowDict)\n",
    "            else:\n",
    "                flowDict = verify_dict(read_dictFile(dictFile))\n",
    "        else:\n",
    "            flowDict = verify_dict(flowDict)\n",
    "        \n",
    "        \n",
    "        L = flowDict['L']\n",
    "        M = flowDict['M']\n",
    "        N = flowDict['N']\n",
    "        K = flowDict['K']\n",
    "        nd = flowDict['nd']\n",
    "        nt = 2*K+1\n",
    "        nx = 2*L+1\n",
    "        nz = int(3.*abs(M)/2. - M/2. + 1)     # = 1 if M=0;    = M+1 if M>0;    = 2*|M|+1 if M<0\n",
    "        \n",
    "        if arr is None:\n",
    "            #obj =  np.zeros((nt,nx,nz,nd,N),dtype=np.complex).view(cls)\n",
    "            obj = np.ndarray.__new__(cls,shape=(nt,nx,nz,nd,N),dtype=np.complex,buffer=np.zeros(nt*nx*nz*nd*N,dtype=np.complex))\n",
    "        else:\n",
    "            if arr.dtype == np.float:\n",
    "                arr = (arr+1.j*np.zeros(arr.shape))\n",
    "            obj = np.ndarray.__new__(cls,shape=(nt,nx,nz,nd,N),dtype=np.complex,buffer=arr)\n",
    "        \n",
    "        #print(norm(obj))\n",
    "        \n",
    "        if obj.size != (nx*nz*nt*nd*N):\n",
    "            raise RuntimeError('The parameters in the dictionary are not consistent with the size of the supplied array')\n",
    "        \n",
    "        obj.flowDict = flowDict\n",
    "        obj.nx = nx\n",
    "        obj.nz = nz\n",
    "        obj.nt = nt\n",
    "        obj.N = N\n",
    "        obj.nd = flowDict['nd']\n",
    "        return obj\n",
    "        \n",
    "    \n",
    "    def __array_finalize__(self,obj):\n",
    "        if self.dtype != np.complex:\n",
    "            print('Shape of self that is giving dtype errors:',self.shape)\n",
    "            warn('flowField class is designed to work with complex array entries\\n'+\n",
    "                 'To obtain real/imaginary parts of an instance, use class methods \"real()\" and \"imag()\"')\n",
    "        if isinstance(obj, flowField):\n",
    "            self.flowDict = getattr(self,'flowDict',obj.flowDict.copy())\n",
    "            self.nt = getattr(self,'nt',obj.nt)\n",
    "            self.nx = getattr(self,'nx',obj.nx)\n",
    "            self.nz = getattr(self,'nz',obj.nz)\n",
    "            self.nd = getattr(self,'nd',obj.nd)\n",
    "            self.N = getattr(self,'N',obj.N)\n",
    "            return\n",
    "        elif obj != None:\n",
    "            raise RuntimeError('View-casting np.ndarray is not supported since dictionaries cannot be passed. \\n'+\n",
    "                               'To initialize class instance from np.ndarray, use constructor call:flowField(arr=myArray,dictFile=myFile)')\n",
    "        return\n",
    "\n",
    "    \n",
    "    def verify(self):\n",
    "        '''Ensures that the size of the class array is consistent with the dictionary entries. \n",
    "        Use this when writing new methods or tests'''\n",
    "        self.flowDict = verify_dict(self.flowDict)\n",
    "        if not ((self.nt == 2*self.flowDict['K']+1) and (self.nx == 2*self.flowDict['L']+1) and \n",
    "                (self.nz == int(3.*abs(self.flowDict['M'])/2. - self.flowDict['M']/2. + 1)) and\n",
    "                (self.N == self.flowDict['N']) and (self.nd == self.flowDict['nd'])): \n",
    "            raise RuntimeError('The shape attributes of the flowField instance are not consistent with dictionary entries')\n",
    "        assert self.size == self.nt*self.nx*self.nz*self.nd*self.N, 'The size of the flowField array is not consistent with its shape attributes'\n",
    "        \n",
    "    def view1d(self):\n",
    "        ''' Returns a 1d view. \n",
    "        Don't try to figure out what the ordering is, just use self.view4d() to get an organized view'''\n",
    "        return self.reshape(self.size)\n",
    "    \n",
    "    def view4d(self):\n",
    "        ''' Returns a 4d view (actually, a 5-D array): (omega, alpha, beta, field=u,v,w,p, N)'''\n",
    "        return self.reshape((self.nt,self.nx,self.nz,self.nd,self.N))\n",
    "\n",
    "    def slice(self,K=None,L=None,M=None,nd=None,N=None):\n",
    "        '''\n",
    "        Returns a class instance with increased/reduced K,L,M,nd,N\n",
    "        Call as new_inst = myFlowField.slice(K=Knew,L=Lnew,N=Nnew)) to change values of K,L,N without affecting M (and nd)\n",
    "        When the number of Fourier modes (K,L,M, or nt,nx,nz) are smaller than what is requested, \n",
    "            additional zero modes are added. For Chebyshev nodes, interpolation is used'''\n",
    "        obj = self.copyArray()\n",
    "        nxt = self.nx\n",
    "        ntt = self.nt\n",
    "        nzt = self.nz\n",
    "        ndt = self.nd\n",
    "        Nt = self.N\n",
    "        flowDict_temp = self.flowDict.copy()\n",
    "        if (K is not None) and (K != self.flowDict['K']):\n",
    "            K = int(abs(K))\n",
    "            Kt = flowDict_temp['K']               # Temporary name for 'K' of self\n",
    "            if K <= Kt:\n",
    "                obj = obj[Kt-K:Kt+K+1]\n",
    "            else: \n",
    "                obj = np.concatenate((  np.zeros((Kt-K,nxt,nzt,ndt,Nt),dtype=np.complex), obj,\n",
    "                               np.zeros((Kt-K,nxt,nzt,ndt,Nt),dtype=np.complex)  ), axis=0)\n",
    "            flowDict_temp['K']= K\n",
    "            ntt = 2*K+1\n",
    "        \n",
    "        if (L is not None) and (L != self.flowDict['L']):\n",
    "            L = int(abs(L))\n",
    "            Lt = flowDict_temp['L']               # Temporary name for 'L' of self\n",
    "            if L <= Lt:\n",
    "                obj = obj[:,Lt-L:Lt+L+1]\n",
    "            else: \n",
    "                obj = np.concatenate((  np.zeros((ntt,abs(Lt-L),nzt,ndt,Nt),dtype=np.complex), obj,\n",
    "                               np.zeros((ntt,abs(Lt-L),nzt,ndt,Nt),dtype=np.complex)  ), axis=1)\n",
    "            flowDict_temp['L']= L\n",
    "            nxt = 2*L+1\n",
    "        \n",
    "        if (M is not None) and (M != self.flowDict['M']):\n",
    "            M = int(M)\n",
    "            Mt = flowDict_temp['M']               # Temporary name for 'M' of self\n",
    "            nzt = int(3.*abs(M)/2. - M/2. + 1)     # = 1 if L=0;    = L+1 if L>0;    = 2*|L|+1 if L<0\n",
    "            \n",
    "            if M*Mt >=0: \n",
    "                if abs(M) <= abs(Mt): # Case 1.A: Truncate\n",
    "                    nz0 = int((abs(Mt)-Mt)/2)     # = Mt for Mt< 0, = 0 otherwise\n",
    "                    nzm1 = nz0 - int((abs(M)-M)/2) \n",
    "                    nzp1 = nz0 + abs(M) + 1\n",
    "                    obj = obj[:,:,nzm1:nzp1]\n",
    "                else:  # Case 1.B: Extend using zero modes\n",
    "                    nzplus = int(abs(M)-abs(Mt))\n",
    "                    if M<0: \n",
    "                        obj = np.concatenate(( np.zeros((ntt,nxt,abs(Mt-M),ndt,Nt),dtype=np.complex), obj,\n",
    "                               np.zeros((ntt,nxt,abs(Mt-M),ndt,Nt),dtype=np.complex)  ), axis=2)\n",
    "                    else:\n",
    "                        obj = np.concatenate(( obj,\n",
    "                               np.zeros((ntt,nxt,abs(Mt-M),ndt,Nt),dtype=np.complex) ), axis=2)\n",
    "            elif M > 0:          # Case 2: Get only modes [0,b,..,|M|b] from [-|Mt|*b,..,0,b,..,|Mt|*b]\n",
    "                if abs(M) <= abs(Mt): # Case 2.A: |M|< |Mt|, so truncate\n",
    "                    nz0 = int((abs(Mt)-Mt)/2)\n",
    "                    nzp1 = nz0 + M + 1\n",
    "                    obj = obj[:,:,nx0:nzp1]\n",
    "                else:    # Case 2.B: |M| > |Mt|, so add zero modes \n",
    "                    obj = np.concatenate(( obj[:,:,abs(Mt):], \n",
    "                               np.zeros((ntt,nxt,abs(Mt-M),ndt,Nt),dtype=np.complex) ), axis=2)\n",
    "            else: # Case 3: Get modes [-|M|b,...,0,b,..,|M|b], given [0,b,..,|Mt|b]\n",
    "                if abs(M) <= abs(Mt):        # Case 3.A: Truncate on positive, extend with conjugates on negative\n",
    "                    obj = np.concatenate(( obj[::-1,::-1,abs(M):0:-1].conjugate(), obj[:,:,:abs(M)+1] ), axis=2)\n",
    "                else:            # Case 3.B: Extend on positive with zeros, extend on negative with conjugates and zeros\n",
    "                    # Doing the extension with conjugates on negative first:\n",
    "                    obj = np.concatenate(( obj[::-1,::-1,:0:-1].conjugate(), obj ), axis=2)\n",
    "                    # Adding zeros on positive and negative:\n",
    "                    obj = np.concatenate((  np.zeros((ntt,nxt,abs(Mt-M),ndt,Nt),dtype=np.complex), obj,\n",
    "                               np.zeros((ntt,nxt,abs(Mt-M),ndt,Nt),dtype=np.complex) ), axis=2)\n",
    "            flowDict_temp['M']= M\n",
    "        \n",
    "        if (N is not None) and (N != self.flowDict['N']):\n",
    "            N = abs(int(N))\n",
    "            Nt = flowDict_temp['N']\n",
    "            if N != Nt:\n",
    "                y = chebdif(N,1)[0]\n",
    "                obj_t = obj.reshape((obj.size//Nt,Nt))\n",
    "                obj = np.zeros((obj_t.size//Nt,N),dtype=np.complex)\n",
    "                for n in range(obj_t.size//Nt):\n",
    "                    obj[n] = chebint(obj_t[n],y)\n",
    "            obj = obj.reshape(obj.size)\n",
    "            flowDict_temp['N'] = N\n",
    "        \n",
    "        obj = flowField(arr=obj, flowDict = flowDict_temp).view4d()\n",
    "        \n",
    "        if (nd is not None):\n",
    "            nd = np.asarray([nd])\n",
    "            nd = nd.reshape(nd.size)\n",
    "            obj = obj[:,:,:,nd]\n",
    "            obj.flowDict['nd'] = nd.size\n",
    "            obj.nd = nd.size\n",
    "        \n",
    "        obj.verify()\n",
    "        return obj\n",
    "    \n",
    "    def getScalar(self,nd=0):\n",
    "        '''Returns the field Variable in the flowField instance identified by the argument \"nd\".\n",
    "        Default for \"nd\" is 0, the first scalar in the flowField (u)'''\n",
    "        if type(nd) != int:\n",
    "            raise RuntimeError('getScalar(nd=0) only accepts integer arguments')\n",
    "        obj = self.view4d()[:,:,:,nd:nd+1].copy()\n",
    "        obj.flowDict['nd'] = 1\n",
    "        obj.nd = 1\n",
    "        return obj.view4d()\n",
    "\n",
    "    def appendField(self,obj):\n",
    "        '''Append a field at the end of \"self\". To append \"p\" to \"uVec\", call as uVec.appendField(p)\n",
    "        Note: Both uVec and p must be flowField objects, each with their flowDict'''\n",
    "        if not isinstance(obj,flowField):\n",
    "            raise RuntimeError('Only flowField objects can be appended to a flowField object')\n",
    "        tempDict = self.flowDict.copy()\n",
    "        tempDict['nd'] += obj.flowDict['nd']\n",
    "        v1 = self.view4d().copyArray()\n",
    "        v2 = obj.view4d().copyArray()\n",
    "        return flowField(arr=np.append(v1,v2,axis=3), flowDict=tempDict)\n",
    "    \n",
    "    def copyArray(self):\n",
    "        ''' Returns a copy of the np.ndarray of the instance. \n",
    "        This is useful for manipulating the entries of a flowField without bothering with all the checks'''\n",
    "        return self.view(np.ndarray).copy()\n",
    "    \n",
    "    def real(self):\n",
    "        ''' Returns the real part of the flowField (the entries are still complex, with zero imaginary parts)'''\n",
    "        return flowField(arr=self.copyArray().real,flowDict=self.flowDict)\n",
    "    \n",
    "    def imag(self):\n",
    "        ''' Returns the imaginary part of the flowField (the entries are still complex, with zero imaginary parts)'''\n",
    "        return flowField(arr=self.copyArray().imag,flowDict=self.flowDict)\n",
    "    \n",
    "    def conjugate(self):\n",
    "        ''' Returns complex conjugate of flowFIeld instance'''\n",
    "        return self.real()-1.j*self.imag()\n",
    "    def abs(self):\n",
    "        '''Returns absolute value of entries of flowField instance (still expressed as complex numbers, but with zero imaginary part and positive real part)'''\n",
    "        return flowField(arr=np.abs(self.copyArray()),flowDict=self.flowDict.copy())\n",
    "    \n",
    "    def ddt(self):\n",
    "        ''' Returns a flowField instance that gives the partial derivative along \"t\" '''\n",
    "        if self.nt == 1:\n",
    "            return 1.j*self.flowDict['omega']*self.copy()\n",
    "        partialT = self.view4d().copy()\n",
    "        kArr = np.arange(-self.flowDict['K'],self.flowDict['K']+1).reshape(self.nt,1,1,1,1)\n",
    "        return partialT\n",
    "    \n",
    "    def ddx(self):\n",
    "        ''' Returns a flowField instance that gives the partial derivative along \"x\" '''\n",
    "        if self.nx == 1:\n",
    "            return 1.j*(1+self.flowDict['lOffset'])*self.flowDict['alpha']*self.copy()\n",
    "        partialX = self.view4d().copy()\n",
    "        lArr = (self.flowDict['lOffset']+np.arange(-self.flowDict['L'],self.flowDict['L']+1)).reshape(1,self.nx,1,1,1)\n",
    "        partialX[:] = 1.j*self.flowDict['alpha']*lArr*partialX\n",
    "        return partialX\n",
    "    \n",
    "    def ddx2(self):\n",
    "        ''' Returns a flowField instance that gives the second partial derivative along \"x\" '''\n",
    "        if self.nx == 1:\n",
    "            return -1.*((1+self.flowDict['lOffset'])*self.flowDict['alpha'])**2*self.copy()\n",
    "        partialX2 = self.view4d().copy()\n",
    "        l2Arr = ((self.flowDict['lOffset']+np.arange(-self.flowDict['L'],self.flowDict['L']+1))**2).reshape(1,self.nx,1,1,1)\n",
    "        partialX2[:] = -self.flowDict['alpha']**2*l2Arr*partialX2\n",
    "        return partialX2\n",
    "    \n",
    "    def ddz(self):\n",
    "        ''' Returns a flowField instance that gives the partial derivative along \"z\" '''\n",
    "        if self.nz == 1:\n",
    "            return 1.j*(1+self.flowDict['mOffset'])*self.flowDict['beta']*self.copy()\n",
    "        partialZ = self.view4d().copy()\n",
    "        M = self.flowDict['M']\n",
    "        mArr = (self.flowDict['mOffset']+np.arange( (M-abs(M))/2,abs(M)+1 ) ).reshape((1,1,self.nz,1,1))\n",
    "        partialZ[:] = 1.j*self.flowDict['beta']*mArr*partialZ\n",
    "        return partialZ\n",
    "    \n",
    "    def ddz2(self):\n",
    "        ''' Returns a flowField instance that gives the second partial derivative along \"z\" '''\n",
    "        if self.nz == 1:\n",
    "            return -1.*((1+self.flowDict['mOffset'])*self.flowDict['beta'])**2*self.copy()\n",
    "        partialZ2 = self.view4d().copy()\n",
    "        M = self.flowDict['M']\n",
    "        mArr = (self.flowDict['mOffset']+np.arange( (M-abs(M))/2,abs(M)+1 )).reshape((1,1,self.nz,1,1))\n",
    "        m2Arr = mArr**2\n",
    "        partialZ2[:] = -self.flowDict['beta']**2*m2Arr*partialZ2\n",
    "        return partialZ2\n",
    "    \n",
    "    def ddy(self):\n",
    "        ''' Returns a flowField instance that gives the partial derivative along \"y\" '''\n",
    "        partialY = self.view1d().copy()\n",
    "        N = partialY.flowDict['N']\n",
    "        D = (chebdif(N,1)[1]).reshape(N,N)\n",
    "        for n in range(self.nt*self.nx*self.nz*self.nd):\n",
    "            partialY[n*N:(n+1)*N] = np.dot(D, partialY[n*N:(n+1)*N])\n",
    "        return partialY.view4d()\n",
    "    \n",
    "    def ddy2(self):\n",
    "        ''' Returns a flowField instance that gives the partial derivative along \"y\" '''\n",
    "        partialY2 = self.view1d().copy()\n",
    "        N = partialY2.flowDict['N']\n",
    "        D2 = (chebdif(N,2)[1])[:,:,1].reshape(N,N)\n",
    "        for n in range(self.nt*self.nx*self.nz*self.nd):\n",
    "            partialY2[n*N:(n+1)*N] = np.dot(D2, partialY2[n*N:(n+1)*N])\n",
    "        return partialY2.view4d()\n",
    "\n",
    "    def intY(self):\n",
    "        ''' Integrate each Fourier mode of each scalar along the wall-normal axis\n",
    "        Returns a flowField object of the same size as self.\n",
    "        Use this method to compute variables from their wall-normal derivatives'''\n",
    "        integral = self.copy().reshape((self.size/self.N, self.N))\n",
    "        arr = integral.copyArray()\n",
    "        for n in range(np.int(integral.size/integral.N)):\n",
    "            integral[n] = chebintegrate(arr[n])\n",
    "        integral.verify()\n",
    "        return integral.view4d()\n",
    "    \n",
    "    def grad3d(self, scalDim=0, nd=3):\n",
    "        ''' Computes gradient (in 3d by default) of either a scalar flowField object, \n",
    "            or of the first variable in a vector flowField object. \n",
    "            Grads of other variables can be calculated by passing scalDim=<index of variable>.\n",
    "            Gradients in 2D (x and y) can be calculated by passing nd=2'''\n",
    "        tempDict = self.flowDict.copy()\n",
    "        tempDict['nd'] = nd\n",
    "        if self.nd ==1:\n",
    "            scal = self\n",
    "        else:\n",
    "            scal = self.getScalar(nd=scalDim)\n",
    "        scal.verify()\n",
    "        if nd == 3:\n",
    "            gradVec = makeVector(scal.ddx(),scal.ddy(),scal.ddz())\n",
    "        elif nd ==2:\n",
    "            gradVec = makeVector(scal.ddx(), scal.ddy())\n",
    "        return gradVec\n",
    "    \n",
    "    def grad(self,**kwargs):\n",
    "        return self.grad3d(**kwargs)\n",
    "    \n",
    "    def grad2d(self, **kwargs):\n",
    "        ''' Computes gradients in 2D (streamwise & wall-normal) for a scalar flowField object, \n",
    "            or for the scalar component of a vector field identified as vecField[:,:,:,scalDim]'''\n",
    "        kwargs['nd'] = 2\n",
    "        return self.grad3d(**kwargs)\n",
    "        \n",
    "    def laplacian(self):\n",
    "        ''' Computes Laplacian for a 3C flowField'''\n",
    "        assert  self.nd in [2,3] , 'Laplacian is defined only for 2C or 3C fields'\n",
    "        if self.nd == 3: return self.ddx2() + self.ddy2() + self.ddz2()\n",
    "        else: return self.ddx2() + self.ddy2()\n",
    "            \n",
    "    def div(self):\n",
    "        ''' Computes divergence of vector field as u_x+v_y+w_z\n",
    "        If a flowField with more than 3 components (nd>3) is supplied, takes first three components as u,v,w.\n",
    "        Optional: 2-D divergence, u_x+v_y can be requested by passing nd=2'''\n",
    "        assert self.nd in [2,3], ('Divergence is defined only for 2C or 3C fields')\n",
    "        if self.nd == 3: return self.getScalar(nd=0).ddx() + self.getScalar(nd=1).ddy() + self.getScalar(nd=2).ddz()\n",
    "        else: return self.getScalar(nd=0).ddx() + self.getScalar(nd=1).ddy() \n",
    "        \n",
    "    def curl3d(self):\n",
    "        assert self.nd == 3, 'curl3d method is defined only for 3C fields. To get vorticity of 2D field, use curl() instead'\n",
    "        return makeVector(self.getScalar(nd=2).ddy() -self.getScalar(nd=1).ddz(),\\\n",
    "                         self.getScalar(nd=0).ddz() -self.getScalar(nd=2).ddx(),\\\n",
    "                         self.getScalar(nd=1).ddx() -self.getScalar(nd=0).ddy())\n",
    "    \n",
    "    def curl(self):\n",
    "        if self.nd == 3: return self.curl3d()\n",
    "        elif self.nd == 2:\n",
    "            tempDict = self.flowDict.copy(); tempDict['nd'] = 1;\n",
    "            zeroField = flowField(flowDict = tempDict)\n",
    "            return (self.appendField(zeroField).curl()).getScalar(nd=2)\n",
    "        else:\n",
    "            raise RuntimeError('Curl is defined only for 2C or 3C fields.')\n",
    "            return\n",
    "    \n",
    "    def sumAll(self):\n",
    "        '''Sums all elements of a flowField object (along all axes)'''\n",
    "        obj = self.view4d().copyArray()\n",
    "        return np.sum(np.sum(np.sum(np.sum(np.sum(obj,axis=4),axis=3),axis=2),axis=1),axis=0)\n",
    "    \n",
    "    def dot(self, vec2):\n",
    "        '''Computes inner product for two flowField objects, scalar or vector,\n",
    "            by integrating each scalar along x,y,and z, and adding the integrals for each scalar.\n",
    "        Currently, only inner products of objects with identical dictionaries are supported'''\n",
    "        assert isinstance(vec2,flowField), 'Inner products are only defined for flowField objects. Ensure passed object is a flowField instance'\n",
    "        assert (self.flowDict == vec2.flowDict), 'Method for inner products is currently unable to handle instances with different flowDicts'\n",
    "        \n",
    "        w = clencurt(self.N).reshape((1,1,1,1,self.N))\n",
    "        return flowField.sumAll(self*vec2.conjugate()*w)\n",
    "    \n",
    "    def norm(self):\n",
    "        '''Integrates v*v.conjugate() along x,y,z, and takes its square-root'''\n",
    "        return np.sqrt(np.abs(self.dot(self)))\n",
    "    \n",
    "    def weighted(self):\n",
    "        '''Weights self by sqrt(W), where W is the Clenshaw-Curtis quadrature weighting\n",
    "        When using .dot() or .norm(), what is done is W*v1*v2'  \n",
    "        Another way to do the same is to pre-multiply vectors v1 and v2 with sqrt(W), \n",
    "            and then use the regular vector dot product to compute the weighted dot product\n",
    "        NOTE: In keeping with the convention throughout the class' methods, \n",
    "                the returned object is not a 1-d array. ''' \n",
    "        q = np.sqrt(clencurt(self.N).reshape((1,1,1,1,self.N)))\n",
    "        return q*self.view4d()\n",
    "    \n",
    "    def convLinear(self,uBase=None):\n",
    "        ''' Computes linearized convection term as [U u_x + v U',  U v_x,  U w_x ]\n",
    "        Baseflow, uBase must be a 1D array of size \"N\" '''\n",
    "        N = self.N\n",
    "        y = chebdif(N,1)[0]\n",
    "        if isinstance(uBase,flowField):\n",
    "            if uBase.size != self.N:\n",
    "                return self.convSemiLinear(uBase=uBase)\n",
    "        else:\n",
    "            if uBase is None:\n",
    "                if self.flowDict['isPois'] == 1: baseArr = 1.- y**2\n",
    "                else: baseArr = y\n",
    "                baseDict = defaultBaseDict; baseDict['N'] = N\n",
    "                baseArr = uBase\n",
    "                uBase = flowField(arr=baseArr, flowDict=baseDict)\n",
    "            else:\n",
    "                assert uBase.size == N,\\\n",
    "                    'Base flow must be of size N ([U(y),0,0]). For \"richer\" base flows, use method .convSemiLinear(uBase=baseFlow)'\n",
    "        assert self.nd in [2,3], 'Convection term (linearized) can be calculated only for 2C or 3C vector fields'\n",
    "        \n",
    "        convTerm = flowField(flowDict = self.flowDict.copy())\n",
    "        convTerm[:] = uBase.view4d()*self.ddx()\n",
    "        convTerm[:,:,:,0:1] += uBase.ddy()*self.view4d()[:,:,:,1:2]\n",
    "        convTerm.verify()\n",
    "        return convTerm\n",
    "    \n",
    "    def convSemiLinear(self,uBase=None):\n",
    "        '''Use this method when baseFlow is \"rich\", i.e. not of the form [U_000(y), 0, 0]\n",
    "            Any base flow with energy in multiple Fourier modes will lead to dispersion of any fluctuation\n",
    "                in modes, say, (k,l,m), to other modes due to the non-linear interaction with modes of the base flow\n",
    "        Arguments:\n",
    "        uBase: The \"rich\" base flow. Must be a flowField instance with the same flowDict (except for lOffset and mOffset)\n",
    "                as self'''\n",
    "        if (uBase is None) or (uBase.size == self.N):\n",
    "            return self.convLinear(uBase=uBase)\n",
    "        assert isinstance(uBase,flowField), 'The base flow must be an instance of flowField class'\n",
    "        assert (uBase.flowDict['K'] == self.flowDict['K']) and \\\n",
    "                (uBase.flowDict['L'] == self.flowDict['L']) and \\\n",
    "                (uBase.flowDict['M'] == self.flowDict['M']) and \\\n",
    "                (uBase.flowDict['N'] == self.flowDict['N']), \\\n",
    "                'The base flow must have the same number of Fourier and Cheb modes as self'\n",
    "        assert (uBase.flowDict['alpha'] == self.flowDict['alpha']) and (uBase.flowDict['beta'] == self.flowDict['beta']),\\\n",
    "            'For convSemiLinear, uBase and self should have same fundamental wavenumbers and harmonics (except for offsets in l and m)'\n",
    "        assert (uBase.flowDict['lOffset'] == 0.) and (uBase.flowDict['mOffset'] == 0.), \\\n",
    "            'In uBase, Fourier modes must be harmonics of alpha and beta in flowDict'\n",
    "            \n",
    "        if self.flowDict['M'] > 0 :\n",
    "            obj = self.slice(M=-self.flowDict['M']); \n",
    "            u = obj.getScalar(nd=0); v = obj.getScalar(nd=1) ; w = obj.getScalar(nd=2); tempDict = obj.flowDict.copy()\n",
    "            uBase = uBase.slice(M=-self.flowDict['M'])\n",
    "        else:\n",
    "            u = self.getScalar(nd=0);  v = self.getScalar(nd=1); w = self.getScalar(nd=2); tempDict = self.flowDict.copy()\n",
    "        \n",
    "        tempDict = self.flowDict.copy()\n",
    "        tempDict['nd'] = 3\n",
    "        convTerm = flowField(flowDict=tempDict).view4d()\n",
    "        \n",
    "        ux = u.ddx(); uy = u.ddy(); uz = u.ddz()\n",
    "        vx = v.ddx(); vy = v.ddy(); vz = v.ddz()\n",
    "        wx = w.ddx(); wy = w.ddy(); wz = w.ddz()\n",
    "        \n",
    "        U = uBase.getScalar(nd=0); baseDict = uBase.flowDict.copy(); baseDict['nd'] = 1;\n",
    "        if uBase.nd >=3 : V = uBase.getScalar(nd=1); W = uBase.getScalar(nd=2);\n",
    "        elif uBase.nd == 2: V = uBase.getScalar(nd=1); W = flowField(flowDict=baseDict) \n",
    "        else: W = flowField(flowDict=baseDict) ;  W = flowField(flowDict=baseDict)\n",
    "        \n",
    "        sumArr = lambda v: np.sum( np.sum( np.sum( v, axis=1), axis=1), axis=1)\n",
    "        \n",
    "        for lp in range(self.nx):\n",
    "            l = lp - L\n",
    "            l1 = l; l2 = None; l3 = None; l4 = l1-1; \n",
    "            if l == 0: l4 = None\n",
    "            if l < 0:  \n",
    "                l1 = None; l2 = self.nx+l; l3 = l2-1; l4 = None\n",
    "                \n",
    "            for mp in range(self.nz):\n",
    "                m = mp - abs(M)\n",
    "                m1 = m; m2 = None; m3 = None; m4 = m1-1; \n",
    "                if m == 0: m4 = None\n",
    "                if m < 0: \n",
    "                    m1 = None; m2 = self.nz+m; m3 = m2-1; m4 = None\n",
    "                \n",
    "                convTerm[:,lp,mp,0] += sumArr(U[:,l1:l2,m1:m2]*ux[:,l3:l4:-1,m3:m4:-1])\n",
    "                convTerm[:,lp,mp,0] += sumArr(V[:,l1:l2,m1:m2]*uy[:,l3:l4:-1,m3:m4:-1])\n",
    "                convTerm[:,lp,mp,0] += sumArr(W[:,l1:l2,m1:m2]*uz[:,l3:l4:-1,m3:m4:-1])\n",
    "                \n",
    "                convTerm[:,lp,mp,1] += sumArr(U[:,l1:l2,m1:m2]*vx[:,l3:l4:-1,m3:m4:-1])\n",
    "                convTerm[:,lp,mp,1] += sumArr(V[:,l1:l2,m1:m2]*vy[:,l3:l4:-1,m3:m4:-1])\n",
    "                convTerm[:,lp,mp,1] += sumArr(W[:,l1:l2,m1:m2]*vz[:,l3:l4:-1,m3:m4:-1])\n",
    "                \n",
    "                convTerm[:,lp,mp,2] += sumArr(U[:,l1:l2,m1:m2]*wx[:,l3:l4:-1,m3:m4:-1])\n",
    "                convTerm[:,lp,mp,2] += sumArr(V[:,l1:l2,m1:m2]*wy[:,l3:l4:-1,m3:m4:-1])\n",
    "                convTerm[:,lp,mp,2] += sumArr(W[:,l1:l2,m1:m2]*wz[:,l3:l4:-1,m3:m4:-1])\n",
    "        \n",
    "        convTerm.verify()\n",
    "        if self.flowDict['M']>0:\n",
    "            convTerm = convTerm.slice(M=self.flowDict['M'])\n",
    "        return convTerm\n",
    "    \n",
    "    def convNL(self, uBase=None):\n",
    "        '''Computes the non-linear convection term, given a fluctuation flow field (base flow is added when calculating)\n",
    "        Warning: Currently, the code assumes that the flowField supplied is that of a steady flow. Temporal frequencies are not accounted for'''\n",
    "        \n",
    "        # If the only modes are, say {(a,-2b),(a,-b),(a,0),(a,b),(a,2b)}, \n",
    "        #    then the only non-linear interactions that produce these modes are when the above modes interact with (0,0)\n",
    "        #    Interactions within the above modes can only produce {(2a,nb)} with doesn't belong to the set\n",
    "        # Similarly for {(-na,b),(-na+a,b),..,(0,b),(a,b),..,(na,b)}. The convection term is simply the linear part of it (for a given base flow)\n",
    "        # For a single mode, (a,b), the convection term that produces the mode is, again, its interaction with just (0,0)\n",
    "        if self.flowDict['L'] == 0 and self.flowDict['M']== 0: return self.convLinear(uBase=uBase)\n",
    "        if self.flowDict['L'] == 0 and self.flowDict['alpha'] != 0.: return self.convLinear(uBase=uBase)\n",
    "        if self.flowDict['M'] == 0 and self.flowDict['beta'] != 0.: return self.convLinear(uBase=uBase)\n",
    "        \n",
    "        assert self.flowDict['lOffset'] == 0. and self.flowDict['mOffset']==0. ,\\\n",
    "            'convNL() method is currently not supported for flowFields with offsets in l and m. Use convSemiLinear() for linearized term about a base'\n",
    "        \n",
    "        # Ensuring a full set -|M|b,...,0b,..,|M|b is available before computing the convection term\n",
    "        if self.flowDict['M'] > 0 :\n",
    "            obj = self.slice(M=-self.flowDict['M'])\n",
    "            u = obj.getScalar(nd=0); v = obj.getScalar(nd=1) ; w = obj.getScalar(nd=2); tempDict = obj.flowDict.copy()\n",
    "        else:\n",
    "            u = self.getScalar(nd=0);  v = self.getScalar(nd=1); w = self.getScalar(nd=2); tempDict = self.flowDict.copy()\n",
    "        L = tempDict['L']; M = tempDict['M']; N = tempDict['N']\n",
    "        nx = 2*L+1; nz= 2*abs(M)+1\n",
    "        \n",
    "        # Computing the base flow and adding it to the flowField before computing the convection term\n",
    "        y = chebdif(N,1)[0]\n",
    "        if uBase is None:\n",
    "            if tempDict['isPois']==1:\n",
    "                uBase = 1.-y**2\n",
    "            else:\n",
    "                uBase = y\n",
    "        else:\n",
    "            print('I have not written code for uBase!=None yet.')\n",
    "        u[0, L, -M ,0] += uBase\n",
    "                \n",
    "        tempDict = self.flowDict.copy()\n",
    "        tempDict['nd'] = 3\n",
    "        convTerm = flowField(flowDict=tempDict).view4d()\n",
    "        \n",
    "        \n",
    "        ux = u.ddx(); uy = u.ddy(); uz = u.ddz()\n",
    "        vx = v.ddx(); vy = v.ddy(); vz = v.ddz()\n",
    "        wx = w.ddx(); wy = w.ddy(); wz = w.ddz()\n",
    "        \n",
    "        sumArr = lambda v: np.sum( np.sum( np.sum( v, axis=1), axis=1), axis=1)\n",
    "        \n",
    "        for lp in range(self.nx):\n",
    "            l = lp - L\n",
    "            l1 = l; l2 = None; l3 = None; l4 = l1-1; \n",
    "            if l == 0: l4 = None\n",
    "            if l < 0:  \n",
    "                l1 = None; l2 = self.nx+l; l3 = l2-1; l4 = None\n",
    "                \n",
    "            for mp in range(self.nz):\n",
    "                m = mp - abs(M)\n",
    "                m1 = m; m2 = None; m3 = None; m4 = m1-1; \n",
    "                if m == 0: m4 = None\n",
    "                if m < 0: \n",
    "                    m1 = None; m2 = self.nz+m; m3 = m2-1; m4 = None\n",
    "                \n",
    "                convTerm[:,lp,mp,0] += sumArr(u[:,l1:l2,m1:m2]*ux[:,l3:l4:-1,m3:m4:-1])\n",
    "                convTerm[:,lp,mp,0] += sumArr(v[:,l1:l2,m1:m2]*uy[:,l3:l4:-1,m3:m4:-1])\n",
    "                convTerm[:,lp,mp,0] += sumArr(w[:,l1:l2,m1:m2]*uz[:,l3:l4:-1,m3:m4:-1])\n",
    "                \n",
    "                convTerm[:,lp,mp,1] += sumArr(u[:,l1:l2,m1:m2]*vx[:,l3:l4:-1,m3:m4:-1])\n",
    "                convTerm[:,lp,mp,1] += sumArr(v[:,l1:l2,m1:m2]*vy[:,l3:l4:-1,m3:m4:-1])\n",
    "                convTerm[:,lp,mp,1] += sumArr(w[:,l1:l2,m1:m2]*vz[:,l3:l4:-1,m3:m4:-1])\n",
    "                \n",
    "                convTerm[:,lp,mp,2] += sumArr(u[:,l1:l2,m1:m2]*wx[:,l3:l4:-1,m3:m4:-1])\n",
    "                convTerm[:,lp,mp,2] += sumArr(v[:,l1:l2,m1:m2]*wy[:,l3:l4:-1,m3:m4:-1])\n",
    "                convTerm[:,lp,mp,2] += sumArr(w[:,l1:l2,m1:m2]*wz[:,l3:l4:-1,m3:m4:-1])\n",
    "        \n",
    "        convTerm.verify()\n",
    "        if self.flowDict['M']>0:\n",
    "            convTerm = convTerm.slice(M=self.flowDict['M'])\n",
    "        return convTerm\n",
    "        \n",
    "    def residuals(self,pField=None, nonLinear=True, divFree=False, uBase=None, unsteady=False):\n",
    "        ''' Computes the residuals of the momentum equations for a velocity field.\n",
    "        Arguments:\n",
    "        pField is the pressure field (optional). \n",
    "            When not supplied, the pressure is taken to be zero everywhere\n",
    "        nonLinear (flag) defaults to True\n",
    "            When set to False, convLinear() is used to evaluate convection term. When true, convNL() is used.\n",
    "        divFree (flag) defaults to False\n",
    "            When set to False, nothing is done. This means the field could have a non-zero divergence\n",
    "            When set to True, wall-normal velocity is changed to ensure divergence is zero.\n",
    "                WARNING: THIS CHANGES THE FLOWFIELD OBJECT THAT IS PASSED. To avoid this, call self.copy().residuals()\n",
    "        When only a velocity field is available, use solvePressure[1] to get the residuals instead.'''\n",
    "        assert self.nd == 3, 'Method only accepts 3D flowfields'\n",
    "        residual = flowField(flowDict=self.flowDict.copy())\n",
    "        L = self.flowDict['L']; M = self.flowDict['M']\n",
    "        if divFree:\n",
    "            # u_x + v_y + w_z = div. \n",
    "            # To ensure divergence is zero, correct 'v' as v += - \\int div * dy\n",
    "            divergence = self.div()\n",
    "            divergence[np.abs(divergence.copyArray()) < divTol] = 0.j\n",
    "            # vCorrection = -(self.div()).intY()\n",
    "            self.view4d()[:,:,:,1:2] -= divergence.intY()\n",
    "        \n",
    "        if pField is None:\n",
    "            tempDict = self.flowDict.copy(); tempDict['nd'] = 1\n",
    "            pField = flowField(flowDict=tempDict)\n",
    "        else: \n",
    "            assert (pField.nd == 1) and (pField.size == np.int(self.size/3)), 'pField should be a scalar of the same size as each scalar of velocity'\n",
    "        residual[:] += pField.grad() - (1./self.flowDict['Re'])*self.laplacian()\n",
    "        residual[:] += self.convLinear(uBase=uBase)\n",
    "        '''\n",
    "        if nonLinear:\n",
    "            residual[:] += self.convNL(uBase=uBase)\n",
    "        else:\n",
    "            if uBase is None:\n",
    "                residual[:] += self.convLinear(uBase=uBase)\n",
    "            elif uBase.size == self.N: \n",
    "                residual[:] += self.convLinear(uBase=uBase)\n",
    "            else:\n",
    "                residual[:] += self.convSemiLinear(uBase=uBase)\n",
    "        '''\n",
    "        if unsteady: \n",
    "            residual[:] += self.ddt()\n",
    "        \n",
    "        residual[:,:,:,:,[0,-1]] = self[:,:,:,:,[0,-1]]\n",
    "        \n",
    "        return residual\n",
    "    \n",
    "    def solvePressure(self, pField=None, residuals=None, divFree=False, nonLinear=True):\n",
    "        ''' Solves for pressure, given a 3D velocity field.\n",
    "            RETURNS TWO FLOWFIELD INSTANCES: The first one is the corrected pField, the second is the residual when the corrected pressure is used\n",
    "        If pField is supplied, only corrections about this field need to be calculated. The returned field is pField + corrections computed.\n",
    "        If residuals is supplied (should be evaluations of the momentum equations using 'self' and 'pField'), \n",
    "            the NSE need not be evaluated again, and solving for the pressure field is quite fast\n",
    "        If residuals is not supplied, the momentum equations are evaluated in the function, and that takes a while\n",
    "        NOTE: The method does not solve a Poisson equation. \n",
    "        Instead, the following approach is used:\n",
    "            Wall-normal momentum gives wall-normal derivative of each pressure Fourier mode\n",
    "                Integrating the wall-normal gradient gives the pressure up to a constant \n",
    "                In this step, the constant is set such that the pressure at y=1 is zero for each mode\n",
    "            The residuals of streamwise momentum equation and spanwise momentum equation are averaged to get the actual constant (minimizes the residuals)'''\n",
    "        \n",
    "        assert self.nd == 3, 'The flowField instance supplied must be a 3D velocity field'\n",
    "        if pField is not None: \n",
    "            assert isinstance(pField,flowField), 'pField must be a flowField instance'\n",
    "        tempDict = self.flowDict.copy()\n",
    "        tempDict['nd'] = 1\n",
    "        pCorrection = flowField(flowDict=tempDict)\n",
    "        \n",
    "        if pField is None:\n",
    "            pField = flowField(flowDict=tempDict)  # Initializes a zero field\n",
    "        else:\n",
    "            assert pField.size == self.size/3, 'pField must be of the same size of each component of the velocity field'\n",
    "        \n",
    "        # (u.div(v) - 1/Re* laplacian(v) ) + dp_1/dy + dp_Corr/dy= 0,     where p_1 = pField (input argument),p_Corr is the correction\n",
    "        # p_Corr = - \\int residual dy, where residual is the sum of first three terms on LHS\n",
    "        \n",
    "        pCorrection = None\n",
    "        if residuals is None:\n",
    "            residuals = self.residuals(pField=pField, divFree=divFree, nonLinear=nonLinear)\n",
    "        else: \n",
    "            assert isinstance(residuals,flowField) and (residuals.nd == 3) and (residuals.size == self.size), 'residuals must be a 3D flowField object of the same size as self'\n",
    "            \n",
    "        pCorrection = -(residuals.getScalar(nd=1)).intY()\n",
    "        # pCorrection is now determined upto a constant. Next, find the constant that minimizes residual for streamwise, spanwise\n",
    "        \n",
    "        residuals[:,:,:,1:2] += pCorrection.ddy()\n",
    "        residuals[:,:,:,0:1] += pCorrection.ddx()\n",
    "        residuals[:,:,:,2:3] += pCorrection.ddz()\n",
    "        #assert residuals.getScalar(nd=1).norm() < 1.0e-6, 'Wall-normal residual has not gone below 1.0e-6 even after correcting dpdy. Weird'\n",
    "        \n",
    "        # (....) + ilap = 0\n",
    "        # (....) + imbp = 0             a is \\alpha, b is \\beta, l and m identify Fourier mode\n",
    "        # Constant that minimizes streamwise residual norm is   \\int (-(residual_x)/ila) dy\n",
    "        # Creating arrays to hold the constants\n",
    "        constX = np.zeros((self.nt,self.nx,self.nz),dtype=np.complex) \n",
    "        constZ = constX.copy()\n",
    "        \n",
    "        w = clencurt(self.N).reshape((1,1,1,1,self.N))\n",
    "        L = self.flowDict['L']; M = self.flowDict['M']\n",
    "        a = self.flowDict['alpha']; b = self.flowDict['beta']\n",
    "        lArr = np.arange(-L, L+1).reshape((1,self.nx,1,1)) \n",
    "        lArr[0,L] = 1.   # Avoiding zeros, will account for this later (about 10 lines below)\n",
    "        mArr = np.arange( (M-abs(M))/2 , abs(M)+1 ).reshape((1,1,self.nz,1)) \n",
    "        mArr[0,0,-(M-abs(M))/2] = 1.   # Avoiding zeros\n",
    "        \n",
    "        # Corrections only make sense when la != 0 and mb != 0. So keep entries of constX, constZ as zero when la= 0 or mb=0\n",
    "        if a != 0.:\n",
    "            constX[:] = -np.sum( w* (residuals.copyArray()[:,:,:,0]/1.j/lArr/a ), axis=-1)\n",
    "        if b != 0.:\n",
    "            constZ[:] = -np.sum( w* (residuals.copyArray()[:,:,:,2]/1.j/mArr/b ), axis=-1)\n",
    "        \n",
    "        constX[:,L ]  = 0.\n",
    "        constZ[:,:,(abs(M)-M)/2] = 0.\n",
    "        \n",
    "        const = None\n",
    "        if a == 0: const = constZ\n",
    "        elif b==0: const = constX\n",
    "        else: \n",
    "            const = (constX + constZ)/2.\n",
    "            const[:,L] += constZ[:,L]/2.; const[:,:,(abs(M)-M)/2] += constX[:,:,(abs(M)-M)/2] \n",
    "        \n",
    "        const = const.reshape((self.nt,self.nx,self.nz,1))\n",
    "        const[const<pCorrTol] = 0.\n",
    "        \n",
    "        residuals[:,:,:,0] += 1.j*lArr*a*const\n",
    "        residuals[:,:,:,2] += 1.j*mArr*b*const\n",
    "        pCorrection[:,:,:,0] += const\n",
    "        \n",
    "        return (pField.view4d()+pCorrection), residuals\n",
    "        \n",
    "    def printCSV(self,xLoc=None, zLoc=None, tLoc=None, yLoc=None,yOff=0.,pField=None, interY=2,toFile=True,fName='ff'):\n",
    "        '''Prints the velocities and pressure in a CSV file with columns ordered as X,Y,Z,U,V,W,P\n",
    "        Arguments (all keyword):\n",
    "            xzLoc: wall-parallel locations where field variables need to be computed \n",
    "                    (default: [0:2*pi/alpha] 40 points in x when alpha != 0., [0:2*pi/beta] 20 points in z when beta != 0.)\n",
    "            tLoc: temporal locations (default: 7 points when omega != 0, 1 when omega = 0). Fields at different time-locations are printed to different files\n",
    "            pField: Pressure field (computed with divFree=False, nonLinear=True if pField not supplied)\n",
    "            interY: Field data is interpolated onto interY*self.N points before printing. Default for interY is 2\n",
    "            yOff: Use this to define wavy surfaces. For flat walls, yOff = 0. For wavy surfaces, yOff = 2*eps\n",
    "                    yOff is used to modify y-grid as   y[tn,xn,zn] += yOff*cos(alpha*x + beta*z - omega*t)\n",
    "            yLoc: Use this to specify a y-grid. When no grid is specified, Chebyshev nodes are used\n",
    "            fname: Name of CSV file to be printed to. Default: ff.csv \n",
    "            toFile: If true, prints field to file. If false, returns the physical field as a 5-d array\n",
    "                    The 5 dimensions are: (variable, time-location, x-loc, z-loc, y-loc)\n",
    "                    variables are ordered as (x,z,y,u,v,w,p)'''\n",
    "        print('printCSV called.............')\n",
    "        a = self.flowDict['alpha']; b = self.flowDict['beta']; omega = self.flowDict['omega']\n",
    "        K = self.flowDict['K']; L = self.flowDict['L']; M=-np.abs(self.flowDict['M'])\n",
    "        if (a==0.): \n",
    "            return self.printCSVPlanar(etaLoc=zLoc, tLoc=tLoc, yLoc=yLoc,yOff=yOff,pField=pField, interY=interY,toFile=toFile,fName=fName)\n",
    "        if (b==0.): \n",
    "            return self.printCSVPlanar(etaLoc=xLoc, tLoc=tLoc, yLoc=yLoc,yOff=yOff,pField=pField, interY=interY,toFile=toFile,fName=fName)\n",
    "        if xLoc is None:\n",
    "            xLoc = np.arange(0., 2.*np.pi/a, 2.*np.pi/a/40.)\n",
    "        if zLoc is None:\n",
    "            zLoc = np.arange(0., 2.*np.pi/b, 2.*np.pi/b/20.)\n",
    "        if tLoc is None:\n",
    "            if omega != 0.: tLoc = np.arange(0,2.*np.pi/omega, 2.*np.pi/b/7.)\n",
    "            else: tLoc = np.zeros(1)\n",
    "        if yLoc is None:\n",
    "            yLoc = chebdif(interY*self.N,1)[0]\n",
    "            yLocFlag = False\n",
    "        else:\n",
    "            yLocFlag = True\n",
    "            assert isinstance(yLoc,np.ndarray) and (yLoc.ndim == 1), 'yLoc must be a 1D numpy array'\n",
    "            \n",
    "        assert type(yOff) is float, 'yOff characterizes surface deformation and must be of type float'\n",
    "        if '.dat' in fName[-4:]: fName = fName[:-4]\n",
    "        \n",
    "        assert self.nd == 3, 'printCSV() is currently written to handle only 3C velocity fields'\n",
    "        assert isinstance(xLoc,np.ndarray) and isinstance(zLoc,np.ndarray) and isinstance(tLoc,np.ndarray),\\\n",
    "            'xLoc, zLoc, and tLoc must be numpy arrays'\n",
    "        assert isinstance(fName,str), 'fName must be a string'\n",
    "        \n",
    "        if pField is None: pField = self.solvePressure(divFree=False,nonLinear=True)[0]\n",
    "        else:\n",
    "            assert isinstance(pField, flowField), 'pField must be an instance of flowField class'\n",
    "            assert pField.size == self.size//3, 'pField must be the same size of each component of self'\n",
    "        \n",
    "        dataArr = np.zeros((7,tLoc.size,xLoc.size,zLoc.size,yLoc.size))\n",
    "        tLoc = tLoc.reshape(tLoc.size,1,1,1)\n",
    "        xLoc = xLoc.reshape(1,xLoc.size,1,1)\n",
    "        zLoc = zLoc.reshape(1,1,zLoc.size,1)\n",
    "        \n",
    "        if interY != 1:\n",
    "            obj = self.slice(M=M, N=interY*self.N).copy()\n",
    "            p = pField.slice(M=M, N=interY*self.N).copy()\n",
    "        else: obj = self.slice(M=M).copy(); p = pField.slice(M=M).copy()\n",
    "        p = p.view4d()\n",
    "        \n",
    "        if yLocFlag:\n",
    "            objTemp = obj.copy(); pTemp = p.copy()\n",
    "            tempDict = obj.flowDict; tempDict['N'] = yLoc.size\n",
    "            obj = flowField(flowDict=tempDict.copy())\n",
    "            tempDict['nd'] = 1; p = flowField(flowDict=tempDict.copy())\n",
    "            N1 = obj.N ; N2 = objTemp.N\n",
    "            for ind in range(obj.size//obj.N):\n",
    "                obj.view1d()[ind*N1:(ind+1)*N1] = chebint(objTemp.view1d()[ind*N2:(ind+1)*N2],yLoc)\n",
    "            for ind in range(p.size//p.N):\n",
    "                p.view1d()[ind*N1:(ind+1)*N1] = chebint(pTemp.view1d()[ind*N2:(ind+1)*N2],yLoc)\n",
    "        \n",
    "        yLoc = yLoc.reshape(1,1,1,yLoc.size)\n",
    "        u = obj.getScalar(nd=0).copyArray().reshape(obj.nt,obj.nx,obj.nz, obj.N)\n",
    "        v = obj.getScalar(nd=1).copyArray().reshape(obj.nt,obj.nx,obj.nz, obj.N)\n",
    "        w = obj.getScalar(nd=2).copyArray().reshape(obj.nt,obj.nx,obj.nz, obj.N)\n",
    "        p = p.copyArray().reshape(obj.nt,obj.nx,obj.nz, obj.N)\n",
    "        \n",
    "        lArr = (self.flowDict['lOffset']+ np.arange(-L,L+1)).reshape((1,self.nx,1,1))\n",
    "        mArr = (self.flowDict['mOffset']+ np.arange(M,-M+1)).reshape((1,1,self.nz,1))\n",
    "        kArr = np.arange(-K,K+1).reshape((self.nt,1,1,1))\n",
    "        \n",
    "        sumArr = lambda arr: np.sum(np.sum(np.sum(arr,axis=0),axis=0),axis=0).real\n",
    "        dataArr[2] = xLoc; dataArr[1] = zLoc; \n",
    "        dataArr[0] = yLoc + yOff*np.cos(a*xLoc+b*zLoc-omega*tLoc)\n",
    "        for tn in range(tLoc.size):\n",
    "            t = tLoc[tn,0,0,0]\n",
    "            for xn in range(xLoc.size):\n",
    "                x = xLoc[0,xn,0,0]\n",
    "                for zn in range(zLoc.size):\n",
    "                    z = zLoc[0,0,zn,0]\n",
    "                    dataArr[3,tn,xn,zn] = sumArr( u * np.exp( 1.j*(lArr*a*x + mArr*b*z - kArr*omega*t) ) )\n",
    "                    dataArr[4,tn,xn,zn] = sumArr( v * np.exp( 1.j*(lArr*a*x + mArr*b*z - kArr*omega*t) ) )\n",
    "                    dataArr[5,tn,xn,zn] = sumArr( w * np.exp( 1.j*(lArr*a*x + mArr*b*z - kArr*omega*t) ) )\n",
    "                    dataArr[6,tn,xn,zn] = sumArr( p * np.exp( 1.j*(lArr*a*x + mArr*b*z - kArr*omega*t) ) )\n",
    "        \n",
    "        if toFile:\n",
    "            variables = 'VARIABLES = \"Y\", \"Z\", \"X\", \"U\", \"V\", \"W\", \"P\"\\n'\n",
    "            zone = 'ZONE T=\"\", I='+str(yLoc.size)+', J='+str(zLoc.size)+', K='+str(xLoc.size)+', DATAPACKING=POINT'\n",
    "            if tLoc.size == 1:\n",
    "                #np.savetxt(fName+'.csv', dataArr.reshape((7,dataArr.size//7)).T,delimiter=',')\n",
    "                #tempArr = dataArr.reshape(dataArr.size)\n",
    "                title = 'TITLE= \"Flow in wavy walled channel with a='+str(a)+', b='+str(b)+\\\n",
    "                    ',Re_{\\tau}='+str(self.flowDict['Re'])+'\"\\n'\n",
    "                hdr = title+variables+zone\n",
    "                np.savetxt(fName+'.dat',dataArr.reshape(7,dataArr.size//7).T, header=hdr,comments='')\n",
    "                print('Printed physical field to file %s.dat'%fName)\n",
    "            else:\n",
    "                for tn in range(tLoc.size):\n",
    "                    title = 'TITLE= \"Flow in wavy walled channel at t='+str(tLoc[tn,0,0,0])+' with a='+str(a)+', b='+str(b)+\\\n",
    "                        ',Re_{\\tau}='+str(self.flowDict['Re'])+'\"\\n'\n",
    "                    hdr = title+variables+zone\n",
    "                    np.savetxt(fName+str(tn)+'.dat', dataArr[:,tn].reshape((7,dataArr[:,tn].size//7)).T,header=hdr,comments='')\n",
    "                print('Printed %d time-resolved physical fields to files %sX.dat'%(tLoc.size,fName))\n",
    "            return\n",
    "        return dataArr\n",
    "    \n",
    "    def printCSVPlanar(self,nLoc=40,etaLoc=None, tLoc=None, yLoc=None,yOff=0.,pField=None, interY=2,toFile=True,fName='ffPlanar'):\n",
    "        '''Prints flowField on the plane beta*x - alpha*z = 0 (this plane has normal (beta,-alpha)),\n",
    "                in coordinate eta := alpha*x + beta*z\n",
    "        nLoc: Number of wall-parallel locations (uniform grid is defined along the vector (alpha,beta) \n",
    "            starting at a*x+b*z = 0 and ending at a*x+b*z = 2*pi\n",
    "        Refer to printCSV() method's doc-string for description of all other input arguments\n",
    "        '''\n",
    "        assert (type(nLoc) is int), 'nLoc must be int'\n",
    "        a = self.flowDict['alpha']; b = self.flowDict['beta']; omega = self.flowDict['omega']\n",
    "        gama = np.sqrt(a*a+b*b)\n",
    "        K = self.flowDict['K']; L = self.flowDict['L']; M=-np.abs(self.flowDict['M'])\n",
    "        N = np.int(self.N*interY)\n",
    "        if etaLoc is None:  etaLoc = np.arange(0., 4.*np.pi/gama, 2.*np.pi/gama/nLoc)\n",
    "        else: \n",
    "            assert isinstance(etaLoc,np.ndarray), 'etaLoc must be a numpy array'\n",
    "            etaLoc = etaLoc.reshape(etaLoc.size)\n",
    "        if (a == 0.) and (b == 0.):\n",
    "            warn('Both alpha and beta are zero for the flowField. Printing a field at (x,z)=(0,0)')\n",
    "            nLoc=1; etaLoc = np.zeros(1)\n",
    "        \n",
    "        if tLoc is None:\n",
    "            if omega != 0.: tLoc = np.arange(0,2.*np.pi/omega, 2.*np.pi/b/7.)\n",
    "            else: tLoc = np.zeros(1)\n",
    "        if yLoc is None:\n",
    "            yLoc = chebdif(N,1)[0]\n",
    "            yLocFlag = False\n",
    "        else:\n",
    "            yLocFlag = True\n",
    "            assert isinstance(yLoc,np.ndarray) and (yLoc.ndim == 1), 'yLoc must be a 1D numpy array'\n",
    "            \n",
    "        assert type(yOff) is float, 'yOff characterizes surface deformation and must be of type float'\n",
    "        assert isinstance(fName,str), 'fName must be a string'\n",
    "        if '.dat' in fName[-4:]: fName = fName[:-4]\n",
    "        \n",
    "        assert self.nd == 3, 'printCSV() is currently written to handle only 3C velocity fields'\n",
    "        assert isinstance(etaLoc,np.ndarray) and isinstance(tLoc,np.ndarray),\\\n",
    "            'xLoc, zLoc, and tLoc must be numpy arrays'\n",
    "        \n",
    "        \n",
    "        if pField is None: pField = self.solvePressure(divFree=False,nonLinear=True)[0]\n",
    "        else:\n",
    "            assert isinstance(pField, flowField), 'pField must be an instance of flowField class'\n",
    "            assert pField.size == self.size//3, 'pField must be the same size of each component of self'\n",
    "        \n",
    "        dataArr = np.zeros((8,tLoc.size,etaLoc.size,yLoc.size))\n",
    "        tLoc = tLoc.reshape(tLoc.size,1,1)\n",
    "        etaLoc = etaLoc.reshape(1,etaLoc.size,1)\n",
    "        \n",
    "        if interY != 1:\n",
    "            obj = self.slice(M=M, N=interY*self.N).copy()\n",
    "            p = pField.slice(M=M, N=interY*self.N).copy()\n",
    "        else: obj = self.slice(M=M).copy(); p = pField.slice(M=M).copy()\n",
    "        p = p.view4d()\n",
    "        \n",
    "        if yLocFlag:\n",
    "            objTemp = obj.copy(); pTemp = p.copy()\n",
    "            tempDict = obj.flowDict; tempDict['N'] = yLoc.size\n",
    "            obj = flowField(flowDict=tempDict.copy())\n",
    "            tempDict['nd'] = 1; p = flowField(flowDict=tempDict.copy())\n",
    "            N1 = obj.N ; N2 = objTemp.N\n",
    "            for ind in range(obj.size//obj.N):\n",
    "                obj.view1d()[ind*N1:(ind+1)*N1] = chebint(objTemp.view1d()[ind*N2:(ind+1)*N2],yLoc)\n",
    "            for ind in range(p.size//p.N):\n",
    "                p.view1d()[ind*N1:(ind+1)*N1] = chebint(pTemp.view1d()[ind*N2:(ind+1)*N2],yLoc)\n",
    "        \n",
    "        yLoc = yLoc.reshape(1,1,yLoc.size)\n",
    "        u = obj.getScalar(nd=0).copyArray().reshape(obj.nt,obj.nx,obj.nz, obj.N)\n",
    "        v = obj.getScalar(nd=1).copyArray().reshape(obj.nt,obj.nx,obj.nz, obj.N)\n",
    "        w = obj.getScalar(nd=2).copyArray().reshape(obj.nt,obj.nx,obj.nz, obj.N)\n",
    "        p = p.copyArray().reshape(obj.nt,obj.nx,obj.nz, obj.N)\n",
    "        \n",
    "        lArr = (self.flowDict['lOffset']+ np.arange(-L,L+1)).reshape((1,self.nx,1,1))\n",
    "        mArr = (self.flowDict['mOffset']+ np.arange(M,-M+1)).reshape((1,1,self.nz,1))\n",
    "        kArr = np.arange(-K,K+1).reshape((self.nt,1,1,1))\n",
    "        \n",
    "        print('yOff is set as',yOff)\n",
    "        sumArr = lambda arr: np.sum(np.sum(np.sum(arr,axis=0),axis=0),axis=0).real\n",
    "        dataArr[1] = etaLoc; \n",
    "        dataArr[0] = yLoc + yOff*np.cos(gama*etaLoc-omega*tLoc)\n",
    "        for tn in range(tLoc.size):\n",
    "            t = tLoc[tn,0,0]\n",
    "            for en in range(etaLoc.size):\n",
    "                eta = etaLoc[0,en,0]\n",
    "                x = (a/gama)*eta;   z = (b/gama)*eta\n",
    "                dataArr[2,tn,en] = sumArr( u * np.exp( 1.j*(lArr*a*x + mArr*b*z - kArr*omega*t) ) )\n",
    "                dataArr[3,tn,en] = sumArr( v * np.exp( 1.j*(lArr*a*x + mArr*b*z - kArr*omega*t) ) )\n",
    "                dataArr[4,tn,en] = sumArr( w * np.exp( 1.j*(lArr*a*x + mArr*b*z - kArr*omega*t) ) )\n",
    "                dataArr[5,tn,en] = sumArr( p * np.exp( 1.j*(lArr*a*x + mArr*b*z - kArr*omega*t) ) )\n",
    "        # U_parallel and U_cross:\n",
    "        dataArr[6] = a/gama*dataArr[2] + b/gama*dataArr[4]\n",
    "        dataArr[7] = -b/gama*dataArr[2]+ a/gama*dataArr[4]\n",
    "        \n",
    "        if toFile:\n",
    "            if 'eps' in self.flowDict: eps = self.flowDict['eps']; g = eps*a\n",
    "            else: eps = 1.0E-9; g = 0\n",
    "            if a != 0.: theta = int(np.arctan(b/a)*180./np.pi)\n",
    "            else: theta = 90\n",
    "            variables = 'VARIABLES = \"Y\", \"eta\", \"U\", \"V\", \"W\", \"P\", \"U_pl\", \"U_cr\" \\n'\n",
    "            zoneName = 'T'+str(theta)+'E'+str(-np.log10(eps))+'G'+str(g)+'Re'+str(self.flowDict['Re'])\n",
    "            zone = 'ZONE T=\"'+zoneName+ '\", I='+str(yLoc.size)+', J='+str(etaLoc.size)+', DATAPACKING=POINT'\n",
    "            if tLoc.size == 1:\n",
    "                #np.savetxt(fName+'.csv', dataArr.reshape((7,dataArr.size//7)).T,delimiter=',')\n",
    "                #tempArr = dataArr.reshape(dataArr.size)\n",
    "                title = 'TITLE= \"Flow (planar) in wavy walled channel with a='+str(a)+', b='+str(b)+\\\n",
    "                    ',Re_{\\tau}='+str(self.flowDict['Re'])+'\"\\n'\n",
    "                hdr = title+variables+zone\n",
    "                np.savetxt(fName+'.dat',dataArr.reshape(8,dataArr.size//8).T, header=hdr,comments='')\n",
    "                print('Printed physical field to file %s.dat'%fName)\n",
    "            else:\n",
    "                for tn in range(tLoc.size):\n",
    "                    title = 'TITLE= \"Flow (planar) in wavy walled channel at t='+str(tLoc[tn,0,0])+' with a='+str(a)+', b='+str(b)+\\\n",
    "                        ',Re_{\\tau}='+str(self.flowDict['Re'])+'\"\\n'\n",
    "                    hdr = title+variables+zone\n",
    "                    np.savetxt(fName+str(tn)+'.dat', dataArr[:,tn].reshape((8,dataArr[:,tn].size//8)).T,header=hdr,comments='')\n",
    "                print('Printed %d time-resolved physical fields to files %sX.dat'%(tLoc.size,fName))\n",
    "            return\n",
    "        return dataArr\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `flowField.py` not found.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linearizing convection term about a base flow\n",
    "\n",
    "$\\chi = \\chi_b + \\chi_f$ \n",
    "    where $\\chi_b$ is the base flow and $\\chi_f$ the perturbation\n",
    "\n",
    "\n",
    "$\\begin{align}\n",
    "(\\chi.\\nabla)\\chi &= ((\\chi_b+\\chi_f).\\nabla)(\\chi_b+\\chi_f)\\\\\n",
    "        &\\approx \\chi_b.\\nabla \\chi_b + \\chi_b.\\nabla \\chi_f + \\chi_f.\\nabla \\chi_b \\\\\n",
    "\\implies (\\chi.\\nabla)\\chi - (\\chi_b.\\nabla)\\chi_b &= \\chi_b.\\nabla \\chi_f + \\chi_f.\\nabla \\chi_b = C_l\n",
    "\\end{align}$ \n",
    "\n",
    "With the domain transformation stuff, the non-linear terms for stability analysis is going to be a pain to deal with- because when the fluctuation has a wavenumber which isn't an integral multiple of the surface wavenumber, the nice Fourier resolution that I have going right now will get messed up. For today, I'll do this part without worrying about the domain transformation. Just plain old LSA. \n",
    "\n",
    "Supposing $\\chi_b = [U(y),0,0]$, with $\\chi_f = [u_f(y), v_f(y), w_f(y)] e^{i(\\alpha x + \\beta z - \\omega t)}$, and dropping the subscript 'f' henceforth:\n",
    "\n",
    "$C_l[0] = U u_x + v U' \\\\\n",
    "C_l[1] = U v_x \\\\\n",
    "C_l[2] = U w_x $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dot products for different flowField instances\n",
    "\n",
    "Inner products are defined as follows (supposing, WLG, only 2D scalars):\n",
    "\n",
    "$\\begin{align}\n",
    "u^1(x,y) &= \\Sigma_l u^1_l(y) e^{il\\alpha_1 x}\\\\\n",
    "u^2(x,y) &= \\Sigma_m u^2_m(y) e^{im\\alpha_2 x}\\\\\n",
    "<u^1, u^2> &= \\\\\n",
    "\\end{align}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapting flowField class for transformed domains\n",
    "\n",
    "My initial plan was to do something like this\n",
    "    * Define flowField.ddx(), .ddy(),..., along with .grad(), .laplacian(), etc..\n",
    "    * Have keyword arguments passed to .grad(), etc.. that refer to the partial derivatives. For flat-walled flows, the keyword arguments default to .ddx(), .ddy(), .ddz()\n",
    "    * For transformed domains, pass functions other than the default .ddx(), etc.. to reflect the coordinate transformation. For instance, pass partialX = self.ddx() + Tfun*self.ddy()\n",
    "\n",
    "\n",
    "But I think that would complicate things a bit too much. So, new strategy:\n",
    "    * No keyword arguments for .grad(), etc... They always call self.ddx(), self.ddy(), self.ddz().\n",
    "    * Overload .ddx(), .ddy(), .ddz() in the subclass of flowField\n",
    "\n",
    "If I make methods such as .grad() use self.ddx() instead of flowField.ddx(), then then the overloaded methods would be used. That's all I need. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making uBase more generic\n",
    "\n",
    "The current version of the code takes uBase to be just [$u_{000}$(y), 0,0]. \n",
    "\n",
    "I need to extend this to more general cases, either for domain transformation or for higher classes of base flows, where uBase is a bigger vector with 3C along different Fourier modes. \n",
    "\n",
    "## Adding attributes kArr, lArr, mArr\n",
    "\n",
    "Currently, the default for Fourier mode wavenumbers is integer multiples of $\\omega, \\alpha,\\beta$. So, whenever a partial derivative along x,z, or t is requested, I create `kArr`, `lArr`, and `mArr` as arrays of integers. \n",
    "\n",
    "But for domain transformation problems, there are two length scales- the scale of the field variables (especially for fluctuations), and the scale of the surface-waviness. When these two length scales are not low integer multiples, I will have to have `kArr`, `lArr`, and `mArr`with non-integer entries. The simplest way to implement this, that I can think of right now, is to define the arrays as attributes of the flowField during initialization.\n",
    "\n",
    "For the domain transformation cases, I can initialize using the default integer arrays, and then add a constant to reflect the wavenumber of the field variable. \n",
    "\n",
    "## Introducing kOffset, lOffset, mOffset instead of kArr, lArr, mArr\n",
    "\n",
    "The reason that I wanted to introduce kArr, lArr, mArr above was so the class could deal with, most importantly, the following case:\n",
    "    If a fluctuation with wavenumbers that are not integer multiples of the wavenumbers of the existing base flow is introduced, its energy would disperse (linearly) into wavenumbers that are, again, not integer multiples of wavenumbers of the base flow. \n",
    "    \n",
    "But, the dispersion would only be into wavenumbers that are offset by a constant amount. \n",
    "\n",
    "To illustrate, suppose the base flow has modes of wavenumbers (-3a,-2a,-a,0,a,2a,3a). If a fluctuation of wavenumber 1.3a is introduced, its energy would disperse linearly (due to the base flow) into wavenumbers(-1.7,-0.7,0.3,1.3,2.3,3.3,4.3)a. \n",
    "\n",
    "Even for wavy walled flows, the above relation holds as long as only solutions periodic in surface waviness are considered. \n",
    "\n",
    "Instead of defining an lArr to indicate the wavenumbers to which energy has dispersed, I can simply say that it's still the same (-3,-2,-1,0,1,2,3)a, except with an offset of 1.3a. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting eigenvalue solver.........\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error in inverting [A-sigma*M]: function gmres did not converge (info = 1050).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-85664efb81dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m '''\n\u001b[0;32m     51\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Starting eigenvalue solver.........'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m \u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mevecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meigs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mALO\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhich\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'LR'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.022\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m0.j\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;31m#sigma = 0.02+0.j\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;31m#nullFun = lambda v: ALO.matvec(v)-sigma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3/dist-packages/scipy/sparse/linalg/eigen/arpack/arpack.py\u001b[0m in \u001b[0;36meigs\u001b[1;34m(A, k, M, sigma, which, v0, ncv, maxiter, tol, return_eigenvectors, Minv, OPinv, OPpart)\u001b[0m\n\u001b[0;32m   1272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1273\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverged\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1274\u001b[1;33m         \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1276\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreturn_eigenvectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3/dist-packages/scipy/sparse/linalg/eigen/arpack/arpack.py\u001b[0m in \u001b[0;36miterate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    733\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[0mBxslice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mipntr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mipntr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 735\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworkd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0myslice\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPa\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworkd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBxslice\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    736\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mido\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    737\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworkd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0myslice\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworkd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mxslice\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3/dist-packages/scipy/sparse/linalg/interface.py\u001b[0m in \u001b[0;36mmatvec\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dimension mismatch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_matvec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3/dist-packages/scipy/sparse/linalg/eigen/arpack/arpack.py\u001b[0m in \u001b[0;36m_matvec\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    995\u001b[0m             raise ValueError(\"Error in inverting [A-sigma*M]: function \"\n\u001b[0;32m    996\u001b[0m                              \u001b[1;34m\"%s did not converge (info = %i).\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 997\u001b[1;33m                              % (self.ifunc.__name__, info))\n\u001b[0m\u001b[0;32m    998\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error in inverting [A-sigma*M]: function gmres did not converge (info = 1050)."
     ]
    }
   ],
   "source": [
    "## Test code for linear stability analysis\n",
    "import scipy as sp\n",
    "from scipy.sparse.linalg import LinearOperator, eigs, svds\n",
    "import numpy as np\n",
    "from flowField import *\n",
    "\n",
    "flowDict = getDefaultDict()\n",
    "flowDict['K'] = 0;\n",
    "flowDict['L'] = 0;\n",
    "flowDict['M'] = 0;\n",
    "flowDict['alpha'] = 1.; flowDict['beta'] = 0.\n",
    "flowDict['isPois'] = 1\n",
    "flowDict['Re'] = 2000.\n",
    "pDict = flowDict.copy(); pDict['nd'] = 1\n",
    "\n",
    "ff = flowField(flowDict=flowDict)\n",
    "scalarSize = ff.size//3\n",
    "\n",
    "def residFun(arr):\n",
    "    assert isinstance(arr,np.ndarray) and not isinstance(arr,flowField), 'residFun only accepts a numpy array as argument'\n",
    "    assert arr.size == 3*scalarSize, 'Array size is not consistent with flowDict attributes'\n",
    "    arr = arr.reshape(arr.size)\n",
    "    vField = flowField(arr=np.append(arr[:2*scalarSize],np.zeros(scalarSize,dtype=np.complex)), flowDict=flowDict.copy())\n",
    "    pField = flowField(arr=arr[2*scalarSize:], flowDict = pDict.copy())\n",
    "    assert vField.dtype==np.complex and pField.dtype==np.complex\n",
    "    resid = vField.residuals(pField=pField,divFree=True,nonLinear=False,unsteady=False).weighted()\n",
    "    assert resid.dtype== np.complex, 'Residuals should be complex, but here it is not'\n",
    "    resid = resid.view1d().copyArray()\n",
    "    assert not isinstance(resid,flowField), 'resid should not be a flowField instance, but strangely, it is'\n",
    "    return resid\n",
    "'''\n",
    "def Mmat(arr):\n",
    "    arrCopy = arr.reshape(arr.size).copy()\n",
    "    arrCopy[3*arrCopy.size//4:] = 0.\n",
    "    return arrCopy\n",
    "'''\n",
    "\n",
    "#MLO = LinearOperator(shape=(3*scalarSize,3*scalarSize), matvec=Mmat, dtype=np.complex)\n",
    "ALO = LinearOperator(shape=(3*scalarSize,3*scalarSize), matvec=residFun, dtype=np.complex)\n",
    "\n",
    "'''\n",
    "#ALO.matvec(ff.view1d().copyArray())\n",
    "farr = ff.view1d().copyArray()\n",
    "vField = flowField(arr=np.append(farr[:2*scalarSize],np.zeros(scalarSize,dtype=np.complex)), flowDict=flowDict.copy())\n",
    "pField = flowField(arr=farr[2*scalarSize:], flowDict = pDict.copy())\n",
    "resid = vField.residuals(pField=pField,divFree=False,nonLinear=False,unsteady=False)\n",
    "\n",
    "divergence = vField.div()\n",
    "abs(divergence.copyArray())<divTol\n",
    "'''\n",
    "print('Starting eigenvalue solver.........')\n",
    "evals,evecs = eigs(ALO, k=1, which='LR', sigma=0.022+0.j,maxiter=50)\n",
    "#sigma = 0.02+0.j\n",
    "#nullFun = lambda v: ALO.matvec(v)-sigma\n",
    "#NLO = LinearOperator(shape=(3*scalarSize,3*scalarSize), matvec=nullFun, dtype=np.complex)\n",
    "#print(ALO)\n",
    "#nSpace = nullspace(NLO)\n",
    "#u,s,vt = svds(NLO,k=1, which='SM', maxiter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evals' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a82653b0d6d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mevals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1.j\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'evals' is not defined"
     ]
    }
   ],
   "source": [
    "from scipy.linalg import norm\n",
    "evals = 1./evals\n",
    "print(evals)\n",
    "print(evals/-1.j)\n",
    "\n",
    "print(norm(ALO.matvec(evecs[:,0]) - evals[0]*evecs[:,0]))\n",
    "#norm(ALO.matvec(evecs[:,1]) - evals[1]*evecs[:,1])\n",
    "print(type(ALO.matvec(evecs[:,0])))\n",
    "#ff = flowField()\n",
    "print(type(evals[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 47, 24, 3, 35) (1, 47, 24, 3, 35) (1, 47, 24, 3, 35) (1, 47, 24, 3, 35) (1, 47, 24, 1, 35) (1, 47, 24, 2, 35) (1, 47, 24, 4, 35) (1, 47, 24, 3, 35) (1, 47, 24, 2, 35) (1, 47, 24, 2, 35) (1, 47, 24, 3, 35) (1, 47, 24, 1, 35) (1, 47, 24, 3, 35) (1, 47, 24, 3, 35) (1, 47, 24, 3, 35)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/IPython/kernel/__main__.py:80: UserWarning: No flowDict was supplied. Assigning the default dictionary\n"
     ]
    }
   ],
   "source": [
    "#from flowField import *\n",
    "ff = flowField()\n",
    "ff1 = ff.ddx()\n",
    "ff2 = ff.ddy()\n",
    "ff3 = ff.ddz()\n",
    "ff4 = ff.ddt()\n",
    "ff5 = ff.getScalar(nd=2)\n",
    "pff = ff.getScalar(nd=1)\n",
    "ff6 = ff5.appendField(pff)\n",
    "u = ff.getScalar()\n",
    "v = ff.getScalar(nd=1)\n",
    "wp = ff.slice(nd = [2,1])\n",
    "ff7 = makeVector(u,v,wp)\n",
    "uGrad = u.grad3d()\n",
    "uGrad2d = u.grad2d()\n",
    "vGrad2d = ff.grad2d(scalDim=1)\n",
    "ff8 = ff.convLinear()\n",
    "ff9 = ff.div()\n",
    "ff10 = ff.convNL()\n",
    "ff11 = ff.convSemiLinear()\n",
    "ff12 = ff.curl()\n",
    "\n",
    "print(ff1.shape,ff2.shape,ff3.shape,ff4.shape, ff5.shape, ff6.shape, ff7.shape, uGrad.shape, uGrad2d.shape, vGrad2d.shape, ff8.shape, ff9.shape, ff10.shape, ff11.shape, ff12.shape)\n",
    "ff.verify()\n",
    "ff1.verify()   # Prints error/warning messages if something's wrong, otherwise returns no output\n",
    "ff2.verify()\n",
    "ff3.verify()\n",
    "ff4.verify()\n",
    "ff5.verify()\n",
    "ff6.verify()\n",
    "ff7.verify()\n",
    "uGrad.verify()\n",
    "ff8.verify()\n",
    "ff9.verify()\n",
    "ff10.verify()\n",
    "ff11.verify()\n",
    "ff12.verify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing flowField class with exact solutions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import numpy as np\n",
    "from pseudo import *\n",
    "\n",
    "f = np.genfromtxt('eq1.asc',dtype=np.complex)\n",
    "f_p = np.genfromtxt('peq1.asc',dtype=np.complex)\n",
    "   \n",
    "x = f[:,3];x_p = f_p[:,3]\n",
    "\n",
    "# From the database at channelflow.org\n",
    "Re=4.0e2\n",
    "a=1.14\n",
    "b=2.5\n",
    "\n",
    "nx = 48\n",
    "nz = 25\n",
    "L = 24\n",
    "M = 24\n",
    "N = 35\n",
    "\n",
    "# In input file, ordering of modes is different from what I would like it to be.\n",
    "# It goes, 0,1,..,24,-23,-22,....,-1 in 'x'\n",
    "# I prefer, -23,-22,..,-1,0,1,...,22,23\n",
    "# In 'z', it's just 0,..,24 \n",
    "#     Negative wavenumbers are not included due to symmetry.\n",
    "\n",
    "# First, getting rid of mode 24 in both x and z \n",
    "modes = x.reshape((nx,nz,3,N))\n",
    "modes = sp.append(modes,x_p.reshape((nx,nz,1,N)),axis=2)\n",
    "modes = sp.delete(modes,L,0)\n",
    "modes = sp.delete(modes,M,1)\n",
    "\n",
    "\n",
    "nx = nx-1 \n",
    "nz = nz-1\n",
    "L = L-1\n",
    "M = M-1\n",
    "\n",
    "# Now, reordering streamwise wavenumbers\n",
    "modes = sp.append(modes[L+1:,:,:,:],modes[:L+1,:,:,:],0)\n",
    "del x,x_p,f,f_p\n",
    "\n",
    "\n",
    "# Projecting Cheb coefficients onto Cheb collocation nodes\n",
    "for kx in range(0,nx):\n",
    "    for kz in range(0,nz):\n",
    "        for nd in range(0,4):\n",
    "            modes[kx,kz,nd,:] = chebcoll_vec(modes[kx,kz,nd,:])\n",
    "\n",
    "# Adding modes for negative spanwise wavenumbers. \n",
    "#modes = sp.append(sp.append(modes[:15:-1,:0:-1,:,:].conjugate(),modes[15::-1,:0:-1,:,:].conjugate(),axis=0),modes,axis=1)\n",
    "modes = sp.append(modes[::-1,:0:-1].conjugate(),modes,axis=1)\n",
    "nz = nx\n",
    "\n",
    "#modes = modes[15:nx-15, 15:nz-15,:,:]\n",
    "#nx = nx-30\n",
    "#nz = nz-30\n",
    "#L = L-15\n",
    "#M = M-15\n",
    "\n",
    "\n",
    "#p_temp = modes[:,:,3]\n",
    "## Removing boundary nodes:\n",
    "#modes = sp.delete(modes,(0,N-1),3)\n",
    "\n",
    "# Deleting pressure from state-vector:\n",
    "p = modes[:,:,3]\n",
    "modes = sp.delete(modes,3,2)\n",
    "\n",
    "## Deleting wall-normal velocity from state-vector:\n",
    "# v = modes[:,:,1,:]\n",
    "# modes = sp.delete(modes,1,2)\n",
    "\n",
    "## Defining wall-normal grid, and differentiation matrices\n",
    "#y,DM = chebdif(N,2)\n",
    "#D = DM[:,:,0]\n",
    "#D2 = DM[:,:,1]\n",
    "\n",
    "vecsize = nx*nz*N\n",
    "# Finally, reshaping to get a state-vector containing u and w\n",
    "x0 = modes.reshape(3*vecsize)\n",
    "p = p.reshape(vecsize)\n",
    "del modes\n",
    "#print(modes[L,M,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-22bbb7658be1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtempDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'M'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m23\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtempDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'nd'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mvField\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflowField\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflowDict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtempDict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mvField\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mtempDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'nd'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mpField\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflowField\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflowDict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtempDict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mpField\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x0' is not defined"
     ]
    }
   ],
   "source": [
    "from scipy.linalg import norm\n",
    "#from flowField import *\n",
    "tempDict = getDefaultDict()\n",
    "tempDict['M'] = -23\n",
    "tempDict['nd'] = 3\n",
    "vField = flowField(arr=x0, flowDict=tempDict.copy()); vField.verify()\n",
    "tempDict['nd'] = 1\n",
    "pField = flowField(arr=p.reshape(p.size), flowDict=tempDict.copy()); pField.verify()\n",
    "\n",
    "'''\n",
    "residuals = vField.residuals(pField=pField,nonLinear=True)\n",
    "print('Norm of residual:',residuals.norm())\n",
    "print('From earlier version, Norm is supposed to be ~ 2.6876e-06')\n",
    "\n",
    "pNew, resids = vField.solvePressure(residuals=residuals, pField=pField, nonLinear=True, divFree=False)\n",
    "print('Norm of correction in pField with solvePressure:',(pField-pNew).norm())\n",
    "print('Norm after correction in pField',resids.norm())\n",
    "'''\n",
    "#vField.printCSV(pField=pField, yLoc=np.arange(1.,-1.,-0.1),fName='ff1')\n",
    "#vField.printCSVPlanar(pField=pField)\n",
    "vField.printCSV(pField=pField)\n",
    "#norm(vField.div())\n",
    "#vField.div().intY().shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm of residual: 0.0\n",
      "Norm of correction in pField with solvePressure: 0.0\n",
      "Norm after correction in pField 0.0\n"
     ]
    }
   ],
   "source": [
    "tempDict = getDefaultDict()\n",
    "tempDict['M'] = -23\n",
    "tempDict['nd'] = 3\n",
    "vField1 = flowField(flowDict=tempDict.copy()); vField.verify()\n",
    "tempDict['nd'] = 1\n",
    "pField1 = flowField(flowDict=tempDict.copy()); pField.verify()\n",
    "\n",
    "residuals1 = vField1.residuals(pField=pField1,nonLinear=True)\n",
    "print('Norm of residual:',residuals1.norm())\n",
    "#print('From earlier version, Norm is supposed to be ~ 2.6876e-06')\n",
    "\n",
    "pNew1, resids1 = vField1.solvePressure(residuals=residuals1, pField=pField1, nonLinear=True, divFree=False)\n",
    "print('Norm of correction in pField with solvePressure:',(pField1-pNew1).norm())\n",
    "print('Norm after correction in pField',resids1.norm())\n",
    "\n",
    "#norm(vField.div())\n",
    "#vField.div().intY().shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying residual for Poiseuille flow\n",
      "Norm of residual: 0.0\n",
      "Norm of correction in pField with solvePressure: 0.0\n",
      "Norm after correction in pField 0.0\n"
     ]
    }
   ],
   "source": [
    "tempDict = getDefaultDict()\n",
    "tempDict['M'] = -23\n",
    "tempDict['isPois'] = 1\n",
    "print('Verifying residual for Poiseuille flow')\n",
    "tempDict['nd'] = 3\n",
    "vField1 = flowField(flowDict=tempDict.copy()); vField.verify()\n",
    "tempDict['nd'] = 1\n",
    "pField1 = flowField(flowDict=tempDict.copy()); pField.verify()\n",
    "\n",
    "residuals1 = vField1.residuals(pField=pField1,nonLinear=True)\n",
    "print('Norm of residual:',residuals1.norm())\n",
    "#print('From earlier version, Norm is supposed to be ~ 2.6876e-06')\n",
    "\n",
    "pNew1, resids1 = vField1.solvePressure(residuals=residuals1, pField=pField1, nonLinear=True, divFree=False)\n",
    "print('Norm of correction in pField with solvePressure:',(pField1-pNew1).norm())\n",
    "print('Norm after correction in pField',resids1.norm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laplacian norm: 0.00857338489618\n",
      "pGrad norm: 0.00596760920711\n",
      "Convection (linear) norm: 0.0\n",
      "Divergence norm: 1.23457070118e-10\n"
     ]
    }
   ],
   "source": [
    "Re = vField.flowDict['Re']\n",
    "print('Laplacian norm:',(1/Re*vField).laplacian().norm())\n",
    "print('pGrad norm:',pField.grad().norm())\n",
    "print('Convection (linear) norm:', vField.convLinear().norm())\n",
    "print('Divergence norm:', vField.div().norm())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overloading methods for inheriting classes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let us see what meth2 of A returns when overloaded: 14\n",
      "Let us see what meth2 of A returns when overloaded: 20\n",
      "type of instB is <class '__main__.B'>\n"
     ]
    }
   ],
   "source": [
    "class A:\n",
    "    def __init__(self,num):\n",
    "        self.num = num\n",
    "        \n",
    "    def double(self):\n",
    "        print('Method returns ', self.num)\n",
    "        \n",
    "    def meth2(self):\n",
    "        return 11+self.num\n",
    "        \n",
    "    def testMethod(self):\n",
    "        print('Let us see what meth2 of A returns when overloaded:',self.meth2())\n",
    "\n",
    "class B(A):\n",
    "    def __init__(self,num):\n",
    "        A.__init__(self,num)\n",
    "    \n",
    "    def double(self):\n",
    "        A.double(self)\n",
    "        print('Method returns',2*self.num)\n",
    "        \n",
    "    def meth2(self):\n",
    "        return 17+self.num\n",
    "\n",
    "        \n",
    "instA = A(3)\n",
    "instA.testMethod()\n",
    "\n",
    "instB = B(3)\n",
    "instB.testMethod()\n",
    "\n",
    "instB.num\n",
    "\n",
    "print('type of instB is', type(instB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## subclass of flowField: flowFieldWavy\n",
    "\n",
    "For starters, define the class for geometries with just 1 surface wavenumber. Extend it later to cover arbitrary surfaces with multiple wavenumbers. \n",
    "\n",
    "The `alpha` and `beta` keys in the flowDict will give both the surface wavenumber and the periodicity of the flowfield being described. For laminar solutions, and possibly other exact solutions, this should suffice. For linear stability analysis, the `lOffset` and `mOffset` should do the job. \n",
    "\n",
    "With `alpha` and `beta` defined, the only parameter needed to define the surface geometry is `epsilon` (call it eps). \n",
    "\n",
    "The surfaces are defined as follows:\n",
    "    \n",
    "    y_surf = +/- 1 + 2*eps* cos(alpha*x + beta*z) = +/- 1 + eps*[ exp(i(alpha*x + beta*z)) + exp(-i(alpha*x + beta*z))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting flowFieldWavy.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile flowFieldWavy.py\n",
    "from flowField import *\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "\n",
    "def mat2ff(arr=None, **kwargs):\n",
    "    '''Converts state-vectors from my MATLAB solutions to flowField objects.\n",
    "        Once a solution is converted to a flowField object, it's .printCSV can be called for visualization.\n",
    "    All parameters are keyword-parameters: arr (state-vec), a,b,eps,Re,N,n'''\n",
    "    assert isinstance(arr,np.ndarray), 'A numpy array must be passed as the state-vector using keyword \"arr\"'\n",
    "    assert set(['a','b','Re','N','eps','n']).issubset(kwargs), 'a,b,Re,eps,N, and n must be supplied as keyword arguments'\n",
    "    assert all((type(kwargs[k]) is float) or (type(kwargs[k]) is int) for k in kwargs)\n",
    "    tempDict = {'alpha':kwargs['a'],   'beta' : kwargs['b'], 'omega':0.0,   'K':0, \\\n",
    "                'L': abs(int(kwargs['n'])), 'M': -abs(int(kwargs['n'])),  'nd':3,  'N': abs(int(kwargs['N'])), \\\n",
    "                'Re': kwargs['Re'], 'isPois':1,  'eps': kwargs['eps'], \\\n",
    "                'noise':0.0 , 'lOffset':0.0, 'mOffset':0.0}\n",
    "    n = tempDict['L']; N = tempDict['N']\n",
    "    xind = 1; zind = 1\n",
    "    if kwargs['a'] == 0.: tempDict['L'] = 0; xind = 0\n",
    "    if kwargs['b'] == 0.: tempDict['M'] = 0; zind = 0\n",
    "    \n",
    "    assert arr.size == (2*n+1)*4*N, 'Size of state-vector is not consistent with supplied \"n\" and \"N\"'\n",
    "    arr = arr.reshape((2*n+1, 4, N))\n",
    "    \n",
    "    vField = flowFieldWavy(flowDict=tempDict)\n",
    "    pDict = tempDict.copy(); pDict['nd']= 1\n",
    "    pField = flowFieldWavy(flowDict=pDict)\n",
    "    for k in range(2*n+1):\n",
    "        vField[0,k*xind, k*zind] = arr[k,:3]\n",
    "        pField[0,k*xind, k*zind] = arr[k,3:]\n",
    "    return vField, pField\n",
    "\n",
    "def data2ff(fName=None, ind=None):\n",
    "    '''Reads a datafile with name fName. '''\n",
    "    assert isinstance(fName,str), 'fName must be a string'\n",
    "    if fName[-4:] != '.mat': fName = fName + '.mat'\n",
    "    dataFile = sio.loadmat(fName, struct_as_record=False)\n",
    "    dataStruct = dataFile['solution']\n",
    "    nCases = dataStruct.shape[0]\n",
    "    \n",
    "    if (ind is not None) and (type(ind) is int):\n",
    "        matArr = dataStruct[ind,0].X\n",
    "        params = dataStruct[ind,0].Param; params=params.reshape(params.size)\n",
    "        a=float(params[0]);b=float(params[1]); eps=float(params[2]); Re=float(params[4]); N=int(params[5]); n=int(params[6])\n",
    "        g = a*eps;  fnorm = float(params[-1])\n",
    "        if fnorm > 1.0e-5: \n",
    "            warn('Residual norm for the case is quite large and the solution cannot be trusted. Initializing a zero flowfield')\n",
    "            matArr = np.zeros(matArr.shape, dtype=np.complex)\n",
    "        vF, pF = mat2ff(arr=matArr,a=a,b=b,Re=Re,n=n,eps=eps,N=N)\n",
    "        return vF, pF, {'eps':eps, 'g':g, 'Re':Re, 'a':a, 'b': b, 'fnorm':fnorm}\n",
    "    else:\n",
    "        vFieldList = []\n",
    "        pFieldList = []\n",
    "        epsArr = np.zeros(nCases); gArr = epsArr.copy(); bArr = epsArr.copy(); ReArr = epsArr.copy(); aArr = epsArr.copy(); fnormArr=epsArr.copy()\n",
    "        for k in range(nCases):\n",
    "            matArr = dataStruct[k,0].X\n",
    "            params = dataStruct[k,0].Param; params=params.reshape(params.size)\n",
    "            a=float(params[0]);b=float(params[1]); eps=float(params[2]); Re=float(params[4]); N=int(params[5]); n=int(params[6])\n",
    "            g = a*eps;  fnorm = float(params[-1])\n",
    "            if fnorm > 1.0e-5: \n",
    "                warn('Residual norm for the case is quite large and the solution cannot be trusted. Initializing a zero flowfield')\n",
    "                matArr = np.zeros(matArr.shape, dtype=np.complex)\n",
    "            vF, pF = mat2ff(arr=matArr,a=a,b=b,Re=Re,n=n,eps=eps,N=N )\n",
    "            vFieldList.append(vF)\n",
    "            pFieldList.append(pF)\n",
    "            epsArr[k] = eps;  gArr[k] = a*eps; ReArr[k] = Re; bArr[k] = b; aArr[k] = a; fnormArr[k] = fnorm\n",
    "        return vFieldList, pFieldList, {'eps':epsArr, 'g':gArr, 'Re':ReArr, 'a':aArr, 'b': bArr, 'fnorm':fnormArr}\n",
    "    \n",
    "\n",
    "class flowFieldWavy(flowField):\n",
    "    '''Subclass of flowField\n",
    "    Corresponds to sinusoidal channel flows (pressure-gradient driven or wall-motion driven)\n",
    "    Adds an extra attribute \"eps\" as a key in flowDict\n",
    "    \n",
    "    Overloads methods for differentiation: ddx, ddx2,ddy,..., along with .printCSV()'''\n",
    "    def __new__(cls,arr=None,flowDict=None,dictFile=None):\n",
    "        #obj = flowField.__new__(flowFieldWavy,arr=arr,flowDict=flowDict,dictFile=dictFile)\n",
    "        obj = flowField.__new__(cls,arr=arr,flowDict=flowDict,dictFile=dictFile)\n",
    "        if 'eps' not in obj.flowDict:\n",
    "            warn('flowFieldWavy object does not have key \"eps\" in its dictionary. Setting \"eps\" to zero')\n",
    "            obj.flowDict['eps'] = 0.\n",
    "        else:\n",
    "            assert type(obj.flowDict['eps']) is float, 'eps in flowDict must be of type float'\n",
    "        obj.verify()\n",
    "        return obj\n",
    "    \n",
    "    def printCSV(self,**kwargs):\n",
    "        '''Refer to flowField.printCSV()\n",
    "        This method sets \"yOff\" to 2*eps'''\n",
    "        kwargs['yOff'] = 2.*self.flowDict['eps']\n",
    "        return flowField.printCSV(self,**kwargs)\n",
    "    \n",
    "    def printCSVPlanar(self,**kwargs):\n",
    "        '''Refer to flowField.printCSVPlanar()'''\n",
    "        kwargs['yOff'] = 2.*self.flowDict['eps']\n",
    "        print('yOff in ffwavy is set as',kwargs['yOff'])\n",
    "        return flowField.printCSVPlanar(self,**kwargs)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 47, 24, 3, 35) (1, 47, 24, 3, 35) (1, 47, 24, 3, 35) (1, 47, 24, 3, 35) (1, 47, 24, 1, 35) (1, 47, 24, 2, 35) (1, 47, 24, 4, 35) (1, 47, 24, 3, 35) (1, 47, 24, 2, 35) (1, 47, 24, 2, 35) (1, 47, 24, 3, 35) (1, 47, 24, 1, 35) (1, 47, 24, 3, 35) (1, 47, 24, 3, 35) (1, 47, 24, 3, 35)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/IPython/kernel/__main__.py:92: UserWarning: No flowDict was supplied. Assigning the default dictionary\n",
      "/usr/local/lib/python3.4/dist-packages/IPython/kernel/__main__.py:12: UserWarning: flowFieldWavy object does not have key \"eps\" in its dictionary. Setting \"eps\" to zero\n"
     ]
    }
   ],
   "source": [
    "ff = flowFieldWavy()\n",
    "ff1 = ff.ddx()\n",
    "ff2 = ff.ddy()\n",
    "ff3 = ff.ddz()\n",
    "ff4 = ff.ddt()\n",
    "ff5 = ff.getScalar(nd=2)\n",
    "pff = ff.getScalar(nd=1)\n",
    "ff6 = ff5.appendField(pff)\n",
    "u = ff.getScalar()\n",
    "v = ff.getScalar(nd=1)\n",
    "wp = ff.slice(nd = [2,1])\n",
    "ff7 = makeVector(u,v,wp)\n",
    "uGrad = u.grad3d()\n",
    "uGrad2d = u.grad2d()\n",
    "vGrad2d = ff.grad2d(scalDim=1)\n",
    "ff8 = ff.convLinear()\n",
    "ff9 = ff.div()\n",
    "ff10 = ff.convNL()\n",
    "ff11 = ff.convSemiLinear()\n",
    "ff12 = ff.curl()\n",
    "\n",
    "print(ff1.shape,ff2.shape,ff3.shape,ff4.shape, ff5.shape, ff6.shape, ff7.shape, uGrad.shape, uGrad2d.shape, vGrad2d.shape, ff8.shape, ff9.shape, ff10.shape, ff11.shape, ff12.shape)\n",
    "ff.verify()\n",
    "ff1.verify()   # Prints error/warning messages if something's wrong, otherwise returns no output\n",
    "ff2.verify()\n",
    "ff3.verify()\n",
    "ff4.verify()\n",
    "ff5.verify()\n",
    "ff6.verify()\n",
    "ff7.verify()\n",
    "uGrad.verify()\n",
    "ff8.verify()\n",
    "ff9.verify()\n",
    "ff10.verify()\n",
    "ff11.verify()\n",
    "ff12.verify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-a8a3acd6e799>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mvField\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mff\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpField\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mff\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetScalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mresid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvField\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresiduals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpField\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpField\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdivFree\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnonLinear\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0munsteady\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/sabarish/Dropbox/gitwork/python3/flowField/flowField.py\u001b[0m in \u001b[0;36mresiduals\u001b[1;34m(self, pField, nonLinear, divFree, uBase, unsteady)\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mresidual\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muBase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muBase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    728\u001b[0m         '''\n\u001b[1;32m--> 729\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mnonLinear\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    730\u001b[0m             \u001b[0mresidual\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvNL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muBase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muBase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "vField = ff.copy()\n",
    "pField = ff.getScalar(nd=0)\n",
    "resid = vField.residuals(pField=pField,divFree=False,nonLinear=False,unsteady=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yOff in ffwavy is set as 0.00447744227713668\n",
      "yOff is set as 0.00447744227713668\n",
      "Printed physical field to file tecFiles/wavyE2.65G0.44999999999999996Re1000.dat\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from flowField import *\n",
    "from flowFieldWavy import *\n",
    "\n",
    "# eps = 10^(-3.+0.025*fileind)   => fileind = 40*(log10(eps) +3)\n",
    "# g0 = [0.2:0.025:0.6]    => gind = 40*(g-0.2)\n",
    "# g1 = [0.65:0.05:1.2, 1.3,1.4,1.5]   => gind = 20*(g-)\n",
    "eps = 0.01/4.;  g = 0.9/2.; Re = 1000\n",
    "\n",
    "gFileInd = 0\n",
    "gInd = int(40*(g-0.2))\n",
    "if g> 0.6:\n",
    "    gFileInd = 1\n",
    "    gInd = int(20*(g-0.65))\n",
    "    if gInd > 11: gInd = int((gInd-11)/2+11)\n",
    "ReInd = np.int(np.log10(Re)-1)\n",
    "        \n",
    "eFileInd = 2*int(40*(np.log10(eps)+3)/2)\n",
    "\n",
    "folderPath = '/home/sabarish/matData/'\n",
    "fileName = 'dataSeprn'+str(gFileInd)+'b0_'+str(eFileInd)+'.mat'\n",
    "\n",
    "#vfList, pfList,paramDict = data2ff(fName=folderPath+fileName,ind=gInd)\n",
    "vf, pf,paramDict = data2ff(fName=folderPath+fileName,ind=3*gInd+ReInd)\n",
    "eps = paramDict['eps']; g = paramDict['g']; Re = paramDict['Re']\n",
    "printName = 'tecFiles/wavyE'+str(round(-np.log10(eps),2)+'G'+str(round(g,2))+'Re'+str(int(Re))+'.dat'\n",
    "vf.printCSVPlanar(pField=pf, fName=printName)\n",
    "#gArr = paramDict['g']\n",
    "#ReArr = paramDict['Re']\n",
    "#paramDict['g'][3:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to redo separation plots for different `utol`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script for flow-vis: theta = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yOff in ffwavy is set as 0.01415891568768276\n",
      "yOff is set as 0.01415891568768276\n",
      "Printed physical field to file tecFiles/wavyB90E2.15G0.0Re1000.dat\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from flowField import *\n",
    "from flowFieldWavy import *\n",
    "\n",
    "# eps = 10^(-3.+0.025*fileind)   => fileind = 40*(log10(eps) +3)\n",
    "# g0 = [0.2:0.025:0.6]    => gind = 40*(g-0.2)\n",
    "# g1 = [0.65:0.05:1.2, 1.3,1.4,1.5]   => gind = 20*(g-0.65)\n",
    "eps = 0.03/4.;  g = 3.0/2.; Re = 1000\n",
    "gFileInd = 0\n",
    "gInd = int(40*(g-0.2))\n",
    "if g> 0.6:\n",
    "    gFileInd = 1\n",
    "    gInd = int(20*(g-0.65))\n",
    "    if gInd > 11: gInd = int((gInd-11)/2+11)\n",
    "ReInd = np.int(np.log10(Re)-1)\n",
    "        \n",
    "eFileInd = 2*int(40*(np.log10(eps)+3)/2)\n",
    "\n",
    "folderPath = '/home/sabarish/matData/'\n",
    "fileName = 'dataSeprn'+str(gFileInd)+'b90_'+str(eFileInd)+'.mat'\n",
    "\n",
    "#vfList, pfList,paramDict = data2ff(fName=folderPath+fileName,ind=gInd)\n",
    "vf, pf,paramDict = data2ff(fName=folderPath+fileName,ind=3*gInd+ReInd)\n",
    "eps = paramDict['eps']; g = paramDict['g']; Re = paramDict['Re']\n",
    "printName = 'tecFiles/wavyB90E'+str(-np.log10(eps))+'G'+str(g)+'Re'+str(int(Re))+'.dat'\n",
    "vf.printCSVPlanar(pField=pf, fName=printName)\n",
    "#gArr = paramDict['g']\n",
    "#ReArr = paramDict['Re']\n",
    "#paramDict['g'][3:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script for flow-vis: theta = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 2] No such file or directory: '/home/sabarish/matData/dataSeprn1b30_30.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/usr/lib/python3/dist-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[1;34m(file_like, appendmat)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/sabarish/matData/dataSeprn1b30_30.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-46d2b0aaaeb8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m#vfList, pfList,paramDict = data2ff(fName=folderPath+fileName,ind=gInd)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mvf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparamDict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata2ff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfName\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfolderPath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfileName\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgInd\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mReInd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[0meps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparamDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparamDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'g'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mRe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparamDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Re'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mprintName\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'tecFiles/wavyB30E'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'G'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'Re'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.dat'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sabarish/Dropbox/gitwork/python3/flowField/flowFieldWavy.py\u001b[0m in \u001b[0;36mdata2ff\u001b[1;34m(fName, ind)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfName\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fName must be a string'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfName\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'.mat'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfName\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfName\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.mat'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mdataFile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstruct_as_record\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[0mdataStruct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataFile\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'solution'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mnCases\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataStruct\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3/dist-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[1;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \"\"\"\n\u001b[0;32m    130\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'variable_names'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m     \u001b[0mMR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m     \u001b[0mmatfile_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmdict\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3/dist-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mmat_reader_factory\u001b[1;34m(file_name, appendmat, **kwargs)\u001b[0m\n\u001b[0;32m     52\u001b[0m        \u001b[0mtype\u001b[0m \u001b[0mdetected\u001b[0m \u001b[1;32min\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \"\"\"\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[0mbyte_stream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m     \u001b[0mmjv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmnv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_matfile_version\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbyte_stream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmjv\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3/dist-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[1;34m(file_like, appendmat)\u001b[0m\n\u001b[0;32m     26\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'.mat'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[1;31m# not a string - maybe file-like object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 2] No such file or directory: '/home/sabarish/matData/dataSeprn1b30_30.mat'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from flowField import *\n",
    "from flowFieldWavy import *\n",
    "\n",
    "# eps = 10^(-3.+0.025*fileind)   => fileind = 40*(log10(eps) +3)\n",
    "# g0 = [0.2:0.025:0.6]    => gind = 40*(g-0.2)\n",
    "# g1 = [0.65:0.05:1.2, 1.3,1.4,1.5]   => gind = 20*(g-0.65)\n",
    "eps = 0.025/4.;  g = 2.0/2.; Re = 10\n",
    "gFileInd = 0\n",
    "gInd = int(40*(g-0.2))\n",
    "if g> 0.6:\n",
    "    gFileInd = 1\n",
    "    gInd = int(20*(g-0.65))\n",
    "    if gInd > 11: gInd = int((gInd-11)/2+11)\n",
    "ReInd = np.int(np.log10(Re)-1)\n",
    "        \n",
    "eFileInd = 2*int(40*(np.log10(eps)+3)/2)\n",
    "\n",
    "folderPath = '/home/sabarish/matData/'\n",
    "fileName = 'dataSeprn'+str(gFileInd)+'b30_'+str(eFileInd)+'.mat'\n",
    "\n",
    "#vfList, pfList,paramDict = data2ff(fName=folderPath+fileName,ind=gInd)\n",
    "vf, pf,paramDict = data2ff(fName=folderPath+fileName,ind=3*gInd+ReInd)\n",
    "eps = paramDict['eps']; g = paramDict['g']; Re = paramDict['Re']\n",
    "printName = 'tecFiles/wavyB30E'+str(-np.log10(eps))+'G'+str(g)+'Re'+str(int(Re))+'.dat'\n",
    "vf.printCSVPlanar(pField=pf, fName=printName)\n",
    "#gArr = paramDict['g']\n",
    "#ReArr = paramDict['Re']\n",
    "#paramDict['g'][3:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.30103   ,  2.        ,  1.82390874,  1.69897   ,  1.60205999,\n",
       "        1.52287875,  1.45593196])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.log10(np.arange(0.02,0.141,0.02)/4.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sabarish/Dropbox/gitwork/python3/flowField/flowField.py:79: UserWarning: No flowDict was supplied. Assigning the default dictionary\n",
      "  warn('No flowDict was supplied. Assigning the default dictionary')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from flowField import *\n",
    "\n",
    "vf = flowField()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 47, 24, 3, 35)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
